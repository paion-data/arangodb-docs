<!doctype html><html lang=en><head><link href=//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.no-icons.min.css rel=stylesheet><link href=//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css rel=stylesheet><link href=/css/fontawesome-all.min.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fontawesome-all.min.css rel=stylesheet></noscript><link href=/css/featherlight.min.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/featherlight.min.css rel=stylesheet></noscript><link href=/css/nucleus.css rel=stylesheet><link href=/css/fonts.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fonts.css rel=stylesheet></noscript><link href=/css/theme.css rel=stylesheet><link href=/css/theme-relearn-light.css rel=stylesheet id=variant-style><link href=/css/print.css rel=stylesheet media=print><script src=/js/variant.js?1747031427></script>
<script>var root_url="/",baseUriFull,baseUri=root_url.replace(/\/$/,"");window.T_Copy_to_clipboard="",window.T_Copied_to_clipboard="",window.T_Copy_link_to_clipboard="",window.T_Link_copied_to_clipboard="",baseUriFull="http://localhost/",window.variants&&variants.init(["relearn-light"])</script><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.119.0"><meta itemprop=description property="description" content="ArangoDB clusters are comprised of DB-Servers, Coordinators, and Agents, with synchronous data replication between DB-Servers and automatic failover"><meta property="og:url" content="http://localhost/3.12/deploy/cluster/"><meta property="og:title" content="Cluster deployments"><meta property="og:type" content="website"><meta property="og:description" content="ArangoDB clusters are comprised of DB-Servers, Coordinators, and Agents, with synchronous data replication between DB-Servers and automatic failover"><meta name=docsearch:version content="3.12"><title>Cluster deployments | ArangoDB Documentation</title><link href=/images/favicon.png rel=icon type=image/png><script src=/js/jquery.min.js></script>
<script src=/js/clipboard.min.js?1747031427 defer></script>
<script src=/js/featherlight.min.js?1747031427 defer></script>
<script>var versions=[{alias:"devel",deprecated:!1,name:"3.13",version:"3.13.0"},{alias:"stable",deprecated:!1,name:"3.12",version:"3.12.4"},{alias:"3.11",deprecated:!1,name:"3.11",version:"3.11.13"},{alias:"3.10",deprecated:!0,name:"3.10",version:"3.10.14"}]</script><script>var develVersion={alias:"devel",deprecated:!1,name:"3.13",version:"3.13.0"}</script><script>var stableVersion={alias:"stable",deprecated:!1,name:"3.12",version:"3.12.4"}</script><script src=/js/codeblocks.js?1747031427 defer></script>
<script src=/js/theme.js?1747031427 defer></script></head><body><noscript>You need to enable JavaScript to use the ArangoDB documentation.</noscript><div id=page-wrapper class=page_content_splash style=height:auto;opacity:0><section id=page-main><section class=page-container id=page-container><header id=header style="transition:.5s padding ease-out,.15s" class="zn_header_white header-splash-new nav-down header-splash-wrap header1"><div class=header-block-left><div class=mobile-menu-toggle><button id=sidebar-toggle-navigation onclick=showSidebarHandler()><svg width="1.33em" height="1.33em" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button></div><div class=version-logo-container><div class="logo-container hasinfocard_img arangodb-logo-large"><div class=logo><a href=https://www.arangodb.com/><img src=/images/logo_main.png alt=ArangoDB title></a></div></div><div class=arangodb-logo-small><a href=https://arangodb.com/><img alt="ArangoDB Logo" src=/images/ArangoDB_Logo_White_small.png></a></div></div></div><div class=container-right style=display:hidden></div><div class=search-and-version-container><a href=# class="home-link is-current" aria-label="Go to home page" onclick=goToHomepage(event)></a><div id=searchbox></div><script type=text/javascript>const SCRIPT_SRC="https://unpkg.com/@inkeep/widgets-embed@0.2.290/dist/embed.js";function loadAndInitializeInkeep(){if(document.querySelector(`script[src="${SCRIPT_SRC}]"`))return;const e=document.createElement("script");e.type="module",e.src=SCRIPT_SRC,e.onload=initializeInkeep,document.head.appendChild(e)}function initializeInkeep(){const e=Inkeep({integrationId:"clo4lx6jk0000s601cp21x2ok",apiKey:"13b4e56966a76e86c6ff359cd795ee6a0412f751d75d6383",organizationId:"org_HGBkkzGAa4KeGJGh",organizationDisplayName:"ArangoDB",primaryBrandColor:"#80a54d",stringReplacementRules:[{matchingRule:{ruleType:"Substring",string:"Arangograph"},replaceWith:"ArangoGraph"},{matchingRule:{ruleType:"Substring",string:"Aql"},replaceWith:"AQL"},{matchingRule:{ruleType:"Substring",string:"Arangodb"},replaceWith:"ArangoDB"}],customCardSettings:[{filters:{UrlMatch:{ruleType:"PartialUrl",partialUrl:"arango.qubitpi.org"}},searchTabLabel:"Official Docs"},{filters:{UrlMatch:{ruleType:"PartialUrl",partialUrl:"developer.arangodb.com"}},searchTabLabel:"Developer Hub"},{filters:{UrlMatch:{ruleType:"PartialUrl",partialUrl:"arangodb.com"}},searchTabLabel:"Home"}]}),t=e.embed({componentType:"ChatButton",properties:{stylesheetUrls:["/css/fonts.css"],fixedPositionXOffset:"52px",baseSettings:{theme:{primaryColors:{textColorOnPrimary:"white"},tokens:{fonts:{body:"'Inter'",heading:"'Inter'"},zIndex:{overlay:1e4,modal:11e3,popover:12e3,skipLink:13e3,toast:14e3,tooltip:15e3}}}},aiChatSettings:{botAvatarSrcUrl:"/images/ArangoDB_Logo_White_small.png",quickQuestions:["What can you do with AQL that is not feasible with SQL?","How do I search for objects within arrays?","Where can I deploy my ArangoDB instance?"],getHelpCallToActions:[{icon:{builtIn:"FaSlack"},name:"Slack",url:"https://arangodb-community.slack.com/"}]},searchSettings:{tabSettings:{isAllTabEnabled:!1,alwaysDisplayedTabs:["Official Docs","Developer Hub","Home"]}}}})}loadAndInitializeInkeep()</script><div class=version-selector><select id=arangodb-version onchange=changeVersion()><option value=3.13>3.13</option><option value=3.12>3.12</option><option value=3.11>3.11</option><option value=3.10>3.10</option><option value=3.9>3.9</option><option value=3.8>3.8</option></select></div></div></header><iframe src=/nav.html title=description id=menu-iframe class="menu-iframe active" style=opacity:0></iframe><div class=container-main><div class=row-main><nav id=breadcrumbs><ol class=links itemscope itemtype=http://schema.org/BreadcrumbList><meta itemprop=itemListOrder content="Descending"><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="3.12"><a itemprop=item class=link href=/3.12/><span itemprop=name class=breadcrumb-entry>3.12.4</span></a>
<i class="fas fa-chevron-right fa-fw"></i></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="Deploy"><a itemprop=item class=link href=/3.12/deploy/><span itemprop=name class=breadcrumb-entry>Deploy</span></a>
<i class="fas fa-chevron-right fa-fw"></i></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="Cluster"><a itemprop=item class=link href=/3.12/deploy/cluster/><span itemprop=name class=breadcrumb-entry>Cluster</span></a></li></ol></nav><article class=default><hgroup><h1>Cluster deployments</h1><p class=lead>ArangoDB clusters are comprised of DB-Servers, Coordinators, and Agents, with synchronous data replication between DB-Servers and automatic failover</p></hgroup><p>The Cluster architecture of ArangoDB is a <em>CP</em> master/master model with no
single point of failure.</p><p>With &ldquo;CP&rdquo; in terms of the <a href=https://en.wikipedia.org/wiki/CAP_theorem target=_blank rel="noopener noreferrer" class=link>CAP theorem</a>&nbsp;<i class="fas fa-external-link-alt"></i>
we mean that in the presence of a
network partition, the database prefers internal consistency over
availability. With &ldquo;master/master&rdquo; we mean that clients can send their
requests to an arbitrary node, and experience the same view on the
database regardless. &ldquo;No single point of failure&rdquo; means that the cluster
can continue to serve requests, even if one machine fails completely.</p><p>In this way, ArangoDB has been designed as a distributed multi-model
database. This section gives a short outline on the Cluster architecture and
how the above features and capabilities are achieved.</p><h2 id=structure-of-an-arangodb-cluster>Structure of an ArangoDB Cluster <a href=/3.12/deploy/cluster/#structure-of-an-arangodb-cluster class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>An ArangoDB Cluster consists of a number of ArangoDB instances
which talk to each other over the network. They play different roles,
which are explained in detail below.</p><p>The current configuration
of the Cluster is held in the <em>Agency</em>, which is a highly-available
resilient key/value store based on an odd number of ArangoDB instances
running <a href=https://raft.github.io/ target=_blank rel="noopener noreferrer" class=link>Raft Consensus Protocol</a>&nbsp;<i class="fas fa-external-link-alt"></i>.</p><p>For the various instances in an ArangoDB Cluster there are three distinct
roles:</p><ul><li><em>Agents</em></li><li><em>Coordinators</em></li><li><em>DB-Servers</em>.</li></ul><p><figure class=image-caption><img alt="ArangoDB Cluster" src=/images/cluster-topology.png><figcaption></figcaption></figure></p><h3 id=agents>Agents <a href=/3.12/deploy/cluster/#agents class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>One or multiple <em>Agents</em> form the <em>Agency</em> in an ArangoDB Cluster. The
<em>Agency</em> is the central place to store the configuration in a Cluster. It
performs leader elections and provides other synchronization services for
the whole Cluster. Without the <em>Agency</em> none of the other components can
operate.</p><p>While generally invisible to the outside the <em>Agency</em> is the heart of the
Cluster. As such, fault tolerance is of course a must have for the
<em>Agency</em>. To achieve that the <em>Agents</em> are using the
<a href=https://raft.github.io/ target=_blank rel="noopener noreferrer" class=link>Raft Consensus Algorithm</a>&nbsp;<i class="fas fa-external-link-alt"></i>.
The algorithm formally guarantees
conflict free configuration management within the ArangoDB Cluster.</p><p>At its core the <em>Agency</em> manages a big configuration tree. It supports
transactional read and write operations on this tree, and other servers
can subscribe to HTTP callbacks for all changes to the tree.</p><h3 id=coordinators>Coordinators <a href=/3.12/deploy/cluster/#coordinators class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><em>Coordinators</em> should be accessible from the outside. These are the ones
the clients talk to. They coordinate cluster tasks like
executing queries and running Foxx services. They know where the
data is stored and optimize where to run user-supplied queries or
parts thereof. <em>Coordinators</em> are stateless and can thus easily be shut down
and restarted as needed.</p><h3 id=db-servers>DB-Servers <a href=/3.12/deploy/cluster/#db-servers class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><em>DB-Servers</em> are the ones where the data is actually hosted. They
host shards of data and using synchronous replication a <em>DB-Server</em> may
either be <em>leader</em> or <em>follower</em> for a shard. Document operations are first
applied on the <em>leader</em> and then synchronously replicated to
all followers.</p><p>Shards must not be accessed from the outside but indirectly through the
<em>Coordinators</em>. They may also execute queries in part or as a whole when
asked by a <em>Coordinator</em>.</p><p>See <a href=#sharding class=link>Sharding</a> below for more information.</p><h2 id=many-sensible-configurations>Many sensible configurations <a href=/3.12/deploy/cluster/#many-sensible-configurations class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>This architecture is very flexible and thus allows many configurations,
which are suitable for different usage scenarios:</p><ol><li>The default configuration is to run exactly one <em>Coordinator</em> and
one <em>DB-Server</em> on each machine. This achieves the classical
master/master setup, since there is a perfect symmetry between the
different nodes, clients can equally well talk to any one of the
<em>Coordinators</em> and all expose the same view to the data store. <em>Agents</em>
can run on separate, less powerful machines.</li><li>One can deploy more <em>Coordinators</em> than <em>DB-Servers</em>. This is a sensible
approach if one needs a lot of CPU power for the Foxx services,
because they run on the <em>Coordinators</em>.</li><li>One can deploy more <em>DB-Servers</em> than <em>Coordinators</em> if more data capacity
is needed and the query performance is the lesser bottleneck</li><li>One can deploy a <em>Coordinator</em> on each machine where an application
server (e.g. a node.js server) runs, and the <em>Agents</em> and <em>DB-Servers</em>
on a separate set of machines elsewhere. This avoids a network hop
between the application server and the database and thus decreases
latency. Essentially, this moves some of the database distribution
logic to the machine where the client runs.</li></ol><p>As you can see, the <em>Coordinator</em> layer can be scaled and deployed independently
from the <em>DB-Server</em> layer.</p><div class="box notices cstyle warning"><div class=box-content-container><div class=box-content><i class="fas fa-exclamation-triangle"></i><div class=box-text><p>It is a best practice and a recommended approach to run <em>Agent</em> instances
on different machines than <em>DB-Server</em> instances.</p><p>When deploying using the tool <a href=/3.12/components/tools/arangodb-starter/ class=link><em>Starter</em></a>
this can be achieved by using the options <code>--cluster.start-dbserver=false</code> and
<code>--cluster.start-coordinator=false</code> on the first three machines where the <em>Starter</em>
is started, if the desired <em>Agency</em> <em>size</em> is 3, or on the first 5 machines
if the desired <em>Agency</em> <em>size</em> is 5.</p></div></div></div></div><div class="box notices cstyle info"><div class=box-content-container><div class=box-content><i class="fas fa-info-circle"></i><div class=box-text>The different instances that form a Cluster are supposed to be run in the same
<em>Data Center</em> (DC), with reliable and high-speed network connection between
all the machines participating to the Cluster.</div></div></div></div><h2 id=sharding>Sharding <a href=/3.12/deploy/cluster/#sharding class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>Using the roles outlined above an ArangoDB Cluster is able to distribute
data in so called <em>shards</em> across multiple <em>DB-Servers</em>. Sharding
allows to use multiple machines to run a cluster of ArangoDB
instances that together constitute a single database. This enables
you to store much more data, since ArangoDB distributes the data
automatically to the different servers. In many situations one can
also reap a benefit in data throughput, again because the load can
be distributed to multiple machines.</p><p><figure class=image-caption><img alt="Cluster Sharding" src=/images/cluster_sharding.jpg><figcaption></figcaption></figure></p><p>From the outside this process is fully transparent:
An application may talk to any <em>Coordinator</em> and
it automatically figures out where the data is currently stored when reading
or is to be stored when writing. The information about the <em>shards</em>
is shared across all <em>Coordinators</em> using the <em>Agency</em>.</p><p><em>Shards</em> are configured per <em>collection</em> so multiple <em>shards</em> of data form
the <em>collection</em> as a whole. To determine in which <em>shard</em> the data is to
be stored ArangoDB performs a hash across the values. By default this
hash is being created from the document _<em>key</em>.</p><p>For further information, please refer to the
<a href=/3.12/deploy/architecture/data-sharding/ class=link><em>Cluster Sharding</em></a> section.</p><h2 id=oneshard>OneShard <a href=/3.12/deploy/cluster/#oneshard class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>A OneShard deployment offers a practicable solution that enables significant
performance improvements by massively reducing cluster-internal communication
and allows running transactions with ACID guarantees on shard leaders.</p><p>For more information, please refer to the <a href=/3.12/deploy/oneshard/ class=link>OneShard</a>
chapter.</p><h2 id=synchronous-replication>Synchronous replication <a href=/3.12/deploy/cluster/#synchronous-replication class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>In an ArangoDB Cluster, the replication among the data stored by the <em>DB-Servers</em>
is synchronous.</p><p>Synchronous replication works on a per-shard basis. Using the <code>replicationFactor</code>
option, you can configure for each <em>collection</em> how many copies of each <em>shard</em>
are kept in the Cluster.</p><div class="box notices cstyle danger"><div class=box-content-container><div class=box-content><i class="fa fa-times-circle"></i><div class=box-text><p>If a collection has a <em>replication factor</em> of <code>1</code>, its data is <strong>not</strong>
replicated to other <em>DB-Servers</em>. This exposes you to a risk of data loss, if
the machine running the <em>DB-Server</em> with the only copy of the data fails permanently.</p><p>You need to set the <em>replication factor</em> to a value equal or higher than <code>2</code>
to achieve minimal data redundancy via the synchronous replication.</p><p>You need to set a <em>replication factor</em> equal to or higher than <code>2</code>
<strong>explicitly</strong> when creating a collection, or you can adjust it later if you
forgot to set it at creation time. You can also enforce a
minimum replication factor for all collections by setting the
<a href=/3.12/components/arangodb-server/options/#--clustermin-replication-factor class=link><code>--cluster.min-replication-factor</code> startup option</a>.</p><p>When using a Cluster, please make sure all the collections that are important
(and should not be lost in any case) have a <em>replication factor</em> equal or higher
than <code>2</code>.</p></div></div></div></div><p>At any given time, one of the copies is declared to be the <em>leader</em> and
all other replicas are <em>followers</em>. Internally, write operations for this <em>shard</em>
are always sent to the <em>DB-Server</em> which happens to hold the <em>leader</em> copy,
which in turn replicates the changes to all <em>followers</em> before the operation
is considered to be done and reported back to the <em>Coordinator</em>.
Internally, read operations are all served by the <em>DB-Server</em> holding the <em>leader</em> copy,
this allows to provide snapshot semantics for complex transactions.</p><p>Using synchronous replication alone guarantees consistency and high availability
at the cost of reduced performance: write requests have a higher latency
(due to every write-request having to be executed on the <em>followers</em>) and
read requests do not scale out as only the <em>leader</em> is being asked.</p><p>In a Cluster, synchronous replication is managed by the <em>Coordinators</em> for the client.
The data is always stored on the <em>DB-Servers</em>.</p><p>The following example gives you an idea of how synchronous operation
has been implemented in ArangoDB Cluster:</p><ol><li><p>Connect to a <em>Coordinator</em> via <a href=/3.12/components/tools/arangodb-shell/ class=link><em>arangosh</em></a></p></li><li><p>Create a collection: <code>db._create("test", {"replicationFactor": 2});</code></p></li><li><p>The <em>Coordinator</em> figures out a <em>leader</em> and one <em>follower</em> and creates
one <em>shard</em> (as this is the default)</p></li><li><p>Insert data: <code>db.test.insert({"foo": "bar"});</code></p></li><li><p>The <em>Coordinator</em> writes the data to the <em>leader</em>, which in turn
replicates it to the <em>follower</em>.</p></li><li><p>Only when both are successful, the result is reported indicating success:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;_id&#34;</span> <span class=p>:</span> <span class=s2>&#34;test/7987&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;_key&#34;</span> <span class=p>:</span> <span class=s2>&#34;7987&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;_rev&#34;</span> <span class=p>:</span> <span class=s2>&#34;7987&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></li></ol><p>Synchronous replication comes at the cost of an increased latency for
write operations, simply because there is one more network hop within the
Cluster for every request. Therefore the user can set the <em>replicationFactor</em>
to 1, which means that only one copy of each shard is kept, thereby
switching off synchronous replication. This is a suitable setting for
less important or easily recoverable data for which low latency write
operations matter.</p><h2 id=automatic-failover>Automatic failover <a href=/3.12/deploy/cluster/#automatic-failover class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=failure-of-a-follower>Failure of a follower <a href=/3.12/deploy/cluster/#failure-of-a-follower class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>If a <em>DB-Server</em> that holds a <em>follower</em> copy of a <em>shard</em> fails, then the <em>leader</em>
can no longer synchronize its changes to that <em>follower</em>. After a short timeout
(3 seconds), the <em>leader</em> gives up on the <em>follower</em> and declares it to be
out of sync.</p><p>One of the following two cases can happen:</p><ul><li><p><strong>A</strong>: If another <em>DB-Server</em> (that does not hold a <em>replica</em> for this <em>shard</em> already)
is available in the Cluster, a new <em>follower</em> is automatically
created on this other <em>DB-Server</em> (so the <em>replication factor</em> constraint is
satisfied again).</p></li><li><p><strong>B</strong>: If no other <em>DB-Server</em> (that does not hold a <em>replica</em> for this <em>shard</em> already)
is available, the service continues with one <em>follower</em> less than the number
prescribed by the <em>replication factor</em>.</p></li></ul><p>If the old <em>DB-Server</em> with the <em>follower</em> copy comes back, one of the following
two cases can happen:</p><ul><li><p>Following case <strong>A</strong>, the <em>DB-Server</em> recognizes that there is a new
<em>follower</em> that was elected in the meantime, so it is no longer a <em>follower</em>
for that <em>shard</em>.</p></li><li><p>Following case <strong>B</strong>, the <em>DB-Server</em> automatically resynchronizes its
data with the <em>leader</em>. The <em>replication factor</em> constraint is now satisfied again
and order is restored.</p></li></ul><h3 id=failure-of-a-leader>Failure of a leader <a href=/3.12/deploy/cluster/#failure-of-a-leader class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>If a <em>DB-Server</em> that holds a <em>leader</em> copy of a shard fails, then the <em>leader</em>
can no longer serve any requests. It no longer sends a heartbeat to
the <em>Agency</em>. Therefore, a <em>supervision</em> process running in the <em>Raft</em> <em>leader</em>
of the Agency, can take the necessary action (after 15 seconds of missing
heartbeats), namely to promote one of the <em>DB-Servers</em> that hold in-sync
replicas of the <em>shard</em> to <em>leader</em> for that <em>shard</em>. This involves a
reconfiguration in the <em>Agency</em> and leads to the fact that <em>Coordinators</em>
now contact a different <em>DB-Server</em> for requests to this <em>shard</em>. Service
resumes. The other surviving <em>replicas</em> automatically resynchronize their
data with the new <em>leader</em>.</p><p>In addition to the above, one of the following two cases cases can happen:</p><ul><li><p><strong>A</strong>: If another <em>DB-Server</em> (that does not hold a <em>replica</em> for this <em>shard</em> already)
is available in the Cluster, a new <em>follower</em> is automatically
created on this other <em>DB-Server</em> (so the <em>replication factor</em> constraint is
satisfied again).</p></li><li><p><strong>B</strong>: If no other <em>DB-Server</em> (that does not hold a <em>replica</em> for this <em>shard</em> already)
is available the service continues with one <em>follower</em> less than the number
prescribed by the <em>replication factor</em>.</p></li></ul><p>When the <em>DB-Server</em> with the original <em>leader</em> copy comes back, it recognizes
that a new <em>leader</em> was elected in the meantime, and one of the following
two cases can happen:</p><ul><li><p>Following case <strong>A</strong>, since also a new <em>follower</em> was created and
the <em>replication factor</em> constraint is satisfied, the <em>DB-Server</em> is no
longer a <em>follower</em> for that <em>shard</em>.</p></li><li><p>Following case <strong>B</strong>, the <em>DB-Server</em> notices that it now holds
a <em>follower</em> <em>replica</em> of that <em>shard</em> and it resynchronizes its data with the
new <em>leader</em>. The <em>replication factor</em> constraint is satisfied again,
and order is restored.</p></li></ul><p>The following example gives you an idea of how <em>failover</em>
has been implemented in ArangoDB Cluster:</p><ol><li>The <em>leader</em> of a <em>shard</em> (let&rsquo;s name it <em>DBServer001</em>) is going down.</li><li>A <em>Coordinator</em> is asked to return a document: <code>db.test.document("100069");</code></li><li>The <em>Coordinator</em> determines which server is responsible for this document
and finds <em>DBServer001</em></li><li>The <em>Coordinator</em> tries to contact <em>DBServer001</em> and timeouts because it is
not reachable.</li><li>After a short while, the <em>supervision</em> (running in parallel on the <em>Agency</em>)
sees that <em>heartbeats</em> from <em>DBServer001</em> are not coming in</li><li>The <em>supervision</em> promotes one of the <em>followers</em> (say <em>DBServer002</em>), that
is in sync, to be <em>leader</em> and makes <em>DBServer001</em> a <em>follower</em>.</li><li>As the <em>Coordinator</em> continues trying to fetch the document, it sees that
the <em>leader</em> changed to <em>DBServer002</em></li><li>The <em>Coordinator</em> tries to contact the new <em>leader</em> (<em>DBServer002</em>) and returns
the result:<div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;_key&#34;</span> <span class=p>:</span> <span class=s2>&#34;100069&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;_id&#34;</span> <span class=p>:</span> <span class=s2>&#34;test/100069&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;_rev&#34;</span> <span class=p>:</span> <span class=s2>&#34;513&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;foo&#34;</span> <span class=p>:</span> <span class=s2>&#34;bar&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></li><li>After a while the <em>supervision</em> declares <em>DBServer001</em> to be completely dead.</li><li>A new <em>follower</em> is determined from the pool of <em>DB-Servers</em>.</li><li>The new <em>follower</em> syncs its data from the <em>leader</em> and order is restored.</li></ol><p>Please note that there may still be timeouts. Depending on when exactly
the request has been done (in regard to the <em>supervision</em>) and depending
on the time needed to reconfigure the Cluster the <em>Coordinator</em> might fail
with a timeout error.</p><h2 id=shard-movement-and-resynchronization>Shard movement and resynchronization <a href=/3.12/deploy/cluster/#shard-movement-and-resynchronization class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>All <em>shard</em> data synchronizations are done in an incremental way, such that
resynchronizations are quick. This technology allows to move shards
(<em>follower</em> and <em>leader</em> ones) between <em>DB-Servers</em> without service interruptions.
Therefore, an ArangoDB Cluster can move all the data on a specific <em>DB-Server</em>
to other <em>DB-Servers</em> and then shut down that server in a controlled way.
This allows to scale down an ArangoDB Cluster without service interruption,
loss of fault tolerance or data loss. Furthermore, one can re-balance the
distribution of the <em>shards</em>, either manually or automatically.</p><p>All these operations can be triggered via a REST/JSON API or via the
graphical web interface. All fail-over operations are completely handled within
the ArangoDB Cluster.</p><h2 id=microservices-and-zero-administration>Microservices and zero administration <a href=/3.12/deploy/cluster/#microservices-and-zero-administration class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>The design and capabilities of ArangoDB are geared towards usage in
modern microservice architectures of applications. With the
<a href=/3.12/develop/foxx-microservices/ class=link>Foxx services</a> it is very easy to deploy a data
centric microservice within an ArangoDB Cluster.</p><p>In addition, one can deploy multiple instances of ArangoDB within the
same project. One part of the project might need a scalable document
store, another might need a graph database, and yet another might need
the full power of a multi-model database actually mixing the various
data models. There are enormous efficiency benefits to be reaped by
being able to use a single technology for various roles in a project.</p><p>To simplify life of the <em>devops</em> in such a scenario we try as much as
possible to use a <em>zero administration</em> approach for ArangoDB. A running
ArangoDB Cluster is resilient against failures and essentially repairs
itself in case of temporary failures.</p><h2 id=deployment>Deployment <a href=/3.12/deploy/cluster/#deployment class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>An ArangoDB Cluster can be deployed in several ways, e.g. by manually
starting all the needed instances, by using the tool
<a href=/3.12/components/tools/arangodb-starter/ class=link><em>Starter</em></a>, in Docker and in Kubernetes.</p><p>See the <a href=/3.12/deploy/cluster/deployment/ class=link>Cluster Deployment</a>
chapter for instructions.</p><p>ArangoDB is also available as a cloud service, the
<a href=https://dashboard.arangodb.cloud/home target=_blank rel="noopener noreferrer" class=link><strong>ArangoGraph Insights Platform</strong></a>&nbsp;<i class="fas fa-external-link-alt"></i>.</p><h2 id=cluster-id>Cluster ID <a href=/3.12/deploy/cluster/#cluster-id class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>Every ArangoDB instance in a Cluster is assigned a unique
ID during its startup. Using its ID, a node is identifiable
throughout the Cluster. All cluster operations communicate
via this ID.</p><nav class=pagination><span class=prev><a class="nav nav-prev link" href=/3.12/deploy/single-instance/><i class="fas fa-chevron-left fa-fw"></i><p>Single instance</p></a></span><span class=next><a class="nav nav-next link" href=/3.12/deploy/cluster/deployment/><p>Deployment</p><i class="fas fa-chevron-right fa-fw"></i></a></span></nav></article><div class=toc-container><a class=edit-page aria-label href=https://github.com/arangodb/docs-hugo/edit/main/site/content/3.12/deploy/cluster/_index.md target=_blank><i class="fab fa-fw fa-github edit-page-icon"></i></a><div class=toc><div class=toc-content><div class=toc-header><p>On this page</p></div><nav id=TableOfContents><div class=level-2><a href=#structure-of-an-arangodb-cluster>Structure of an ArangoDB Cluster</a></div><div class=level-3><a href=#agents>Agents</a></div><div class=level-3><a href=#coordinators>Coordinators</a></div><div class=level-3><a href=#db-servers>DB-Servers</a></div><div class=level-2><a href=#many-sensible-configurations>Many sensible configurations</a></div><div class=level-2><a href=#sharding>Sharding</a></div><div class=level-2><a href=#oneshard>OneShard</a></div><div class=level-2><a href=#synchronous-replication>Synchronous replication</a></div><div class=level-2><a href=#automatic-failover>Automatic failover</a></div><div class=level-3><a href=#failure-of-a-follower>Failure of a follower</a></div><div class=level-3><a href=#failure-of-a-leader>Failure of a leader</a></div><div class=level-2><a href=#shard-movement-and-resynchronization>Shard movement and resynchronization</a></div><div class=level-2><a href=#microservices-and-zero-administration>Microservices and zero administration</a></div><div class=level-2><a href=#deployment>Deployment</a></div><div class=level-2><a href=#cluster-id>Cluster ID</a></div></nav></div></div></div></div></div></section></section></div><button class="back-to-top hidden" onclick=goToTop(event) href=#><i class="fa fa-arrow-up"></i></button><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@docsearch/css@3>
<script src=https://cdn.jsdelivr.net/npm/@docsearch/js@3></script>
<script type=text/javascript>window.setupDocSearch=function(e){if(!window.docsearch)return;docsearch({appId:"OK3ZBQ5982",apiKey:"500c85ccecb335d507fe4449aed12e1d",indexName:"arangodbdocs",insights:!0,container:"#searchbox",debug:!1,maxResultsPerGroup:10,searchParameters:{facetFilters:[`version:${e}`]}})}</script></body></html>