<!doctype html><html lang=en><head><link href=//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.no-icons.min.css rel=stylesheet><link href=//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css rel=stylesheet><link href=/css/fontawesome-all.min.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fontawesome-all.min.css rel=stylesheet></noscript><link href=/css/featherlight.min.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/featherlight.min.css rel=stylesheet></noscript><link href=/css/nucleus.css rel=stylesheet><link href=/css/fonts.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fonts.css rel=stylesheet></noscript><link href=/css/theme.css rel=stylesheet><link href=/css/theme-relearn-light.css rel=stylesheet id=variant-style><link href=/css/print.css rel=stylesheet media=print><script src=/js/variant.js?1743774193></script>
<script>var root_url="/",baseUriFull,baseUri=root_url.replace(/\/$/,"");window.T_Copy_to_clipboard="",window.T_Copied_to_clipboard="",window.T_Copy_link_to_clipboard="",window.T_Link_copied_to_clipboard="",baseUriFull="http://localhost/",window.variants&&variants.init(["relearn-light"])</script><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.119.0"><meta itemprop=description property="description" content="Improved performance and reporting for AQL queries, new caching features for indexed data, improvements to the web interface"><meta property="og:url" content="http://localhost/3.11/release-notes/version-3.11/whats-new-in-3-11/"><meta property="og:title" content="Features and Improvements in ArangoDB 3.11"><meta property="og:type" content="website"><meta property="og:description" content="Improved performance and reporting for AQL queries, new caching features for indexed data, improvements to the web interface"><meta name=docsearch:version content="3.11"><title>Features and Improvements in ArangoDB 3.11 | ArangoDB Documentation</title><link href=/images/favicon.png rel=icon type=image/png><script src=/js/jquery.min.js></script>
<script src=/js/clipboard.min.js?1743774193 defer></script>
<script src=/js/featherlight.min.js?1743774193 defer></script>
<script>var versions=[{alias:"devel",deprecated:!1,name:"3.13",version:"3.13.0"},{alias:"stable",deprecated:!1,name:"3.12",version:"3.12.4"},{alias:"3.11",deprecated:!1,name:"3.11",version:"3.11.13"},{alias:"3.10",deprecated:!0,name:"3.10",version:"3.10.14"}]</script><script>var develVersion={alias:"devel",deprecated:!1,name:"3.13",version:"3.13.0"}</script><script>var stableVersion={alias:"stable",deprecated:!1,name:"3.12",version:"3.12.4"}</script><script src=/js/codeblocks.js?1743774193 defer></script>
<script src=/js/theme.js?1743774193 defer></script></head><body><noscript>You need to enable JavaScript to use the ArangoDB documentation.</noscript><div id=page-wrapper class=page_content_splash style=height:auto;opacity:0><section id=page-main><section class=page-container id=page-container><header id=header style="transition:.5s padding ease-out,.15s" class="zn_header_white header-splash-new nav-down header-splash-wrap header1"><div class=header-block-left><div class=mobile-menu-toggle><button id=sidebar-toggle-navigation onclick=showSidebarHandler()><svg width="1.33em" height="1.33em" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button></div><div class=version-logo-container><div class="logo-container hasinfocard_img arangodb-logo-large"><div class=logo><a href=https://www.arangodb.com/><img src=/images/logo_main.png alt=ArangoDB title></a></div></div><div class=arangodb-logo-small><a href=https://arangodb.com/><img alt="ArangoDB Logo" src=/images/ArangoDB_Logo_White_small.png></a></div></div></div><div class=container-right style=display:hidden></div><div class=search-and-version-container><a href=# class="home-link is-current" aria-label="Go to home page" onclick=goToHomepage(event)></a><div id=searchbox></div><script type=text/javascript>const SCRIPT_SRC="https://unpkg.com/@inkeep/widgets-embed@0.2.290/dist/embed.js";function loadAndInitializeInkeep(){if(document.querySelector(`script[src="${SCRIPT_SRC}]"`))return;const e=document.createElement("script");e.type="module",e.src=SCRIPT_SRC,e.onload=initializeInkeep,document.head.appendChild(e)}function initializeInkeep(){const e=Inkeep({integrationId:"clo4lx6jk0000s601cp21x2ok",apiKey:"13b4e56966a76e86c6ff359cd795ee6a0412f751d75d6383",organizationId:"org_HGBkkzGAa4KeGJGh",organizationDisplayName:"ArangoDB",primaryBrandColor:"#80a54d",stringReplacementRules:[{matchingRule:{ruleType:"Substring",string:"Arangograph"},replaceWith:"ArangoGraph"},{matchingRule:{ruleType:"Substring",string:"Aql"},replaceWith:"AQL"},{matchingRule:{ruleType:"Substring",string:"Arangodb"},replaceWith:"ArangoDB"}],customCardSettings:[{filters:{UrlMatch:{ruleType:"PartialUrl",partialUrl:"arango.qubitpi.org"}},searchTabLabel:"Official Docs"},{filters:{UrlMatch:{ruleType:"PartialUrl",partialUrl:"developer.arangodb.com"}},searchTabLabel:"Developer Hub"},{filters:{UrlMatch:{ruleType:"PartialUrl",partialUrl:"arangodb.com"}},searchTabLabel:"Home"}]}),t=e.embed({componentType:"ChatButton",properties:{stylesheetUrls:["/css/fonts.css"],fixedPositionXOffset:"52px",baseSettings:{theme:{primaryColors:{textColorOnPrimary:"white"},tokens:{fonts:{body:"'Inter'",heading:"'Inter'"},zIndex:{overlay:1e4,modal:11e3,popover:12e3,skipLink:13e3,toast:14e3,tooltip:15e3}}}},aiChatSettings:{botAvatarSrcUrl:"/images/ArangoDB_Logo_White_small.png",quickQuestions:["What can you do with AQL that is not feasible with SQL?","How do I search for objects within arrays?","Where can I deploy my ArangoDB instance?"],getHelpCallToActions:[{icon:{builtIn:"FaSlack"},name:"Slack",url:"https://arangodb-community.slack.com/"}]},searchSettings:{tabSettings:{isAllTabEnabled:!1,alwaysDisplayedTabs:["Official Docs","Developer Hub","Home"]}}}})}loadAndInitializeInkeep()</script><div class=version-selector><select id=arangodb-version onchange=changeVersion()><option value=3.13>3.13</option><option value=3.12>3.12</option><option value=3.11>3.11</option><option value=3.10>3.10</option><option value=3.9>3.9</option><option value=3.8>3.8</option></select></div></div></header><iframe src=/nav.html title=description id=menu-iframe class="menu-iframe active" style=opacity:0></iframe><div class=container-main><div class=row-main><nav id=breadcrumbs><ol class=links itemscope itemtype=http://schema.org/BreadcrumbList><meta itemprop=itemListOrder content="Descending"><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="3.11"><a itemprop=item class=link href=/3.11/><span itemprop=name class=breadcrumb-entry>3.11.13</span></a>
<i class="fas fa-chevron-right fa-fw"></i></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="Release Notes"><a itemprop=item class=link href=/3.11/release-notes/><span itemprop=name class=breadcrumb-entry>Release Notes</span></a>
<i class="fas fa-chevron-right fa-fw"></i></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="Version 3.11"><a itemprop=item class=link href=/3.11/release-notes/version-3.11/><span itemprop=name class=breadcrumb-entry>Version 3.11</span></a>
<i class="fas fa-chevron-right fa-fw"></i></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="What&rsquo;s New in 3.11"><a itemprop=item class=link href=/3.11/release-notes/version-3.11/whats-new-in-3-11/><span itemprop=name class=breadcrumb-entry>What&rsquo;s New in 3.11</span></a></li></ol></nav><article class=default><hgroup><h1>Features and Improvements in ArangoDB 3.11</h1><p class=lead>Improved performance and reporting for AQL queries, new caching features for indexed data, improvements to the web interface</p></hgroup><p>The following list shows in detail which features have been added or improved in
ArangoDB 3.11. ArangoDB 3.11 also contains several bug fixes that are not listed
here.</p><h2 id=arangosearch>ArangoSearch <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#arangosearch class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=late-materialization-improvements>Late materialization improvements <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#late-materialization-improvements class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The number of disk reads required when executing search queries with late
materialization optimizations applied has been reduced so that less data needs
to be requested from the RocksDB storage engine.</p><h3 id=arangosearch-column-cache-enterprise-edition>ArangoSearch column cache (Enterprise Edition) <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#arangosearch-column-cache-enterprise-edition class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><a href=/3.11/index-and-search/arangosearch/arangosearch-views-reference/ class=link><code>arangosearch</code> Views</a> support new caching options.</p><p><small>Introduced in: v3.9.5, v3.10.2</small></p><ul><li><p>You can enable the new <code>cache</code> option for individual View links or fields
to always cache field normalization values in memory. This can improve the
performance of scoring and ranking queries.</p><p>It also enables caching of auxiliary data used for querying fields that are
indexed with Geo Analyzers. This can improve the performance of geo-spatial
queries.</p></li><li><p>You can enable the new <code>cache</code> option in the definition of a <code>storedValues</code>
View property to always cache stored values in memory. This can improve the
query performance if stored values are involved.</p></li></ul><hr><p><small>Introduced in: v3.9.6, v3.10.2</small></p><ul><li><p>You can enable the new <code>primarySortCache</code> View property to always cache the
primary sort columns in memory. This can improve the performance of queries
that utilize the primary sort order.</p></li><li><p>You can enable the new <code>primaryKeyCache</code> View property to always cache the
primary key column in memory. This can improve the performance of queries
that return many documents.</p></li></ul><hr><p><a href=/3.11/develop/http-api/indexes/inverted/ class=link>Inverted indexes</a> also support similar new caching
options.</p><p><small>Introduced in: v3.10.2</small></p><ul><li><p>A new <code>cache</code> option for inverted indexes as the default or for specific
<code>fields</code> to always cache field normalization values and Geo Analyzer auxiliary
data in memory.</p></li><li><p>A new <code>cache</code> option per object in the definition of the <code>storedValues</code>
elements to always cache stored values in memory.</p></li><li><p>A new <code>cache</code> option in the <code>primarySort</code> property to always cache the
primary sort columns in memory.</p></li><li><p>A new <code>primaryKeyCache</code> property for inverted indexes to always cache the
primary key column in memory.</p></li></ul><hr><p>The cache size can be controlled with the new <code>--arangosearch.columns-cache-limit</code>
startup option and monitored via the new <code>arangodb_search_columns_cache_size</code>
metric.</p><p>ArangoSearch caching is only available in the Enterprise Edition.</p><p>See <a href=/3.11/index-and-search/arangosearch/performance/ class=link>Optimizing View and inverted index query performance</a>
for examples.</p><div class="box notices cstyle info"><div class=box-content-container><div class=box-content><i class="fas fa-info-circle"></i><div class=box-text>If you use ArangoSearch caching in supported 3.9 versions and upgrade an
Active Failover deployment to 3.10, you may need to re-configure the
cache-related options and thus recreate inverted indexes and Views. See
<a href=/3.11/release-notes/version-3.10/known-issues-in-3-10/#arangosearch class=link>Known Issues in 3.10</a>.</div></div></div></div><h2 id=analyzers>Analyzers <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#analyzers class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=geo_s2-analyzer-enterprise-edition><code>geo_s2</code> Analyzer (Enterprise Edition) <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#geo_s2-analyzer-enterprise-edition class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.5</small></p><p>This new Analyzer lets you index GeoJSON data with inverted indexes or Views
similar to the existing <code>geojson</code> Analyzer, but it internally uses a format for
storing the geo-spatial data that is more efficient.</p><p>You can choose between different formats to make a tradeoff between the size on
disk, the precision, and query performance:</p><ul><li>8 bytes per coordinate pair using 4-byte integer values, with limited precision.</li><li>16 bytes per coordinate pair using 8-byte floating-point values, which is still
more compact than the VelocyPack format used by the <code>geojson</code> Analyzer</li><li>24 bytes per coordinate pair using the native Google S2 format to reduce the number
of computations necessary when you execute geo-spatial queries.</li></ul><p>This feature is only available in the Enterprise Edition.</p><p>See <a href=/3.11/index-and-search/analyzers/#geo_s2 class=link>Analyzers</a> for details.</p><h2 id=web-interface>Web interface <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#web-interface class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=new-graph-viewer>New graph viewer <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#new-graph-viewer class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The graph viewer for visualizing named graphs has been reimplemented based on
the <a href=https://visjs.org/ target=_blank rel="noopener noreferrer" class=link>vis.js</a>&nbsp;<i class="fas fa-external-link-alt"></i> library, the interface
has been redesigned to be cleaner and rewritten to use the React framework,
and the overall performance has been improved.</p><p>The available <strong>Layout</strong> algorithms are <strong>forceAtlas2</strong> and <strong>hierarchical</strong>.
Force-based layouts try to avoid overlaps while grouping adjacent nodes together.
The new hierarchical layout is useful for strict topologies like trees.</p><p>A new feature is the ability to search the visible graph to center a specific
vertex. Another quality-of-life improvement is the <strong>Start node</strong> setting listing
the graph&rsquo;s vertex collections and the available document keys, that you can
also search by.</p><p><figure class=image-caption><img alt="New graph viewer" src=/images/graphViewer.png><figcaption></figcaption></figure></p><p>You can still switch to the old graph viewer if desired.</p><p>See the <a href=/3.11/components/web-interface/graphs/ class=link>Graph Viewer</a> documentation for
details.</p><h3 id=search-alias-views><code>search-alias</code> Views <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#search-alias-views class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The 3.11 release of ArangoDB introduces a new web interface for Views that lets
you to create and manage <a href=/3.11/index-and-search/arangosearch/search-alias-views-reference/ class=link><code>search-alias</code> Views</a>.</p><p>Through this dialog, you can easily create a new View and add to it one or more
inverted indexes from your collections that you could otherwise do via the HTTP
or JavaScript API.</p><p>When opening your newly created View, you can copy mutable properties from
previously created <code>search-alias</code> Views, providing a convenient way to apply
the same settings to multiple Views. In addition, the JSON editor offers the
option to directly write the definition of your View in JSON format.</p><p>For more information, see the
<a href=/3.11/index-and-search/arangosearch/search-alias-views-reference/#create-search-alias-views-using-the-web-interface class=link>detailed guide</a>.</p><h3 id=arangosearch-views><code>arangosearch</code> Views <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#arangosearch-views class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The existing way of creating and managing <code>arangosearch</code> Views through the
web interface has been redesigned, offering a more straightforward approach to add
or modify the definition of your View. The settings, links, and JSON editor have
been merged into a single page, allowing for a much quicker workflow.</p><p>For more information, see the
<a href=/3.11/index-and-search/arangosearch/arangosearch-views-reference/#create-arangosearch-views-using-the-web-interface class=link>detailed guide</a>.</p><h3 id=inverted-indexes>Inverted indexes <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#inverted-indexes class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The web interface now includes the option for creating
<a href=/3.11/index-and-search/indexing/working-with-indexes/inverted-indexes/ class=link>inverted indexes</a> on collections. You can set all the
properties directly in the web interface, which previously required the JavaScript
or HTTP API. It also offers an editor where you can write the definition of
your inverted index in JSON format.</p><h3 id=new-sorting-mechanism-and-search-box-for-saved-queries>New sorting mechanism and search box for Saved Queries <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#new-sorting-mechanism-and-search-box-for-saved-queries class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>When working with <strong>Saved Queries</strong> in the web interface, you can now
configure their sort order so that your saved queries are listed by the
date they were last modified.
This is particularly helpful when you have a large amount of saved custom
queries and want to see which ones have been created or used recently.</p><p>In addition, the web interface also offers a search box which helps you
quickly find the query you&rsquo;re looking for.</p><h2 id=aql>AQL <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#aql class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=parallel-gather>Parallel gather <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#parallel-gather class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>On Coordinators in cluster deployments, results from different DB-Servers are
combined into a stream of results. This process is called gathering. It shows as
<code>GatherNode</code> nodes in the execution plan of AQL queries.</p><p>Previously, a cluster AQL query could only parallelize a <code>GatherNode</code> if the
DB-Server query part above it (in terms of query execution plan layout) was a
terminal part of the query. That means that it was not allowed for other nodes of
type <code>ScatterNode</code>, <code>GatherNode</code>, or <code>DistributeNode</code> to be present in the query.</p><p>Modification queries were also not allowed to use parallel gather unless the
<code>--query.parallelize-gather-writes</code> startup option was enabled, which defaulted
to <code>false</code>.</p><p>From v3.11.0 onward, these limitations are removed so that parallel gather can be
used in almost all queries. As a result, the feature is enabled by default and
the <code>--query.parallelize-gather-writes</code> startup option is now obsolete. You can
still disable the optimization by disabling the <code>parallelize-gather</code> AQL
optimizer rule.</p><p>The only case where parallel gather is not supported is when using traversals,
although there are some exceptions for Disjoint SmartGraphs where the traversal
can run completely on the local DB-Server (only available in the Enterprise Edition).</p><p>The parallel gather optimization can not only speed up queries quite significantly,
but also overcome issues with the previous serial processing within <code>GatherNode</code>
nodes, which could lead to high memory usage on Coordinators caused by buffering
of documents for other shards, and timeouts on some DB-Servers because query parts
were idle for too long.</p><h3 id=optimized-access-of-last-element-in-traversals>Optimized access of last element in traversals <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#optimized-access-of-last-element-in-traversals class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>If you use a <code>FOR</code> operation for an AQL graph traversal like <code>FOR v, e, p IN ...</code>
and later access the last vertex or edge via the path variable <code>p</code>, like
<code>FILTER p.vertices[-1].name == "ArangoDB"</code> or <code>FILTER p.edges[-1].weight > 5</code>,
the access is transformed to use the vertex variable <code>v</code> or edge variable <code>e</code>
instead, like <code>FILTER v.name == "ArangoDB"</code> or <code>FILTER e.weight > 5</code>. This is
cheaper to compute because the path variable <code>p</code> may not need to be computed at
all, and it can enable further optimizations that are not possible on <code>p</code>.</p><p>The new <code>optimize-traversal-last-element-access</code> optimization rule appears in
query execution plans if this optimization is applied.</p><h3 id=faster-bulk-insert-operations-in-clusters>Faster bulk <code>INSERT</code> operations in clusters <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#faster-bulk-insert-operations-in-clusters class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>AQL <code>INSERT</code> operations that insert multiple documents can now be faster in
cluster deployments by avoiding unnecessary overhead that AQL queries typically
require for the setup and shutdown in a cluster, as well as for the internal
batching.</p><p>This improvement also decreases the number of HTTP requests to the DB-Servers.
Instead of batching the array of documents (with a default batch size of <code>1000</code>),
a single request per DB-Server is used internally to transfer the data.</p><p>The optimization brings the AQL <code>INSERT</code> performance close to the performance of
the specialized HTTP API for <a href=/3.11/develop/http-api/documents/#create-multiple-documents class=link>creating multiple documents</a>.</p><p>The pattern that is recognized by the optimizer is as follows:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=o>&lt;</span><span class=n>docs</span><span class=o>&gt;</span> <span class=kr>INSERT</span> <span class=n>doc</span> <span class=kr>INTO</span> <span class=n>collection</span></span></span></code></pre></div><p><code>&lt;docs></code> can either be a bind parameter, a variable, or an array literal.
The value needs to be an array of objects and be known at query compile time.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=n>Query</span> <span class=n>String</span> <span class=p>(</span><span class=mi>43</span> <span class=n>chars</span><span class=p>,</span> <span class=n>cacheable</span><span class=o>:</span> <span class=kc>false</span><span class=p>)</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=nv>@docs</span> <span class=kr>INSERT</span> <span class=n>doc</span> <span class=kr>INTO</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Execution</span> <span class=n>plan</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Id</span>   <span class=n>NodeType</span>                         <span class=n>Site</span>  <span class=n>Est</span><span class=p>.</span>   <span class=n>Comment</span>
</span></span><span class=line><span class=cl>  <span class=mi>1</span>   <span class=n>SingletonNode</span>                    <span class=n>COOR</span>     <span class=mi>1</span>   <span class=o>*</span> <span class=n>ROOT</span>
</span></span><span class=line><span class=cl>  <span class=mi>2</span>   <span class=n>CalculationNode</span>                  <span class=n>COOR</span>     <span class=mi>1</span>     <span class=o>-</span> <span class=kd>LET</span> <span class=nl>#2</span> <span class=o>=</span> <span class=p>[</span> <span class=p>{</span> <span class=s2>&#34;value&#34;</span> <span class=o>:</span> <span class=mi>1</span> <span class=p>},</span> <span class=p>{</span> <span class=s2>&#34;value&#34;</span> <span class=o>:</span> <span class=mi>2</span> <span class=p>},</span> <span class=p>{</span> <span class=s2>&#34;value&#34;</span> <span class=o>:</span> <span class=mi>3</span> <span class=p>}</span> <span class=p>]</span>   <span class=cm>/* json expression */</span>   <span class=cm>/* const assignment */</span>
</span></span><span class=line><span class=cl>  <span class=mi>5</span>   <span class=n>MultipleRemoteModificationNode</span>   <span class=n>COOR</span>     <span class=mi>3</span>     <span class=o>-</span> <span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=nl>#2</span> <span class=kr>INSERT</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Indexes</span> <span class=n>used</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=kr>none</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Optimization</span> <span class=n>rules</span> <span class=n>applied</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Id</span>   <span class=n>RuleName</span>
</span></span><span class=line><span class=cl>  <span class=mi>1</span>   <span class=kr>remove</span><span class=o>-</span><span class=n>data</span><span class=o>-</span><span class=n>modification</span><span class=o>-</span><span class=n>out</span><span class=o>-</span><span class=n>variables</span>
</span></span><span class=line><span class=cl>  <span class=mi>2</span>   <span class=n>optimize</span><span class=o>-</span><span class=n>cluster</span><span class=o>-</span><span class=n>multiple</span><span class=o>-</span><span class=n>document</span><span class=o>-</span><span class=n>operations</span></span></span></code></pre></div><p>The query runs completely on the Coordinator. The <code>MultipleRemoteModificationNode</code>
performs a bulk document insert for the whole input array in one go, internally
using a transaction that is more lightweight for transferring the data to the
DB-Servers than a regular AQL query.</p><p>Without the optimization, the Coordinator requests data from the DB-Servers
(<code>GatherNode</code>), but the DB-Servers have to contact the Coordinator in turn to
request their data (<code>DistributeNode</code>), involving a network request for every
batch of documents:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=n>Execution</span> <span class=n>plan</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Id</span>   <span class=n>NodeType</span>            <span class=n>Site</span>  <span class=n>Est</span><span class=p>.</span>   <span class=n>Comment</span>
</span></span><span class=line><span class=cl>  <span class=mi>1</span>   <span class=n>SingletonNode</span>       <span class=n>COOR</span>     <span class=mi>1</span>   <span class=o>*</span> <span class=n>ROOT</span>
</span></span><span class=line><span class=cl>  <span class=mi>2</span>   <span class=n>CalculationNode</span>     <span class=n>COOR</span>     <span class=mi>1</span>     <span class=o>-</span> <span class=kd>LET</span> <span class=nl>#2</span> <span class=o>=</span> <span class=p>[</span> <span class=p>{</span> <span class=s2>&#34;value&#34;</span> <span class=o>:</span> <span class=mi>1</span> <span class=p>},</span> <span class=p>{</span> <span class=s2>&#34;value&#34;</span> <span class=o>:</span> <span class=mi>2</span> <span class=p>},</span> <span class=p>{</span> <span class=s2>&#34;value&#34;</span> <span class=o>:</span> <span class=mi>3</span> <span class=p>}</span> <span class=p>]</span>   <span class=cm>/* json expression */</span>   <span class=cm>/* const assignment */</span>
</span></span><span class=line><span class=cl>  <span class=mi>3</span>   <span class=n>EnumerateListNode</span>   <span class=n>COOR</span>     <span class=mi>3</span>     <span class=o>-</span> <span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=nl>#2</span>   <span class=cm>/* list iteration */</span>
</span></span><span class=line><span class=cl>  <span class=mi>9</span>   <span class=n>CalculationNode</span>     <span class=n>COOR</span>     <span class=mi>3</span>       <span class=o>-</span> <span class=kd>LET</span> <span class=nl>#4</span> <span class=o>=</span> <span class=n>MAKE_DISTRIBUTE_INPUT_WITH_KEY_CREATION</span><span class=p>(</span><span class=n>doc</span><span class=p>,</span> <span class=kc>null</span><span class=p>,</span> <span class=p>{</span> <span class=s2>&#34;allowSpecifiedKeys&#34;</span> <span class=o>:</span> <span class=kc>false</span><span class=p>,</span> <span class=s2>&#34;ignoreErrors&#34;</span> <span class=o>:</span> <span class=kc>false</span><span class=p>,</span> <span class=s2>&#34;collection&#34;</span> <span class=o>:</span> <span class=s2>&#34;collection&#34;</span> <span class=p>})</span>   <span class=cm>/* simple expression */</span>
</span></span><span class=line><span class=cl>  <span class=mi>5</span>   <span class=n>DistributeNode</span>      <span class=n>COOR</span>     <span class=mi>3</span>       <span class=o>-</span> <span class=n>DISTRIBUTE</span> <span class=nl>#4</span>
</span></span><span class=line><span class=cl>  <span class=mi>6</span>   <span class=n>RemoteNode</span>          <span class=n>DBS</span>      <span class=mi>3</span>       <span class=o>-</span> <span class=n>REMOTE</span>
</span></span><span class=line><span class=cl>  <span class=mi>4</span>   <span class=n>InsertNode</span>          <span class=n>DBS</span>      <span class=mi>0</span>       <span class=o>-</span> <span class=kr>INSERT</span> <span class=nl>#4</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>  <span class=mi>7</span>   <span class=n>RemoteNode</span>          <span class=n>COOR</span>     <span class=mi>0</span>       <span class=o>-</span> <span class=n>REMOTE</span>
</span></span><span class=line><span class=cl>  <span class=mi>8</span>   <span class=n>GatherNode</span>          <span class=n>COOR</span>     <span class=mi>0</span>       <span class=o>-</span> <span class=n>GATHER</span>   <span class=cm>/* parallel, unsorted */</span></span></span></code></pre></div><p>The new <code>optimize-cluster-multiple-document-operations</code> optimizer rule that
enables the optimization is only applied if there is no <code>RETURN</code> operation,
which means you cannot use <code>RETURN NEW</code> or similar to access the new documents
including their document keys. Additionally, all preceding calculations must be
constant, which excludes any subqueries that read documents.</p><p>See the list of <a href=/3.11/aql/execution-and-performance/query-optimization/#optimizer-rules class=link>optimizer rules</a>
for details.</p><h3 id=index-cache-refilling>Index cache refilling <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#index-cache-refilling class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The <a href=/3.11/release-notes/version-3.10/whats-new-in-3-10/#edge-cache-refilling-experimental class=link>edge cache refilling</a>
feature introduced in v3.9.6 and v3.10.2 is no longer experimental. From v3.11.0
onward, it is called <em><strong>index</strong> cache refilling</em> and is not limited to edge caches
anymore, but also supports in-memory hash caches of persistent indexes
(persistent indexes with the <code>cacheEnabled</code> option set to <code>true</code>).</p><p>This new feature automatically refills the in-memory index caches.
When documents (including edges) are added, modified, or removed and if this
affects an edge index or cache-enabled persistent indexes, these changes are
tracked and a background thread tries to update the index caches accordingly if
the feature is enabled, by adding new, updating existing, or deleting and
refilling cache entries.</p><p>You can enable it for individual <code>INSERT</code>, <code>UPDATE</code>, <code>REPLACE</code>, and <code>REMOVE</code>
operations in AQL queries (using <code>OPTIONS { refillIndexCaches: true }</code>), for
individual document API requests that insert, update, replace, or remove single
or multiple documents (by setting <code>refillIndexCaches=true</code> as query
parameter), as well as enable it by default using the new
<code>--rocksdb.auto-refill-index-caches-on-modify</code> startup option.</p><p>The new <code>--rocksdb.auto-refill-index-caches-queue-capacity</code> startup option
restricts how many index cache entries the background thread can queue at most.
This limits the memory usage for the case of the background thread being slower
than other operations that invalidate index cache entries.</p><p>The background refilling is done on a best-effort basis and not guaranteed to
succeed, for example, if there is no memory available for the cache subsystem,
or during cache grow/shrink operations. A background thread is used so that
foreground write operations are not slowed down by a lot. It may still cause
additional I/O activity to look up data from the storage engine to repopulate
the cache.</p><p>In addition to refilling the index caches, the caches can also automatically be
seeded on server startup. Use the new <code>--rocksdb.auto-fill-index-caches-on-startup</code>
startup option to enable this feature. It may cause additional CPU and I/O load.
You can limit how many index filling operations can execute concurrently with the
<code>--rocksdb.max-concurrent-index-fill-tasks</code> option. The lower this number, the
lower the impact of the cache filling, but the longer it takes to complete.</p><p>The following metrics are available:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>rocksdb_cache_auto_refill_loaded_total</code></td><td style=text-align:left>Total number of queued items for in-memory index caches refilling.</td></tr><tr><td style=text-align:left><code>rocksdb_cache_auto_refill_dropped_total</code></td><td style=text-align:left>Total number of dropped items for in-memory index caches refilling.</td></tr><tr><td style=text-align:left><code>rocksdb_cache_full_index_refills_total</code></td><td style=text-align:left>Total number of in-memory index caches refill operations for entire indexes.</td></tr></tbody></table><p>This feature is experimental.</p><p>Also see:</p><ul><li><a href=/3.11/aql/high-level-operations/insert/#refillindexcaches class=link>AQL <code>INSERT</code> operation</a></li><li><a href=/3.11/aql/high-level-operations/update/#refillindexcaches class=link>AQL <code>UPDATE</code> operation</a></li><li><a href=/3.11/aql/high-level-operations/replace/#refillindexcaches class=link>AQL <code>REPLACE</code> operation</a></li><li><a href=/3.11/aql/high-level-operations/remove/#refillindexcaches class=link>AQL <code>REMOVE</code> operation</a></li><li><a href=/3.11/develop/http-api/documents/ class=link>Document HTTP API</a></li><li><a href=#index-cache-refill-options class=link>Index cache refill options</a></li></ul><h3 id=retry-request-for-result-batch>Retry request for result batch <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#retry-request-for-result-batch class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>You can retry the request for the latest result batch of an AQL query cursor if
you enable the new <code>allowRetry</code> query option. See
<a href=/3.11/release-notes/version-3.11/api-changes-in-3-11/#cursor-api class=link>API Changes in ArangoDB 3.11</a>
for details.</p><h3 id=collect--into-can-use-hash-method><code>COLLECT ... INTO</code> can use <code>hash</code> method <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#collect--into-can-use-hash-method class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Grouping with the <code>COLLECT</code> operation supports two different methods, <code>hash</code> and
<code>sorted</code>. For <code>COLLECT</code> operations with an <code>INTO</code> clause, only the <code>sorted</code> method
was previously supported, but the <code>hash</code> variant has been extended to now support
<code>INTO</code> clauses as well.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>i</span> <span class=kr>IN</span> <span class=mf>1</span><span class=o>..</span><span class=mi>10</span>
</span></span><span class=line><span class=cl>  <span class=kr>COLLECT</span> <span class=n>v</span> <span class=o>=</span> <span class=n>i</span> <span class=o>%</span> <span class=mi>2</span> <span class=kr>INTO</span> <span class=n>group</span> <span class=c1>// OPTIONS { method: &#34;hash&#34; }
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=kr>SORT</span> <span class=kc>null</span>
</span></span><span class=line><span class=cl>  <span class=kr>RETURN</span> <span class=p>{</span> <span class=n>v</span><span class=p>,</span> <span class=n>group</span> <span class=p>}</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=n>Execution</span> <span class=n>plan</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Id</span>   <span class=n>NodeType</span>            <span class=n>Est</span><span class=p>.</span>   <span class=n>Comment</span>
</span></span><span class=line><span class=cl>  <span class=mi>1</span>   <span class=n>SingletonNode</span>          <span class=mi>1</span>   <span class=o>*</span> <span class=n>ROOT</span>
</span></span><span class=line><span class=cl>  <span class=mi>2</span>   <span class=n>CalculationNode</span>        <span class=mi>1</span>     <span class=o>-</span> <span class=kd>LET</span> <span class=nl>#3</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>..</span> <span class=mi>10</span>   <span class=cm>/* range */</span>   <span class=cm>/* simple expression */</span>
</span></span><span class=line><span class=cl>  <span class=mi>3</span>   <span class=n>EnumerateListNode</span>     <span class=mi>10</span>     <span class=o>-</span> <span class=kr>FOR</span> <span class=n>i</span> <span class=kr>IN</span> <span class=nl>#3</span>   <span class=cm>/* list iteration */</span>
</span></span><span class=line><span class=cl>  <span class=mi>4</span>   <span class=n>CalculationNode</span>       <span class=mi>10</span>       <span class=o>-</span> <span class=kd>LET</span> <span class=nl>#5</span> <span class=o>=</span> <span class=p>(</span><span class=n>i</span> <span class=o>%</span> <span class=mi>2</span><span class=p>)</span>   <span class=cm>/* simple expression */</span>
</span></span><span class=line><span class=cl>  <span class=mi>5</span>   <span class=n>CollectNode</span>            <span class=mi>8</span>       <span class=o>-</span> <span class=kr>COLLECT</span> <span class=n>v</span> <span class=o>=</span> <span class=nl>#5</span> <span class=kr>INTO</span> <span class=n>group</span> <span class=kp>KEEP</span> <span class=n>i</span>   <span class=cm>/* hash */</span>
</span></span><span class=line><span class=cl>  <span class=mi>8</span>   <span class=n>CalculationNode</span>        <span class=mi>8</span>       <span class=o>-</span> <span class=kd>LET</span> <span class=nl>#9</span> <span class=o>=</span> <span class=p>{</span> <span class=s2>&#34;v&#34;</span> <span class=o>:</span> <span class=n>v</span><span class=p>,</span> <span class=s2>&#34;group&#34;</span> <span class=o>:</span> <span class=n>group</span> <span class=p>}</span>   <span class=cm>/* simple expression */</span>
</span></span><span class=line><span class=cl>  <span class=mi>9</span>   <span class=n>ReturnNode</span>             <span class=mi>8</span>       <span class=o>-</span> <span class=kr>RETURN</span> <span class=nl>#9</span></span></span></code></pre></div><p>The query optimizer automatically chooses the <code>hash</code> method for the above
example query, but you can also specify your preferred method explicitly.</p><p>See the <a href=/3.11/aql/high-level-operations/collect/#method class=link><code>COLLECT</code> options</a> for details.</p><h3 id=k_shortest_paths-performance-improvements>K_SHORTEST_PATHS performance improvements <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#k_shortest_paths-performance-improvements class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The <code>K_SHORTEST_PATHS</code> graph algorithm in AQL has been refactored in ArangoDB 3.11,
resulting in major performance improvements. The query now returns the
shortest paths between two documents in a graph up to 100 times faster.</p><h3 id=added-aql-functions>Added AQL functions <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#added-aql-functions class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Added the <code>DATE_ISOWEEKYEAR()</code> function that returns the ISO week number,
like <code>DATE_ISOWEEK()</code> does, but also the year it belongs to:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>RETURN</span> <span class=nf>DATE_ISOWEEKYEAR</span><span class=p>(</span><span class=s2>&#34;2023-01-01&#34;</span><span class=p>)</span> <span class=c1>// { &#34;week&#34;: 52, &#34;year&#34;: 2022 }
</span></span></span></code></pre></div><p>See <a href=/3.11/aql/functions/date/#date_isoweekyear class=link>AQL Date functions</a> for details.</p><hr><p>Added the <code>SHA256()</code> function that calculates the SHA256 checksum for a string
and returns it in a hexadecimal string representation.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>RETURN</span> <span class=nf>SHA256</span><span class=p>(</span><span class=s2>&#34;ArangoDB&#34;</span><span class=p>)</span> <span class=c1>// &#34;acbd84398a61fcc6fd784f7e16c32e02a0087fd5d631421bf7b5ede5db7fda31&#34;
</span></span></span></code></pre></div><p>See <a href=/3.11/aql/functions/string/#sha256 class=link>AQL String functions</a> for details.</p><h3 id=extended-query-explain-statistics>Extended query explain statistics <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#extended-query-explain-statistics class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.4</small></p><p>The query explain result now includes the peak memory usage and execution time.
This helps finding queries that use a lot of memory or take long to build the
execution plan.</p><p>The additional statistics are displayed at the end of the output in the
web interface (using the <strong>Explain</strong> button in the <strong>QUERIES</strong> section) and in
<em>arangosh</em> (using <code>db._explain()</code>):</p><pre tabindex=0><code>44 rule(s) executed, 1 plan(s) created, peak mem [b]: 32768, exec time [s]: 0.00214
</code></pre><p>The HTTP API returns the extended statistics in the <code>stats</code> attribute when you
use the <code>POST /_api/explain</code> endpoint:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=err>...</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;stats&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;rulesExecuted&#34;</span><span class=p>:</span> <span class=mi>44</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;rulesSkipped&#34;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;plansCreated&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;peakMemoryUsage&#34;</span><span class=p>:</span> <span class=mi>32768</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;executionTime&#34;</span><span class=p>:</span> <span class=mf>0.00241307167840004</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Also see:</p><ul><li><a href=/3.11/release-notes/version-3.11/api-changes-in-3-11/#explain-api class=link>API Changes in ArangoDB 3.11</a></li><li><a href=/3.11/aql/execution-and-performance/query-optimization/#optimizer-statistics class=link>The AQL query optimizer</a></li></ul><h3 id=extended-peak-memory-usage-reporting>Extended peak memory usage reporting <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#extended-peak-memory-usage-reporting class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The peak memory usage of AQL queries is now also reported for running queries
and slow queries.</p><p>In the web interface, you can find the <strong>Peak memory usage</strong> column in the
<strong>QUERIES</strong> section, in the <strong>Running Queries</strong> and <strong>Slow Query History</strong> tabs.</p><p>In the JavaScript and HTTP APIs, the value is reported as <code>peakMemoryUsage</code>.
See <a href=/3.11/release-notes/version-3.11/api-changes-in-3-11/#query-api class=link>API Changes in ArangoDB 3.11</a>.</p><h3 id=number-of-cluster-requests-in-profiling-output>Number of cluster requests in profiling output <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#number-of-cluster-requests-in-profiling-output class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.5, v3.10.2</small></p><p>The query profiling output in the web interface and <em>arangosh</em> now shows the
number of HTTP requests for queries that you run against cluster deployments in
the <code>Query Statistics</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=n>Query</span> <span class=n>String</span> <span class=p>(</span><span class=mi>33</span> <span class=n>chars</span><span class=p>,</span> <span class=n>cacheable</span><span class=o>:</span> <span class=kc>false</span><span class=p>)</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>coll</span>
</span></span><span class=line><span class=cl>   <span class=kr>RETURN</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Execution</span> <span class=n>plan</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Id</span>   <span class=n>NodeType</span>          <span class=n>Site</span>  <span class=n>Calls</span>   <span class=n>Items</span>   <span class=n>Filtered</span>   <span class=n>Runtime</span> <span class=p>[</span><span class=n>s</span><span class=p>]</span>   <span class=n>Comment</span>
</span></span><span class=line><span class=cl>  <span class=mi>1</span>   <span class=n>SingletonNode</span>     <span class=n>DBS</span>       <span class=mi>3</span>       <span class=mi>3</span>          <span class=mi>0</span>       <span class=mf>0.00024</span>   <span class=o>*</span> <span class=n>ROOT</span>
</span></span><span class=line><span class=cl>  <span class=mi>9</span>   <span class=n>IndexNode</span>         <span class=n>DBS</span>       <span class=mi>3</span>       <span class=mi>0</span>          <span class=mi>0</span>       <span class=mf>0.00060</span>     <span class=o>-</span> <span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>coll</span>   <span class=cm>/* primary index scan, index only (projections: `_key`), 3 shard(s) */</span>
</span></span><span class=line><span class=cl>  <span class=mi>3</span>   <span class=n>CalculationNode</span>   <span class=n>DBS</span>       <span class=mi>3</span>       <span class=mi>0</span>          <span class=mi>0</span>       <span class=mf>0.00025</span>       <span class=o>-</span> <span class=kd>LET</span> <span class=nl>#1</span> <span class=o>=</span> <span class=n>doc</span><span class=p>.</span><span class=n>`_key`</span>   <span class=cm>/* attribute expression */</span>   <span class=cm>/* collections used: doc : coll */</span>
</span></span><span class=line><span class=cl>  <span class=mi>7</span>   <span class=n>RemoteNode</span>        <span class=n>COOR</span>      <span class=mi>6</span>       <span class=mi>0</span>          <span class=mi>0</span>       <span class=mf>0.00227</span>       <span class=o>-</span> <span class=n>REMOTE</span>
</span></span><span class=line><span class=cl>  <span class=mi>8</span>   <span class=n>GatherNode</span>        <span class=n>COOR</span>      <span class=mi>2</span>       <span class=mi>0</span>          <span class=mi>0</span>       <span class=mf>0.00209</span>       <span class=o>-</span> <span class=n>GATHER</span>   <span class=cm>/* parallel, unsorted */</span>
</span></span><span class=line><span class=cl>  <span class=mi>4</span>   <span class=n>ReturnNode</span>        <span class=n>COOR</span>      <span class=mi>2</span>       <span class=mi>0</span>          <span class=mi>0</span>       <span class=mf>0.00008</span>       <span class=o>-</span> <span class=kr>RETURN</span> <span class=nl>#1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Indexes</span> <span class=n>used</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>By</span>   <span class=n>Name</span>      <span class=n>Type</span>      <span class=n>Collection</span>   <span class=n>Unique</span>   <span class=n>Sparse</span>   <span class=n>Cache</span>   <span class=n>Selectivity</span>   <span class=n>Fields</span>       <span class=n>Stored</span> <span class=n>values</span>   <span class=n>Ranges</span>
</span></span><span class=line><span class=cl>  <span class=mi>9</span>   <span class=n>primary</span>   <span class=n>primary</span>   <span class=n>coll</span>         <span class=kc>true</span>     <span class=kc>false</span>    <span class=kc>false</span>      <span class=mi>10</span><span class=mf>0.00</span> <span class=o>%</span>   <span class=p>[</span> <span class=n>`_key`</span> <span class=p>]</span>   <span class=p>[</span>  <span class=p>]</span>            <span class=o>*</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Optimization</span> <span class=n>rules</span> <span class=n>applied</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Id</span>   <span class=n>RuleName</span>
</span></span><span class=line><span class=cl>  <span class=mi>1</span>   <span class=n>scatter</span><span class=o>-</span><span class=kr>in</span><span class=o>-</span><span class=n>cluster</span>
</span></span><span class=line><span class=cl>  <span class=mi>2</span>   <span class=n>distribute</span><span class=o>-</span><span class=n>filtercalc</span><span class=o>-</span><span class=kp>to</span><span class=o>-</span><span class=n>cluster</span>
</span></span><span class=line><span class=cl>  <span class=mi>3</span>   <span class=kr>remove</span><span class=o>-</span><span class=n>unnecessary</span><span class=o>-</span><span class=n>remote</span><span class=o>-</span><span class=n>scatter</span>
</span></span><span class=line><span class=cl>  <span class=mi>4</span>   <span class=n>reduce</span><span class=o>-</span><span class=n>extraction</span><span class=o>-</span><span class=kp>to</span><span class=o>-</span><span class=n>projection</span>
</span></span><span class=line><span class=cl>  <span class=mi>5</span>   <span class=n>parallelize</span><span class=o>-</span><span class=n>gather</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>Query</span> <span class=n>Statistics</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Writes</span> <span class=n>Exec</span>   <span class=n>Writes</span> <span class=n>Ign</span>   <span class=n>Scan</span> <span class=n>Full</span>   <span class=n>Scan</span> <span class=n>Index</span>   <span class=n>Cache</span> <span class=n>Hits</span><span class=o>/</span><span class=n>Misses</span>   <span class=n>Filtered</span>   <span class=n>Requests</span>   <span class=n>Peak</span> <span class=n>Mem</span> <span class=p>[</span><span class=n>b</span><span class=p>]</span>   <span class=n>Exec</span> <span class=n>Time</span> <span class=p>[</span><span class=n>s</span><span class=p>]</span>
</span></span><span class=line><span class=cl>           <span class=mi>0</span>            <span class=mi>0</span>           <span class=mi>0</span>            <span class=mi>0</span>               <span class=mi>0</span> <span class=o>/</span> <span class=mi>0</span>          <span class=mi>0</span>          <span class=mi>9</span>          <span class=mi>32768</span>         <span class=mf>0.00564</span></span></span></code></pre></div><h3 id=new-stage-in-query-profiling-output>New stage in query profiling output <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#new-stage-in-query-profiling-output class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.3</small></p><p>The query profiling output has a new <code>instantiating executors</code> stage.
The time spent in this stage is the time needed to create the query executors
from the final query execution time. In cluster mode, this stage also includes
the time needed for physically distributing the query snippets to the
participating DB-Servers. Previously, the time spent for instantiating executors
and the physical distribution was contained in the <code>optimizing plan</code> stage.</p><pre tabindex=0><code>Query Profile:
 Query Stage               Duration [s]
 initializing                   0.00001
 parsing                        0.00009
 optimizing ast                 0.00001
 loading collections            0.00001
 instantiating plan             0.00004
 optimizing plan                0.00088
 instantiating executors        0.00153
 executing                      1.27349
 finalizing                     0.00091
</code></pre><h3 id=limit-for-the-normalization-of-filter-conditions>Limit for the normalization of <code>FILTER</code> conditions <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#limit-for-the-normalization-of-filter-conditions class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Converting complex AQL <code>FILTER</code> conditions with a lot of logical branches
(<code>AND</code>, <code>OR</code>, <code>NOT</code>) into the internal DNF (disjunctive normal form) format can
take a large amount of processing time and memory. The new <code>maxDNFConditionMembers</code>
query option is a threshold for the maximum number of <code>OR</code> sub-nodes in the
internal representation and defaults to <code>786432</code>.</p><p>You can also set the threshold globally instead of per query with the
<a href=/3.11/components/arangodb-server/options/#--querymax-dnf-condition-members class=link><code>--query.max-dnf-condition-members</code> startup option</a>.</p><p>If the threshold is hit, the query continues with a simplified representation of
the condition, which is <strong>not usable in index lookups</strong>. However, this should
still be better than overusing memory or taking a very long time to compute the
DNF version.</p><h2 id=server-options>Server options <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#server-options class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=telemetrics>Telemetrics <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#telemetrics class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Starting with version 3.11, ArangoDB automatically gathers information on how
it is used and the features being utilized. This data is used to identify the
primary usage patterns and features, and to measure their adoption rate.</p><p>The information collected by ArangoDB is anonymous and purely statistical.
It does not contain any personal information like usernames or IP addresses, nor
any content of the documents stored in ArangoDB. This means that your privacy is
protected, and that there is no risk of your data being compromised.</p><p>If for any reason you prefer not to share usage statistics with ArangoDB, you
can easily disable this feature by setting the new <code>--server.telemetrics-api</code>
startup option to <code>false</code>. The default value is <code>true</code>.</p><p>For a detailed list of what anonymous metrics ArangoDB collects see
<a href=/3.11/operations/administration/telemetrics/ class=link>Telemetrics</a>.</p><h3 id=extended-naming-constraints-for-collections-views-and-indexes>Extended naming constraints for collections, Views, and indexes <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#extended-naming-constraints-for-collections-views-and-indexes class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>In ArangoDB 3.9, the <code>--database.extended-names-databases</code> startup option was
added to optionally allow database names to contain most UTF-8 characters.
The startup option has been renamed to <code>--database.extended-names</code> in 3.11 and
now controls whether you want to use the extended naming constraints for
database, collection, View, and index names.</p><p>This feature is <strong>experimental</strong> in ArangoDB 3.11, but will become the norm in
a future version.</p><p>Running the server with the option enabled provides support for extended names
that are not comprised within the ASCII table, such as Japanese or Arabic
letters, emojis, letters with accentuation. Also, many ASCII characters that
were formerly banned by the traditional naming constraints are now accepted.</p><p>Example collection, View, and index names that can be used with the new extended
constraints: <code>España</code>, <code>😀</code>, <code>犬</code>, <code>كلب</code>, <code>@abc123</code>, <code>København</code>, <code>München</code>,
<code>Бишкек</code>, <code>abc? &lt;> 123!</code></p><p>Using extended collection and View names in the JavaScript API such as in
<em>arangosh</em> or Foxx may require using the square bracket notation instead of the
dot notation for property access depending on the characters you use:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=nx>_create</span><span class=p>(</span><span class=s2>&#34;🥑~колекція =)&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=err>🥑</span><span class=o>~</span><span class=nx>колекція</span> <span class=o>=</span><span class=p>).</span><span class=nx>properties</span><span class=p>();</span>   <span class=c1>// dot notation (syntax error)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nx>db</span><span class=p>[</span><span class=s2>&#34;🥑~колекція =)&#34;</span><span class=p>].</span><span class=nx>properties</span><span class=p>()</span> <span class=c1>// square bracket notation
</span></span></span></code></pre></div><p>Using extended collection and View names in AQL queries requires wrapping the
name in backticks or forward ticks (see <a href=/3.11/aql/fundamentals/syntax/#names class=link>AQL Syntax</a>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>`🥑~колекція =)`</span>
</span></span><span class=line><span class=cl>  <span class=kr>RETURN</span> <span class=n>doc</span></span></span></code></pre></div><p>When using extended names, any Unicode characters in names need to be
<a href=http://unicode.org/reports/tr15/#Norm_Forms target=_blank rel="noopener noreferrer" class=link>NFC-normalized</a>&nbsp;<i class="fas fa-external-link-alt"></i>.
If you try to create a database, collection, View, or index with a non-NFC-normalized
name, the server rejects it.</p><p>The ArangoDB web interface as well as the <em>arangobench</em>, <em>arangodump</em>,
<em>arangoexport</em>, <em>arangoimport</em>, <em>arangorestore</em>, and <em>arangosh</em> client tools
ship with support for the extended naming constraints, but they require you
to provide NFC-normalized names.</p><p>Note that the default value for <code>--database.extended-names</code> is <code>false</code>
for compatibility with existing client drivers and applications that only support
ASCII names according to the traditional naming constraints used in previous
ArangoDB versions. Enabling the feature may lead to incompatibilities up to the
ArangoDB instance becoming inaccessible for such drivers and client applications.</p><p>Please be aware that dumps containing extended names cannot be restored
into older versions that only support the traditional naming constraints. In a
cluster setup, it is required to use the same naming constraints for all
Coordinators and DB-Servers of the cluster. Otherwise, the startup is
refused. In DC2DC setups, it is also required to use the same naming constraints
for both datacenters to avoid incompatibilities.</p><p>Also see:</p><ul><li><a href=/3.11/concepts/data-structure/collections/#collection-names class=link>Collection names</a></li><li><a href=/3.11/concepts/data-structure/views/#view-names class=link>View names</a></li><li>Index names have the same character restrictions as collection names</li></ul><h3 id=verify-sst-files>Verify <code>.sst</code> files <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#verify-sst-files class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The new <code>--rocksdb.verify-sst</code> startup option lets you validate the <code>.sst</code> files
currently contained in the database directory on startup. If set to <code>true</code>,
on startup, all SST files in the <code>engine-rocksdb</code> folder in the database
directory are validated, then the process finishes execution.
The default value is <code>false</code>.</p><h3 id=support-for-additional-value-suffixes>Support for additional value suffixes <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#support-for-additional-value-suffixes class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Numeric startup options support suffixes like <code>m</code> (megabytes) and <code>GiB</code> (gibibytes)
to make it easier to specify values that are expected in bytes. The following
suffixes are now also supported:</p><ul><li><code>tib</code>, <code>TiB</code>, <code>TIB</code>: tebibytes (factor 1024<sup>4</sup>)</li><li><code>t</code>, <code>tb</code>, <code>T</code>, <code>TB</code>: terabytes (factor 1000<sup>4</sup>)</li><li><code>b</code>, <code>B</code>: bytes (factor 1)</li></ul><p>Example: <code>arangod --rocksdb.total-write-buffer-size 2TiB</code></p><p>See <a href=/3.11/operations/administration/configuration/#suffixes-for-numeric-options class=link>Suffixes for numeric options</a>
for details.</p><h3 id=configurable-status-code-if-write-concern-not-fulfilled>Configurable status code if write concern not fulfilled <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#configurable-status-code-if-write-concern-not-fulfilled class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>In cluster deployments, you can use a replication factor greater than <code>1</code> for
collections. This creates additional shard replicas for redundancy. For write
operations to these collections, you can define how many replicas need to
acknowledge the write for the operation to succeed. This option is called the
write concern. If there are not enough in-sync replicas available, the
write concern cannot be fulfilled. An error with the HTTP <code>403 Forbidden</code>
status code is returned immediately in this case.</p><p>You can now change the status code via the new
<code>--cluster.failed-write-concern-status-code</code> startup option. It defaults to <code>403</code>
but you can set it to <code>503</code> to use an HTTP <code>503 Service Unavailable</code> status code
instead. This signals client applications that it is a temporary error.</p><p>Note that no automatic retry of the operation is attempted by the cluster if you
set the startup option to <code>503</code>. It only changes the status code to one that
doesn&rsquo;t signal a permanent error like <code>403</code> does.
It is up to client applications to retry the operation.</p><h3 id=rocksdb-blob-storage-experimental>RocksDB BLOB storage (experimental) <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#rocksdb-blob-storage-experimental class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>From version 3.11 onward, ArangoDB can make use of RocksDB&rsquo;s integrated BLOB
(binary large object) storage for larger documents, called <em>BlobDB</em>.
This is currently an experimental feature, not supported and should not be used in production.</p><p><a href=https://rocksdb.org/blog/2021/05/26/integrated-blob-db.html target=_blank rel="noopener noreferrer" class=link>BlobDB is an integral part of RocksDB</a>&nbsp;<i class="fas fa-external-link-alt"></i>
and provides a key-value separation: large values are stored in dedicated BLOB
files, and only a small pointer to them is stored in the LSM tree&rsquo;s SST files.
Storing values separate from the keys means that the values do no need to be moved
through the LSM tree by the compaction. This reduces write amplification and is
especially beneficial for large values.</p><p>When the option is enabled in ArangoDB, the key-value separation is used for
the documents column family, because large values are mostly to be expected here.
The cutoff value for the key-value separation is configurable by a startup option,
i.e. the administrator can set a size limit for values from which onwards they
are offloaded to separate BLOB files. This allows storing small documents
inline with the keys as before, but still benefit from reduced write amplification
for larger documents.</p><p>BlobDB is disabled by default in ArangoDB 3.11.
Using BlobDB in ArangoDB is experimental and not recommended in production. It is
made available as an experimental feature so that further tests and tuning can be
done by interested parties. Future versions of ArangoDB may declare the feature
production-ready and even enable BlobDB by default.</p><p>There are currently a few caveats when using BlobDB in ArangoDB:</p><ul><li>Even though BlobDB can help reduce the write amplification, it may increase the
read amplification and may worsen the read performance for some workloads.</li><li>The various tuning parameters that BlobDB offers are made available in ArangoDB,
but the current default settings for the BlobDB tuning options are not ideal
for many use cases and need to be adjusted by administrators first.</li><li>It is very likely that the default settings for the BlobDB tuning options will
change in future versions of ArangoDB.</li><li>Memory and disk usage patterns are different to that of versions running without
BlobDB enabled. It is very likely that memory limits and disk capacity may
need to be adjusted.</li><li>Some metrics for observing RocksDB do not react properly when BlobDB is in use.</li><li>The built-in throttling mechanism for controlling the write-throughput
slows down writes too much when BlobDB is used. This can be circumvented with
tuning parameters, but the defaults may be too aggressive.</li></ul><p>The following experimental startup options have been added in ArangoDB 3.11 to
enable and configure BlobDB:</p><ul><li><code>--rocksdb.enable-blob-files</code>: Enable the usage of BLOB files for the
documents column family. This option defaults to <code>false</code>. All following
options are only relevant if this option is set to <code>true</code>.</li><li><code>--rocksdb.min-blob-size</code>: Size threshold for storing large documents in
BLOB files (in bytes, 0 = store all documents in BLOB files).</li><li><code>--rocksdb.blob-file-size</code>: Size limit for BLOB files in the documents
column family (in bytes). Note that RocksDB counts the size of uncompressed
BLOBs before checking if a new BLOB file needs to be started, even though
the BLOB may be compressed and end up much smaller than uncompressed.</li><li><code>--rocksdb.blob-compression-type</code>: Compression algorithm to use for BLOB
data in the documents column family.</li><li><code>--rocksdb.enable-blob-garbage-collection</code>: Enable BLOB garbage collection
during compaction in the documents column family.</li><li><code>--rocksdb.blob-garbage-collection-age-cutoff</code>: Age cutoff for garbage
collecting BLOB files in the documents column family (percentage value from
0 to 1 determines how many BLOB files are garbage collected during
compaction).</li><li><code>--rocksdb.blob-garbage-collection-force-threshold</code>: Garbage ratio
threshold for scheduling targeted compactions for the oldest BLOB files
in the documents column family.</li></ul><p>Note that ArangoDB&rsquo;s built-in throttling mechanism that automatically adjusts
the write rate for RocksDB may need to be reconfigured as well to see the
benefits of BlobDB. The relevant startup options for the throttle are:</p><ul><li><code>--rocksdb.throttle-lower-bound-bps</code></li><li><code>--rocksdb.throttle-max-write-rate</code></li><li><code>--rocksdb.throttle-slow-down-writes-trigger</code></li></ul><h3 id=--querymax-dnf-condition-members-option><code>--query.max-dnf-condition-members</code> option <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#--querymax-dnf-condition-members-option class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>See <a href=#limit-for-the-normalization-of-filter-conditions class=link>Limit for the normalization of <code>FILTER</code> conditions</a>.</p><h3 id=--rocksdbreserve-file-metadata-memory-option><code>--rocksdb.reserve-file-metadata-memory</code> option <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#--rocksdbreserve-file-metadata-memory-option class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>This new startup option controls whether to account for <code>.sst</code> file metadata
memory in the block cache.</p><h3 id=arangosearch-column-cache-limit>ArangoSearch column cache limit <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#arangosearch-column-cache-limit class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.5, v3.10.2</small></p><p>The new <code>--arangosearch.columns-cache-limit</code> startup option lets you control how
much memory (in bytes) the <a href=#arangosearch-column-cache-enterprise-edition class=link>ArangoSearch column cache</a>
is allowed to use.</p><p><small>Introduced in: v3.10.6</small></p><p>You can reduce the memory usage of the column cache in cluster deployments by
only using the cache for leader shards with the new
<a href=/3.11/components/arangodb-server/options/#--arangosearchcolumns-cache-only-leader class=link><code>--arangosearch.columns-cache-only-leader</code> startup option</a>.
It is disabled by default, which means followers also maintain a column cache.</p><h3 id=aql-query-logging>AQL query logging <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#aql-query-logging class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.5, v3.10.2</small></p><p>There are three new startup options to configure how AQL queries are logged:</p><ul><li><code>--query.log-failed</code> for logging all failed AQL queries, to be used during
development or to catch unexpected failed queries in production (off by default)</li><li><code>--query.log-memory-usage-threshold</code> to define a peak memory threshold from
which on a warning is logged for AQL queries that exceed it (default: 4 GB)</li><li><code>--query.max-artifact-log-length</code> for controlling the length of logged query
strings and bind parameter values. Both are truncated to 4096 bytes by default.</li></ul><h3 id=index-cache-refill-options>Index cache refill options <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#index-cache-refill-options class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.6, v3.10.2</small></p><ul><li><code>--rocksdb.auto-refill-index-caches-on-modify</code>: Whether to automatically
(re-)fill in-memory index cache entries on insert/update/replace operations
by default. Default: <code>false</code>.</li><li><code>--rocksdb.auto-refill-index-caches-queue-capacity</code>: How many changes can be
queued at most for automatically refilling the index cache. Default: <code>131072</code>.</li><li><code>--rocksdb.auto-fill-index-caches-on-startup</code>: Whether to automatically fill
the in-memory index cache with entries on server startup. Default: <code>false</code>.</li><li><code>--rocksdb.max-concurrent-index-fill-tasks</code>: The maximum number of index fill
tasks that can run concurrently on server startup. Default: the number of
cores divided by 8, but at least <code>1</code>.</li></ul><hr><p><small>Introduced in: v3.9.10, v3.10.5</small></p><ul><li><code>--rocksdb.auto-refill-index-caches-on-followers</code>: Control whether automatic
refilling of in-memory caches should happen on followers or only leaders.
The default value is <code>true</code>, i.e. refilling happens on followers, too.</li></ul><h3 id=cluster-supervision-options>Cluster supervision options <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#cluster-supervision-options class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.6, v3.10.2</small></p><p>The following new options allow you to delay supervision actions for a
configurable amount of time. This is desirable in case DB-Servers are restarted
or fail and come back quickly because it gives the cluster a chance to get in
sync and fully resilient without deploying additional shard replicas and thus
without causing any data imbalance:</p><ul><li><p><code>--agency.supervision-delay-add-follower</code>:
The delay in supervision, before an AddFollower job is executed (in seconds).</p></li><li><p><code>--agency.supervision-delay-failed-follower</code>:
The delay in supervision, before a FailedFollower job is executed (in seconds).</p></li></ul><p><small>Introduced in: v3.9.7, v3.10.2</small></p><p>A <code>--agency.supervision-failed-leader-adds-follower</code> startup option has been
added with a default of <code>true</code> (behavior as before). If you set this option to
<code>false</code>, a <code>FailedLeader</code> job does not automatically configure a new shard
follower, thereby preventing unnecessary network traffic, CPU load, and I/O load
for the case that the server comes back quickly. If the server has permanently
failed, an <code>AddFollower</code> job is created anyway eventually, as governed by the
<code>--agency.supervision-delay-add-follower</code> option.</p><h3 id=rocksdb-bloom-filter-option>RocksDB Bloom filter option <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#rocksdb-bloom-filter-option class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.3</small></p><p>A new <code>--rocksdb.bloom-filter-bits-per-key</code> startup option has been added to
configure the number of bits to use per key in a Bloom filter.</p><p>The default value is <code>10</code>, which is downwards-compatible to the previously
hard-coded value.</p><h3 id=disable-user-defined-aql-functions>Disable user-defined AQL functions <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#disable-user-defined-aql-functions class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.4</small></p><p>The new <code>--javascript.user-defined-functions</code> startup option lets you disable
user-defined AQL functions so that no user-defined JavaScript code of
<a href=/3.11/aql/user-defined-functions/ class=link>UDFs</a> runs on the server. This can be useful to close off
a potential attack vector in case no user-defined AQL functions are used.
Also see <a href=/3.11/operations/security/security-options/ class=link>Server security options</a>.</p><h3 id=option-to-disable-foxx>Option to disable Foxx <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#option-to-disable-foxx class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.5</small></p><p>A <code>--foxx.enable</code> startup option has been added to let you configure whether
access to user-defined Foxx services is possible for the instance. It defaults
to <code>true</code>.</p><p>If you set the option to <code>false</code>, access to Foxx services is forbidden and is
responded with an HTTP <code>403 Forbidden</code> error. Access to the management APIs for
Foxx services are also disabled as if you set <code>--foxx.api false</code> manually.</p><p>Access to ArangoDB&rsquo;s built-in web interface, which is also a Foxx service, is
still possible even with the option set to <code>false</code>.</p><p>Disabling the access to Foxx can be useful to close off a potential attack
vector in case Foxx is not used.
Also see <a href=/3.11/operations/security/security-options/ class=link>Server security options</a>.</p><h3 id=rocksdb-auto-flushing>RocksDB auto-flushing <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#rocksdb-auto-flushing class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.10, v3.10.5</small></p><p>A new feature for automatically flushing RocksDB Write-Ahead Log (WAL) files and
in-memory column family data has been added.</p><p>An auto-flush occurs if the number of live WAL files exceeds a certain threshold.
This ensures that WAL files are moved to the archive when there are a lot of
live WAL files present, for example, after a restart. In this case, RocksDB does
not count any previously existing WAL files when calculating the size of WAL
files and comparing its <code>max_total_wal_size</code>. Auto-flushing fixes this problem,
but may prevent WAL files from being moved to the archive quickly.</p><p>You can configure the feature via the following new startup options:</p><ul><li><code>--rocksdb.auto-flush-min-live-wal-files</code>:
The minimum number of live WAL files that triggers an auto-flush. Defaults to <code>10</code>.</li><li><code>--rocksdb.auto-flush-check-interval</code>:
The interval (in seconds) in which auto-flushes are executed. Defaults to <code>3600</code>.
Note that an auto-flush is only executed if the number of live WAL files
exceeds the configured threshold and the last auto-flush is longer ago than
the configured auto-flush check interval. This avoids too frequent auto-flushes.</li></ul><h3 id=configurable-whitespace-in-metrics>Configurable whitespace in metrics <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#configurable-whitespace-in-metrics class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.6</small></p><p>The output format of the metrics API slightly changed in v3.10.0. It no longer
had a space between the label and the value for metrics with labels. Example:</p><pre tabindex=0><code>arangodb_agency_cache_callback_number{role=&#34;SINGLE&#34;}0
</code></pre><p>The new <code>--server.ensure-whitespace-metrics-format</code> startup option lets you
control whether the metric label and value shall be separated by a space for
improved compatibility with some tools. This option is enabled by default.
From v3.10.6 onward, the default output format looks like this:</p><pre tabindex=0><code>arangodb_agency_cache_callback_number{role=&#34;SINGLE&#34;} 0
</code></pre><h3 id=configurable-interval-when-counting-open-file-descriptors>Configurable interval when counting open file descriptors <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#configurable-interval-when-counting-open-file-descriptors class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.7</small></p><p>The <code>--server.count-descriptors-interval</code> startup option can be used to specify
the update interval in milliseconds when counting the number of open file
descriptors.</p><p>The default value is <code>60000</code>, i.e. the update interval is once per minute.
To disable the counting of open file descriptors, you can set the value to <code>0</code>.
If counting is turned off, the <code>arangodb_file_descriptors_current</code> metric
reports a value of <code>0</code>.</p><h3 id=configurable-limit-of-collections-per-query>Configurable limit of collections per query <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#configurable-limit-of-collections-per-query class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.7, v3.11.1</small></p><p>The <code>--query.max-collections-per-query</code> startup option allows you to adjust the
previously fixed limit for the maximum number of collections/shards per AQL query.
The default value is <code>2048</code>, which is equal to the fixed limit of
collections/shards in older versions.</p><h3 id=custom-arguments-to-rclone>Custom arguments to rclone <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#custom-arguments-to-rclone class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.11, v3.10.7, v3.11.1</small></p><p>The <code>--rclone.argument</code> startup option can be used to prepend custom arguments
to rclone. For example, you can enable debug logging to a separate file on
startup as follows:</p><pre tabindex=0><code>arangod --rclone.argument &#34;--log-level=DEBUG&#34; --rclone.argument &#34;--log-file=rclone.log&#34;
</code></pre><h3 id=lz4-compression-for-values-in-the-in-memory-edge-cache>LZ4 compression for values in the in-memory edge cache <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#lz4-compression-for-values-in-the-in-memory-edge-cache class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.11.2</small></p><p>LZ4 compression of edge index cache values allows to store more data in main
memory than without compression, so the available memory can be used more
efficiently. The compression is transparent and does not require any change to
queries or applications.
The compression can add CPU overhead for compressing values when storing them
in the cache, and for decompressing values when fetching them from the cache.</p><p>The new startup option <code>--cache.min-value-size-for-edge-compression</code> can be
used to set a threshold value size for compression edge index cache payload
values. The default value is <code>1GB</code>, which effectively turns compression
off. Setting the option to a lower value (i.e. <code>100</code>) turns on the
compression for any payloads whose size exceeds this value.</p><p>The new startup option <code>--cache.acceleration-factor-for-edge-compression</code> can
be used to fine-tune the compression. The default value is <code>1</code>.
Higher values typically mean less compression but faster speeds.</p><p>The following new metrics can be used to determine the usefulness of
compression:</p><ul><li><code>rocksdb_cache_edge_inserts_effective_entries_size_total</code>: returns the total
number of bytes of all entries that were ever stored in the in-memory edge cache,
after compression was attempted/applied. This metric is populated regardless
of whether compression is used or not.</li><li><code>rocksdb_cache_edge_inserts_uncompressed_entries_size_total</code>: returns the total
number of bytes of all entries that were ever stored in the in-memory edge
cache, before compression was applied. This metric is populated regardless of
whether compression is used or not.</li><li><code>rocksdb_cache_edge_compression_ratio</code>: returns the effective
compression ratio for all edge cache entries ever stored in the cache.</li></ul><p>Note that these metrics are increased upon every insertion into the edge
cache, but not decreased when data gets evicted from the cache.</p><h3 id=limit-the-number-of-databases-in-a-deployment>Limit the number of databases in a deployment <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#limit-the-number-of-databases-in-a-deployment class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.10, v3.11.2</small></p><p>The <code>--database.max-databases</code> startup option allows you to limit the
number of databases that can exist in parallel in a deployment. You can use this
option to limit the resources used by database objects. If the option is used
and there are already as many databases as configured by this option, any
attempt to create an additional database fails with error
<code>32</code> (<code>ERROR_RESOURCE_LIMIT</code>). Additional databases can then only be created
if other databases are dropped first. The default value for this option is
unlimited, so an arbitrary amount of databases can be created.</p><h3 id=cluster-internal-connectivity-checks>Cluster-internal connectivity checks <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#cluster-internal-connectivity-checks class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.11.5</small></p><p>This feature makes Coordinators and DB-Servers in a cluster periodically send
check requests to each other, in order to see if all nodes can connect to
each other.
If a cluster-internal connection to another Coordinator or DB-Server cannot
be established within 10 seconds, a warning is now logged.</p><p>The new <code>--cluster.connectivity-check-interval</code> startup option can be used
to control the frequency of the connectivity check, in seconds.
If set to a value greater than zero, the initial connectivity check is
performed approximately 15 seconds after the instance start, and subsequent
connectivity checks are executed with the specified frequency.
If set to <code>0</code>, connectivity checks are disabled.</p><p>You can also use the following metrics to monitor and detect temporary or
permanent connectivity issues:</p><ul><li><code>arangodb_network_connectivity_failures_coordinators</code>: Number of failed
connectivity check requests sent by this instance to Coordinators.</li><li><code>arangodb_network_connectivity_failures_dbservers_total</code>: Number of failed
connectivity check requests sent to DB-Servers.</li></ul><h3 id=configurable-maximum-for-queued-log-entries>Configurable maximum for queued log entries <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#configurable-maximum-for-queued-log-entries class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.12, v3.11.5</small></p><p>The new <code>--log.max-queued-entries</code> startup option lets you configure how many
log entries are queued in a background thread.</p><p>Log entries are pushed on a queue for asynchronous writing unless you enable the
<code>--log.force-direct</code> startup option. If you use a slow log output (e.g. syslog),
the queue might grow and eventually overflow.</p><p>You can configure the upper bound of the queue with this option. If the queue is
full, log entries are written synchronously until the queue has space again.</p><h3 id=monitoring-per-collectiondatabaseuser>Monitoring per collection/database/user <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#monitoring-per-collectiondatabaseuser class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.13, v3.11.7</small></p><p>The following metrics have been introduced to track per-shard requests on
DB-Servers:</p><ul><li><code>arangodb_collection_leader_reads_total</code>: The number of read requests on
leaders, per shard, and optionally also split by user.</li><li><code>arangodb_collection_leader_writes_total</code>: The number of write requests on
leaders, per shard, and optionally also split by user.</li><li><code>arangodb_collection_requests_bytes_read_total</code>: The number of bytes read in
read requests on leaders.</li><li><code>arangodb_collection_requests_bytes_written_total</code>: The number of bytes written
in write requests on leaders and followers.</li></ul><p>To opt into these metrics, you can use the new <code>--server.export-shard-usage-metrics</code>
startup option. It can be set to one of the following values on DB-Servers:</p><ul><li><code>disabled</code>: No shard usage metrics are recorded nor exported. This is the
default value.</li><li><code>enabled-per-shard</code>: This makes DB-Servers collect per-shard usage metrics.</li><li><code>enabled-per-shard-per-user</code>: This makes DB-Servers collect per-shard
and per-user metrics. This is more granular than <code>enabled-per-shard</code> but
can produce a lot of metrics.</li></ul><p>Whenever a shard is accessed in read or write mode by one of the following
operations, the metrics are populated dynamically, either with a per-user
label or not, depending on the above setting.
The metrics are retained in memory on DB-Servers. Removing databases,
collections, or users that are already included in the metrics won&rsquo;t remove
the metrics until the DB-Server is restarted.</p><p>The following operations increase the metrics:</p><ul><li>AQL queries: an AQL query increases the read or write counters exactly
once for each involved shard. For shards that are accessed in read/write
mode, only the write counter is increased.</li><li>Single-document insert, update, replace, and remove operations: for each
such operation, the write counter is increased once for the affected
shard.</li><li>Multi-document insert, update, replace, and remove operations: for each
such operation, the write counter is increased once for each shard
that is affected by the operation. Note that this includes collection
truncate operations.</li><li>Single and multi-document read operations: for each such operation, the
read counter is increased once for each shard that is affected by the
operation.</li></ul><p>The metrics are increased when any of the above operations start, and they
are not decreased should an operation abort or if an operation does not
lead to any actual reads or writes.</p><p>As there can be many of these dynamic metrics based on the number of shards
and/or users in the deployment, these metrics are turned off by default.
When turned on, the metrics are exposed only via the new
<code>GET /_admin/usage-metrics</code> endpoint. They are not exposed via the existing
metrics <code>GET /_admin/metrics</code> endpoint.</p><p>Note that internal operations, such as internal queries executed for statistics
gathering, internal garbage collection, and TTL index cleanup are not counted in
these metrics. Additionally, all requests that are using the superuser JWT for
authentication and that do not have a specific user set are not counted.</p><p>Enabling these metrics can likely result in a small latency overhead of a few
percent for write operations. The exact overhead depends on
several factors, such as the type of operation (single or multi-document operation),
replication factor, network latency, etc.</p><h2 id=miscellaneous-changes>Miscellaneous changes <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#miscellaneous-changes class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=write-write-conflict-improvements>Write-write conflict improvements <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#write-write-conflict-improvements class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>It is now less likely that writes to the same document in quick succession
result in write-write conflicts for single document operations that use the
Document HTTP API. See
<a href=/3.11/release-notes/version-3.11/incompatible-changes-in-3-11/#write-write-conflict-improvements class=link>Incompatible changes in ArangoDB 3.11</a>
about the detailed behavior changes.</p><h3 id=trace-logs-for-graph-traversals-and-path-searches>Trace logs for graph traversals and path searches <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#trace-logs-for-graph-traversals-and-path-searches class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Detailed information is now logged if you run AQL graph traversals
or (shortest) path searches with AQL and set the
log level to <code>TRACE</code> for the <code>graphs</code> log topic. This information is fairly
low-level but can help to understand correctness and performance issues with
traversal queries. There are also some new log messages for the <code>DEBUG</code> level.</p><p>To enable tracing for traversals and path searches at startup, you can set
<code>--log.level graphs=trace</code>.</p><p>To enable or disable it at runtime, you can call the
<a href=/3.11/develop/http-api/monitoring/logs/#set-the-server-log-levels class=link><code>PUT /_admin/log/level</code></a>
endpoint of the HTTP API and set the log level using a request body like
<code>{"graphs":"TRACE"}</code>.</p><h3 id=persisted-pregel-execution-statistics>Persisted Pregel execution statistics <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#persisted-pregel-execution-statistics class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Pregel algorithm executions now persist execution statistics to a system
collection. The statistics are kept until you remove them, whereas the
previously existing interfaces only store the information about Pregel jobs
temporarily in memory.</p><p>To access and delete persisted execution statistics, you can use the newly added
<code>history()</code> and <code>removeHistory()</code> JavaScript API methods of the Pregel module:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=kd>var</span> <span class=nx>pregel</span> <span class=o>=</span> <span class=nx>require</span><span class=p>(</span><span class=s2>&#34;@arangodb/pregel&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=kr>const</span> <span class=nx>execution</span> <span class=o>=</span> <span class=nx>pregel</span><span class=p>.</span><span class=nx>start</span><span class=p>(</span><span class=s2>&#34;sssp&#34;</span><span class=p>,</span> <span class=s2>&#34;demograph&#34;</span><span class=p>,</span> <span class=p>{</span> <span class=nx>source</span><span class=o>:</span> <span class=s2>&#34;vertices/V&#34;</span> <span class=p>});</span>
</span></span><span class=line><span class=cl><span class=kr>const</span> <span class=nx>historyStatus</span> <span class=o>=</span> <span class=nx>pregel</span><span class=p>.</span><span class=nx>history</span><span class=p>(</span><span class=nx>execution</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nx>pregel</span><span class=p>.</span><span class=nx>removeHistory</span><span class=p>();</span></span></span></code></pre></div><p>See <a href=/3.11/data-science/pregel/#get-persisted-execution-statistics class=link>Distributed Iterative Graph Processing (Pregel)</a>
for details.</p><p>You can also use the newly added HTTP endpoints with the
<code>/_api/control_pregel/history</code> route.
See <a href=/3.11/develop/http-api/pregel/ class=link>Pregel HTTP API</a> for details.</p><p>You can still use the old interfaces (the <code>pregel.status()</code> method as well as
the <code>GET /_api/control_pregel</code> and <code>GET /_api/control_pregel/{id}</code> endpoints).</p><h3 id=arangosearch-metric>ArangoSearch metric <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#arangosearch-metric class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The following ArangoSearch metric has been added in version 3.11:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>arangodb_search_num_primary_docs</code></td><td style=text-align:left>Number of primary documents for current snapshot.</td></tr></tbody></table><h3 id=traffic-accounting-metrics>Traffic accounting metrics <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#traffic-accounting-metrics class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.8.9, v3.9.6, v3.10.2</small></p><p>The following metrics for traffic accounting have been added:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>arangodb_client_user_connection_statistics_bytes_received</code></td><td style=text-align:left>Bytes received for requests, only user traffic.</td></tr><tr><td style=text-align:left><code>arangodb_client_user_connection_statistics_bytes_sent</code></td><td style=text-align:left>Bytes sent for responses, only user traffic.</td></tr><tr><td style=text-align:left><code>arangodb_http1_connections_total</code></td><td style=text-align:left>Total number of HTTP/1.1 connections accepted.</td></tr></tbody></table><h3 id=configurable-cache_oblivious-option-for-jemalloc>Configurable <code>CACHE_OBLIVIOUS</code> option for jemalloc <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#configurable-cache_oblivious-option-for-jemalloc class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.7, v3.10.3</small></p><p>The jemalloc memory allocator supports an option to toggle cache-oblivious large
allocation alignment. It is enabled by default up to v3.10.3, but disabled from
v3.10.4 onwards. Disabling it helps to save 4096 bytes of memory for every
allocation which is at least 16384 bytes large. This is particularly beneficial
for the RocksDB buffer cache.</p><p>You can now configure the option by setting a <code>CACHE_OBLIVIOUS</code> environment
variable to the string <code>true</code> or <code>false</code> before starting ArangoDB.</p><p>See <a href=/3.11/components/arangodb-server/environment-variables/ class=link>ArangoDB Server environment variables</a>
for details.</p><h3 id=wal-file-tracking-metrics>WAL file tracking metrics <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#wal-file-tracking-metrics class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.10, v3.10.5</small></p><p>The following metrics for write-ahead log (WAL) file tracking have been added:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>rocksdb_live_wal_files</code></td><td style=text-align:left>Number of live RocksDB WAL files.</td></tr><tr><td style=text-align:left><code>rocksdb_wal_released_tick_flush</code></td><td style=text-align:left>Lower bound sequence number from which WAL files need to be kept because of external flushing needs.</td></tr><tr><td style=text-align:left><code>rocksdb_wal_released_tick_replication</code></td><td style=text-align:left>Lower bound sequence number from which WAL files need to be kept because of replication.</td></tr><tr><td style=text-align:left><code>arangodb_flush_subscriptions</code></td><td style=text-align:left>Number of currently active flush subscriptions.</td></tr></tbody></table><h3 id=number-of-replication-clients-metric>Number of replication clients metric <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#number-of-replication-clients-metric class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.5</small></p><p>The following metric for the number of replication clients for a server has
been added:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>arangodb_replication_clients</code></td><td style=text-align:left>Number of currently connected/active replication clients.</td></tr></tbody></table><h3 id=reduced-memory-usage-of-in-memory-edge-indexes>Reduced memory usage of in-memory edge indexes <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#reduced-memory-usage-of-in-memory-edge-indexes class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.5</small></p><p>The memory usage of in-memory edge index caches is reduced if most of the edges
in an index refer to a single or mostly the same collection.</p><p>Previously, the full edge IDs, consisting of the referred-to collection
name and the referred-to key of the edge, were stored in full, i.e. the full
values of the edges&rsquo; <code>_from</code> and <code>_to</code> attributes.
Now, the first edge inserted into an edge index&rsquo; in-memory cache determines
the collection name for which all corresponding edges can be stored
prefix-compressed.</p><p>For example, when inserting an edge pointing to <code>the-collection/abc</code> into the
empty cache, the collection name <code>the-collection</code> is noted for that cache
as a prefix. The edge is stored in-memory as only <code>/abc</code>. Further edges
that are inserted into the cache and that point to the same collection are
also stored prefix-compressed.</p><p>The prefix compression is transparent and does not require configuration or
setup. Compression is done separately for each cache, i.e. a separate prefix
can be used for each individual edge index, and separately for the <code>_from</code> and
<code>_to</code> parts. Lookups from the in-memory edge cache do not return compressed
values but the full-length edge IDs. The compressed values are also used
in-memory only and are not persisted on disk.</p><h3 id=sending-delay-metrics-for-internal-requests>Sending delay metrics for internal requests <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#sending-delay-metrics-for-internal-requests class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.9.11, v3.10.6</small></p><p>The following metrics for diagnosing delays in cluster-internal network requests
have been added:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>arangodb_network_dequeue_duration</code></td><td style=text-align:left>Internal request duration for the dequeue in seconds.</td></tr><tr><td style=text-align:left><code>arangodb_network_response_duration</code></td><td style=text-align:left>Internal request duration from fully sent till response received in seconds.</td></tr><tr><td style=text-align:left><code>arangodb_network_send_duration</code></td><td style=text-align:left>Internal request send duration in seconds.</td></tr><tr><td style=text-align:left><code>arangodb_network_unfinished_sends_total</code></td><td style=text-align:left>Number of internal requests for which sending has not finished.</td></tr></tbody></table><h3 id=peak-memory-metric-for-in-memory-caches>Peak memory metric for in-memory caches <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#peak-memory-metric-for-in-memory-caches class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.7</small></p><p>This new metric stores the peak value of the <code>rocksdb_cache_allocated</code> metric:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>rocksdb_cache_peak_allocated</code></td><td style=text-align:left>Global peak memory allocation of ArangoDB in-memory caches.</td></tr></tbody></table><h3 id=number-of-sst-files-metric>Number of SST files metric <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#number-of-sst-files-metric class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.7, v3.11.1</small></p><p>This new metric reports the number of RocksDB <code>.sst</code> files:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>rocksdb_total_sst_files</code></td><td style=text-align:left>Total number of RocksDB sst files, aggregated over all levels.</td></tr></tbody></table><h3 id=file-descriptor-metrics>File descriptor metrics <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#file-descriptor-metrics class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.7</small></p><p>The following system metrics have been added:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>arangodb_file_descriptors_limit</code></td><td style=text-align:left>System limit for the number of open files for the arangod process.</td></tr><tr><td style=text-align:left><code>arangodb_file_descriptors_current</code></td><td style=text-align:left>Number of file descriptors currently opened by the arangod process.</td></tr></tbody></table><h3 id=more-instant-hot-backups>More instant Hot Backups <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#more-instant-hot-backups class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.10, v3.11.3</small></p><p>Cluster deployments no longer wait for all in-progress transactions to get
committed when a user requests a Hot Backup. The waiting could cause deadlocks
and thus Hot Backups to fail, in particular in ArangoGraph. Now, Hot Backups are
created immediately and commits have to wait until the backup process is done.</p><h3 id=in-memory-edge-cache-startup-options-and-metrics>In-memory edge cache startup options and metrics <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#in-memory-edge-cache-startup-options-and-metrics class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.11.4</small></p><p>The following startup options have been added:</p><ul><li><p><code>--cache.max-spare-memory-usage</code>: the maximum memory usage for spare tables
in the in-memory cache.</p></li><li><p><code>--cache.high-water-multiplier</code>: controls the cache&rsquo;s effective memory usage
limit. The user-defined memory limit (i.e. <code>--cache.size</code>) is multiplied with
this value to create the effective memory limit, from which on the cache tries
to free up memory by evicting the oldest entries. The default value is <code>0.56</code>,
matching the previously hardcoded 56% for the cache subsystem.</p><p>You can increase the multiplier to make the cache subsystem use more memory, but
this may overcommit memory because the cache memory reclamation procedure is
asynchronous and can run in parallel to other tasks that insert new data.
In case a deployment&rsquo;s memory usage is already close to the maximum, increasing
the multiplier can lead to out-of-memory (OOM) kills.</p></li></ul><p>The following metrics have been added:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>rocksdb_cache_edge_compressed_inserts_total</code></td><td style=text-align:left>Total number of compressed inserts into the in-memory edge cache.</td></tr><tr><td style=text-align:left><code>rocksdb_cache_edge_empty_inserts_total</code></td><td style=text-align:left>Total number of insertions into the in-memory edge cache for non-connected edges.</td></tr><tr><td style=text-align:left><code>rocksdb_cache_edge_inserts_total</code></td><td style=text-align:left>Total number of insertions into the in-memory edge cache.</td></tr></tbody></table><h3 id=observability-of-in-memory-cache-subsystem>Observability of in-memory cache subsystem <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#observability-of-in-memory-cache-subsystem class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.11, v3.11.4</small></p><p>The following metrics have been added to improve the observability of in-memory
cache subsystem:</p><ul><li><code>rocksdb_cache_free_memory_tasks_total</code>: Total number of free memory tasks
that were scheduled by the in-memory edge cache subsystem. This metric will
be increased whenever the cache subsystem schedules a task to free up memory
in one of the managed in-memory caches. It is expected to see this metric
rising when the cache subsystem hits its global memory budget.</li><li><code>rocksdb_cache_free_memory_tasks_duration_total</code>: Total amount of time spent
inside the free memory tasks of the in-memory cache subsystem. Free memory
tasks are scheduled by the cache subsystem to free up memory in existing cache
hash tables.</li><li><code>rocksdb_cache_migrate_tasks_total</code>: Total number of migrate tasks that were
scheduled by the in-memory edge cache subsystem. This metric will be increased
whenever the cache subsystem schedules a task to migrate an existing cache hash
table to a bigger or smaller size.</li><li><code>rocksdb_cache_migrate_tasks_duration_total</code>: Total amount of time spent inside
the migrate tasks of the in-memory cache subsystem. Migrate tasks are scheduled
by the cache subsystem to migrate existing cache hash tables to a bigger or
smaller table.</li></ul><h3 id=detached-scheduler-threads>Detached scheduler threads <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#detached-scheduler-threads class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.13, v3.11.5</small></p><p>A scheduler thread now has the capability to detach itself from the scheduler
if it observes the need to perform a potentially long running task, like waiting
for a lock. This allows a new scheduler thread to be started and prevents
scenarios where all threads are blocked waiting for a lock, which has previously
led to deadlock situations.</p><p>Threads waiting for more than 1 second on a collection lock will detach
themselves.</p><p>The following startup option has been added:</p><ul><li><code>--server.max-number-detached-threads</code>: The maximum number of detached scheduler
threads.</li></ul><p>The following metric has been added:</p><ul><li><code>arangodb_scheduler_num_detached_threads</code>: The number of worker threads
currently started and detached from the scheduler.</li></ul><h3 id=memory-usage-of-connection-and-request-statistics>Memory usage of connection and request statistics <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#memory-usage-of-connection-and-request-statistics class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><small>Introduced in: v3.10.12, v3.11.6</small></p><p>The following metrics have been added:</p><table><thead><tr><th style=text-align:left>Label</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left><code>arangodb_connection_statistics_memory_usage</code></td><td style=text-align:left>Total memory usage of connection statistics.</td></tr><tr><td style=text-align:left><code>arangodb_request_statistics_memory_usage</code></td><td style=text-align:left>Total memory usage of request statistics.</td></tr></tbody></table><p>If the <code>--server.statistics</code> startup option is set to <code>true</code>, then some
connection and request statistics are built up in memory for incoming request.
It is expected that the memory usage reported by these metrics remains
relatively constant over time. It may grow only when there are bursts of new
connections. Some memory is pre-allocated at startup for higher efficiency. If the
<code>--server.statistics</code> startup option is set to <code>false</code>, then no memory will be
allocated for connection and request statistics.</p><h2 id=client-tools>Client tools <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#client-tools class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=arangodump>arangodump <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#arangodump class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><h4 id=option-to-not-dump-views>Option to not dump Views <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#option-to-not-dump-views class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h4><p><em>arangodump</em> has a new <code>--dump-views</code> startup option to control whether
View definitions shall be included in the backup. The default value is <code>true</code>.</p><h4 id=improved-dump-performance-experimental>Improved dump performance (experimental) <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#improved-dump-performance-experimental class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h4><p><small>Introduced in: v3.10.8, v3.11.2</small></p><p><em>arangodump</em> has experimental extended parallelization capabilities
to work not only at the collection level, but also at the shard level.
In combination with the newly added support for the VelocyPack format that
ArangoDB uses internally, database dumps can now be created and restored more
quickly and occupy less disk space. This major performance boost makes dumps and
restores up to several times faster, which is extremely useful when dealing
with large shards.</p><ul><li><p>Whether the new parallel dump variant is used is controlled by the newly added
<code>--use-experimental-dump</code> startup option (introduced in v3.10.8 and v3.11.2).
The default value is <code>false</code>.</p></li><li><p>Optionally, you can make <em>arangodump</em> write multiple output files per
collection/shard (introduced in v3.10.10 and v3.11.2).
The file splitting allows for better parallelization when
writing the results to disk, which in case of non-split files must be serialized.
You can enable it by setting the <code>--split-files</code> option to <code>true</code>. This option
is disabled by default because dumps created with this option enabled cannot
be restored into previous versions of ArangoDB.</p></li></ul><h2 id=internal-changes>Internal changes <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#internal-changes class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=upgraded-bundled-library-versions>Upgraded bundled library versions <a href=/3.11/release-notes/version-3.11/whats-new-in-3-11/#upgraded-bundled-library-versions class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The bundled version of the OpenSSL library has been upgraded from 1.1.1 to 3.0.8.</p><p>The bundled version of the zlib library has been upgraded to 1.2.13.</p><p>The bundled version of the fmt library has been upgraded to 9.1.0.</p><p>The bundled version of the immer library has been upgraded to 0.8.0.</p><p>The bundled versions of the abseil-cpp, s2geometry, and wcwidth library have
been updated to more recent versions that don&rsquo;t have a version number.</p><p>For ArangoDB 3.11, the bundled version of rclone is 1.62.2. Check if your
rclone configuration files require changes.</p><p>From version 3.11.10 onward, ArangoDB uses the glibc C standard library
implementation with an LGPL-3.0 license instead of libmusl. Notably, it features
string functions that are better optimized for common CPUs.</p><nav class=pagination><span class=prev><a class="nav nav-prev link" href=/3.11/release-notes/version-3.11/><i class="fas fa-chevron-left fa-fw"></i><p>Version 3.11</p></a></span><span class=next><a class="nav nav-next link" href=/3.11/release-notes/version-3.11/known-issues-in-3-11/><p>Known Issues in 3.11</p><i class="fas fa-chevron-right fa-fw"></i></a></span></nav></article><div class=toc-container><a class=edit-page aria-label href=https://github.com/arangodb/docs-hugo/edit/main/site/content/3.11/release-notes/version-3.11/whats-new-in-3-11.md target=_blank><i class="fab fa-fw fa-github edit-page-icon"></i></a><div class=toc><div class=toc-content><div class=toc-header><p>On this page</p></div><nav id=TableOfContents><div class=level-2><a href=#arangosearch>ArangoSearch</a></div><div class=level-3><a href=#late-materialization-improvements>Late materialization improvements</a></div><div class=level-3><a href=#arangosearch-column-cache-enterprise-edition>ArangoSearch column cache (Enterprise Edition)</a></div><div class=level-2><a href=#analyzers>Analyzers</a></div><div class=level-3><a href=#geo_s2-analyzer-enterprise-edition><code>geo_s2</code> Analyzer (Enterprise Edition)</a></div><div class=level-2><a href=#web-interface>Web interface</a></div><div class=level-3><a href=#new-graph-viewer>New graph viewer</a></div><div class=level-3><a href=#search-alias-views><code>search-alias</code> Views</a></div><div class=level-3><a href=#arangosearch-views><code>arangosearch</code> Views</a></div><div class=level-3><a href=#inverted-indexes>Inverted indexes</a></div><div class=level-3><a href=#new-sorting-mechanism-and-search-box-for-saved-queries>New sorting mechanism and search box for Saved Queries</a></div><div class=level-2><a href=#aql>AQL</a></div><div class=level-3><a href=#parallel-gather>Parallel gather</a></div><div class=level-3><a href=#optimized-access-of-last-element-in-traversals>Optimized access of last element in traversals</a></div><div class=level-3><a href=#faster-bulk-insert-operations-in-clusters>Faster bulk <code>INSERT</code> operations in clusters</a></div><div class=level-3><a href=#index-cache-refilling>Index cache refilling</a></div><div class=level-3><a href=#retry-request-for-result-batch>Retry request for result batch</a></div><div class=level-3><a href=#collect--into-can-use-hash-method><code>COLLECT ... INTO</code> can use <code>hash</code> method</a></div><div class=level-3><a href=#k_shortest_paths-performance-improvements>K_SHORTEST_PATHS performance improvements</a></div><div class=level-3><a href=#added-aql-functions>Added AQL functions</a></div><div class=level-3><a href=#extended-query-explain-statistics>Extended query explain statistics</a></div><div class=level-3><a href=#extended-peak-memory-usage-reporting>Extended peak memory usage reporting</a></div><div class=level-3><a href=#number-of-cluster-requests-in-profiling-output>Number of cluster requests in profiling output</a></div><div class=level-3><a href=#new-stage-in-query-profiling-output>New stage in query profiling output</a></div><div class=level-3><a href=#limit-for-the-normalization-of-filter-conditions>Limit for the normalization of <code>FILTER</code> conditions</a></div><div class=level-2><a href=#server-options>Server options</a></div><div class=level-3><a href=#telemetrics>Telemetrics</a></div><div class=level-3><a href=#extended-naming-constraints-for-collections-views-and-indexes>Extended naming constraints for collections, Views, and indexes</a></div><div class=level-3><a href=#verify-sst-files>Verify <code>.sst</code> files</a></div><div class=level-3><a href=#support-for-additional-value-suffixes>Support for additional value suffixes</a></div><div class=level-3><a href=#configurable-status-code-if-write-concern-not-fulfilled>Configurable status code if write concern not fulfilled</a></div><div class=level-3><a href=#rocksdb-blob-storage-experimental>RocksDB BLOB storage (experimental)</a></div><div class=level-3><a href=#--querymax-dnf-condition-members-option><code>--query.max-dnf-condition-members</code> option</a></div><div class=level-3><a href=#--rocksdbreserve-file-metadata-memory-option><code>--rocksdb.reserve-file-metadata-memory</code> option</a></div><div class=level-3><a href=#arangosearch-column-cache-limit>ArangoSearch column cache limit</a></div><div class=level-3><a href=#aql-query-logging>AQL query logging</a></div><div class=level-3><a href=#index-cache-refill-options>Index cache refill options</a></div><div class=level-3><a href=#cluster-supervision-options>Cluster supervision options</a></div><div class=level-3><a href=#rocksdb-bloom-filter-option>RocksDB Bloom filter option</a></div><div class=level-3><a href=#disable-user-defined-aql-functions>Disable user-defined AQL functions</a></div><div class=level-3><a href=#option-to-disable-foxx>Option to disable Foxx</a></div><div class=level-3><a href=#rocksdb-auto-flushing>RocksDB auto-flushing</a></div><div class=level-3><a href=#configurable-whitespace-in-metrics>Configurable whitespace in metrics</a></div><div class=level-3><a href=#configurable-interval-when-counting-open-file-descriptors>Configurable interval when counting open file descriptors</a></div><div class=level-3><a href=#configurable-limit-of-collections-per-query>Configurable limit of collections per query</a></div><div class=level-3><a href=#custom-arguments-to-rclone>Custom arguments to rclone</a></div><div class=level-3><a href=#lz4-compression-for-values-in-the-in-memory-edge-cache>LZ4 compression for values in the in-memory edge cache</a></div><div class=level-3><a href=#limit-the-number-of-databases-in-a-deployment>Limit the number of databases in a deployment</a></div><div class=level-3><a href=#cluster-internal-connectivity-checks>Cluster-internal connectivity checks</a></div><div class=level-3><a href=#configurable-maximum-for-queued-log-entries>Configurable maximum for queued log entries</a></div><div class=level-3><a href=#monitoring-per-collectiondatabaseuser>Monitoring per collection/database/user</a></div><div class=level-2><a href=#miscellaneous-changes>Miscellaneous changes</a></div><div class=level-3><a href=#write-write-conflict-improvements>Write-write conflict improvements</a></div><div class=level-3><a href=#trace-logs-for-graph-traversals-and-path-searches>Trace logs for graph traversals and path searches</a></div><div class=level-3><a href=#persisted-pregel-execution-statistics>Persisted Pregel execution statistics</a></div><div class=level-3><a href=#arangosearch-metric>ArangoSearch metric</a></div><div class=level-3><a href=#traffic-accounting-metrics>Traffic accounting metrics</a></div><div class=level-3><a href=#configurable-cache_oblivious-option-for-jemalloc>Configurable <code>CACHE_OBLIVIOUS</code> option for jemalloc</a></div><div class=level-3><a href=#wal-file-tracking-metrics>WAL file tracking metrics</a></div><div class=level-3><a href=#number-of-replication-clients-metric>Number of replication clients metric</a></div><div class=level-3><a href=#reduced-memory-usage-of-in-memory-edge-indexes>Reduced memory usage of in-memory edge indexes</a></div><div class=level-3><a href=#sending-delay-metrics-for-internal-requests>Sending delay metrics for internal requests</a></div><div class=level-3><a href=#peak-memory-metric-for-in-memory-caches>Peak memory metric for in-memory caches</a></div><div class=level-3><a href=#number-of-sst-files-metric>Number of SST files metric</a></div><div class=level-3><a href=#file-descriptor-metrics>File descriptor metrics</a></div><div class=level-3><a href=#more-instant-hot-backups>More instant Hot Backups</a></div><div class=level-3><a href=#in-memory-edge-cache-startup-options-and-metrics>In-memory edge cache startup options and metrics</a></div><div class=level-3><a href=#observability-of-in-memory-cache-subsystem>Observability of in-memory cache subsystem</a></div><div class=level-3><a href=#detached-scheduler-threads>Detached scheduler threads</a></div><div class=level-3><a href=#memory-usage-of-connection-and-request-statistics>Memory usage of connection and request statistics</a></div><div class=level-2><a href=#client-tools>Client tools</a></div><div class=level-3><a href=#arangodump>arangodump</a></div><div class=level-4><a href=#option-to-not-dump-views>Option to not dump Views</a></div><div class=level-4><a href=#improved-dump-performance-experimental>Improved dump performance (experimental)</a></div><div class=level-2><a href=#internal-changes>Internal changes</a></div><div class=level-3><a href=#upgraded-bundled-library-versions>Upgraded bundled library versions</a></div></nav></div></div></div></div></div></section></section></div><button class="back-to-top hidden" onclick=goToTop(event) href=#><i class="fa fa-arrow-up"></i></button><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@docsearch/css@3>
<script src=https://cdn.jsdelivr.net/npm/@docsearch/js@3></script>
<script type=text/javascript>window.setupDocSearch=function(e){if(!window.docsearch)return;docsearch({appId:"OK3ZBQ5982",apiKey:"500c85ccecb335d507fe4449aed12e1d",indexName:"arangodbdocs",insights:!0,container:"#searchbox",debug:!1,maxResultsPerGroup:10,searchParameters:{facetFilters:[`version:${e}`]}})}</script></body></html>