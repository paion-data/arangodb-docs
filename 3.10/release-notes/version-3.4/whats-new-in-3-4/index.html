<!doctype html><html lang=en><head><link href=//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.no-icons.min.css rel=stylesheet><link href=//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css rel=stylesheet><link href=/css/fontawesome-all.min.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fontawesome-all.min.css rel=stylesheet></noscript><link href=/css/featherlight.min.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/featherlight.min.css rel=stylesheet></noscript><link href=/css/nucleus.css rel=stylesheet><link href=/css/fonts.css rel=stylesheet media=print onload='this.media="all",this.onload=null'><noscript><link href=/css/fonts.css rel=stylesheet></noscript><link href=/css/theme.css rel=stylesheet><link href=/css/theme-relearn-light.css rel=stylesheet id=variant-style><link href=/css/print.css rel=stylesheet media=print><script src=/js/variant.js?1743775370></script>
<script>var root_url="/",baseUriFull,baseUri=root_url.replace(/\/$/,"");window.T_Copy_to_clipboard="",window.T_Copied_to_clipboard="",window.T_Copy_link_to_clipboard="",window.T_Link_copied_to_clipboard="",baseUriFull="http://localhost/",window.variants&&variants.init(["relearn-light"])</script><meta charset=utf-8><meta name=viewport content="height=device-height,width=device-width,initial-scale=1,minimum-scale=1"><meta name=generator content="Hugo 0.119.0"><meta itemprop=description property="description" content="An integrated search engine for full-text and beyond, overhauled geo-spatial indexing, query result streaming, storage engine changes"><meta property="og:url" content="http://localhost/3.10/release-notes/version-3.4/whats-new-in-3-4/"><meta property="og:title" content="Features and Improvements in ArangoDB 3.4"><meta property="og:type" content="website"><meta property="og:description" content="An integrated search engine for full-text and beyond, overhauled geo-spatial indexing, query result streaming, storage engine changes"><meta name=docsearch:version content="3.10"><title>Features and Improvements in ArangoDB 3.4 | ArangoDB Documentation</title><link href=/images/favicon.png rel=icon type=image/png><script src=/js/jquery.min.js></script>
<script src=/js/clipboard.min.js?1743775370 defer></script>
<script src=/js/featherlight.min.js?1743775370 defer></script>
<script>var versions=[{alias:"devel",deprecated:!1,name:"3.13",version:"3.13.0"},{alias:"stable",deprecated:!1,name:"3.12",version:"3.12.4"},{alias:"3.11",deprecated:!1,name:"3.11",version:"3.11.13"},{alias:"3.10",deprecated:!0,name:"3.10",version:"3.10.14"}]</script><script>var develVersion={alias:"devel",deprecated:!1,name:"3.13",version:"3.13.0"}</script><script>var stableVersion={alias:"stable",deprecated:!1,name:"3.12",version:"3.12.4"}</script><script src=/js/codeblocks.js?1743775370 defer></script>
<script src=/js/theme.js?1743775370 defer></script></head><body><noscript>You need to enable JavaScript to use the ArangoDB documentation.</noscript><div id=page-wrapper class=page_content_splash style=height:auto;opacity:0><section id=page-main><section class=page-container id=page-container><header id=header style="transition:.5s padding ease-out,.15s" class="zn_header_white header-splash-new nav-down header-splash-wrap header1"><div class=header-block-left><div class=mobile-menu-toggle><button id=sidebar-toggle-navigation onclick=showSidebarHandler()><svg width="1.33em" height="1.33em" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="3" y1="12" x2="21" y2="12"/><line x1="3" y1="6" x2="21" y2="6"/><line x1="3" y1="18" x2="21" y2="18"/></svg></button></div><div class=version-logo-container><div class="logo-container hasinfocard_img arangodb-logo-large"><div class=logo><a href=https://www.arangodb.com/><img src=/images/logo_main.png alt=ArangoDB title></a></div></div><div class=arangodb-logo-small><a href=https://arangodb.com/><img alt="ArangoDB Logo" src=/images/ArangoDB_Logo_White_small.png></a></div></div></div><div class=container-right style=display:hidden></div><div class=search-and-version-container><a href=# class="home-link is-current" aria-label="Go to home page" onclick=goToHomepage(event)></a><div id=searchbox></div><script type=text/javascript>const SCRIPT_SRC="https://unpkg.com/@inkeep/widgets-embed@0.2.290/dist/embed.js";function loadAndInitializeInkeep(){if(document.querySelector(`script[src="${SCRIPT_SRC}]"`))return;const e=document.createElement("script");e.type="module",e.src=SCRIPT_SRC,e.onload=initializeInkeep,document.head.appendChild(e)}function initializeInkeep(){const e=Inkeep({integrationId:"clo4lx6jk0000s601cp21x2ok",apiKey:"13b4e56966a76e86c6ff359cd795ee6a0412f751d75d6383",organizationId:"org_HGBkkzGAa4KeGJGh",organizationDisplayName:"ArangoDB",primaryBrandColor:"#80a54d",stringReplacementRules:[{matchingRule:{ruleType:"Substring",string:"Arangograph"},replaceWith:"ArangoGraph"},{matchingRule:{ruleType:"Substring",string:"Aql"},replaceWith:"AQL"},{matchingRule:{ruleType:"Substring",string:"Arangodb"},replaceWith:"ArangoDB"}],customCardSettings:[{filters:{UrlMatch:{ruleType:"PartialUrl",partialUrl:"arango.qubitpi.org"}},searchTabLabel:"Official Docs"},{filters:{UrlMatch:{ruleType:"PartialUrl",partialUrl:"developer.arangodb.com"}},searchTabLabel:"Developer Hub"},{filters:{UrlMatch:{ruleType:"PartialUrl",partialUrl:"arangodb.com"}},searchTabLabel:"Home"}]}),t=e.embed({componentType:"ChatButton",properties:{stylesheetUrls:["/css/fonts.css"],fixedPositionXOffset:"52px",baseSettings:{theme:{primaryColors:{textColorOnPrimary:"white"},tokens:{fonts:{body:"'Inter'",heading:"'Inter'"},zIndex:{overlay:1e4,modal:11e3,popover:12e3,skipLink:13e3,toast:14e3,tooltip:15e3}}}},aiChatSettings:{botAvatarSrcUrl:"/images/ArangoDB_Logo_White_small.png",quickQuestions:["What can you do with AQL that is not feasible with SQL?","How do I search for objects within arrays?","Where can I deploy my ArangoDB instance?"],getHelpCallToActions:[{icon:{builtIn:"FaSlack"},name:"Slack",url:"https://arangodb-community.slack.com/"}]},searchSettings:{tabSettings:{isAllTabEnabled:!1,alwaysDisplayedTabs:["Official Docs","Developer Hub","Home"]}}}})}loadAndInitializeInkeep()</script><div class=version-selector><select id=arangodb-version onchange=changeVersion()><option value=3.13>3.13</option><option value=3.12>3.12</option><option value=3.11>3.11</option><option value=3.10>3.10</option><option value=3.9>3.9</option><option value=3.8>3.8</option></select></div></div></header><iframe src=/nav.html title=description id=menu-iframe class="menu-iframe active" style=opacity:0></iframe><div class=container-main><div class=row-main><nav id=breadcrumbs><ol class=links itemscope itemtype=http://schema.org/BreadcrumbList><meta itemprop=itemListOrder content="Descending"><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="3.10"><a itemprop=item class=link href=/3.10/><span itemprop=name class=breadcrumb-entry>3.10.14</span></a>
<i class="fas fa-chevron-right fa-fw"></i></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="Release Notes"><a itemprop=item class=link href=/3.10/release-notes/><span itemprop=name class=breadcrumb-entry>Release Notes</span></a>
<i class="fas fa-chevron-right fa-fw"></i></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="Version 3.4"><a itemprop=item class=link href=/3.10/release-notes/version-3.4/><span itemprop=name class=breadcrumb-entry>Version 3.4</span></a>
<i class="fas fa-chevron-right fa-fw"></i></li><li itemscope itemtype=https://schema.org/ListItem itemprop=itemListElement><meta itemprop=position content="What&rsquo;s New in 3.4"><a itemprop=item class=link href=/3.10/release-notes/version-3.4/whats-new-in-3-4/><span itemprop=name class=breadcrumb-entry>What&rsquo;s New in 3.4</span></a></li></ol></nav><article class=default><div class="box notices cstyle warning"><div class=box-content-container><div class=box-content><i class="fas fa-exclamation-triangle"></i><div class=box-text><p>ArangoDB v3.10 reached End of Life (EOL) and is no longer supported.</p><p>This documentation is outdated. Please see the most recent <a href=/3.12/release-notes/version-3.4/whats-new-in-3-4/ class=link>stable version</a>.</p></div></div></div></div><hgroup><h1>Features and Improvements in ArangoDB 3.4</h1><p class=lead>An integrated search engine for full-text and beyond, overhauled geo-spatial indexing, query result streaming, storage engine changes</p></hgroup><p>The following list shows in detail which features have been added or improved in
ArangoDB 3.4. ArangoDB 3.4 also contains several bug fixes that are not listed
here.</p><h2 id=arangosearch>ArangoSearch <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#arangosearch class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>ArangoSearch is a sophisticated, integrated full-text search solution over
a user-defined set of attributes and collections. It is the first type of
view in ArangoDB.</p><ul><li><a href=https://www.arangodb.com/learn/search/tutorial/ target=_blank rel="noopener noreferrer" class=link>ArangoSearch tutorial</a>&nbsp;<i class="fas fa-external-link-alt"></i></li><li><a href=/3.10/index-and-search/arangosearch/ class=link>ArangoSearch overview</a></li><li>ArangoSearch in AQL:<ul><li><a href=/3.10/aql/high-level-operations/search/ class=link>SEARCH operation</a></li><li><a href=/3.10/aql/functions/arangosearch/ class=link>ArangoSearch functions</a></li></ul></li></ul><h2 id=new-geo-index-implementation>New geo index implementation <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#new-geo-index-implementation class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=s2-based-geo-index>S2 based geo index <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#s2-based-geo-index class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The geo index in ArangoDB has been reimplemented based on <a href=http://s2geometry.io/ target=_blank rel="noopener noreferrer" class=link>S2 library</a>&nbsp;<i class="fas fa-external-link-alt"></i>
functionality. The new geo index allows indexing points, but also indexing of more
complex geographical objects. The new implementation is much faster than the previous one for
the RocksDB engine.</p><p>Additionally, several AQL functions have been added to facilitate working with
geographical data: <code>GEO_POINT</code>, <code>GEO_MULTIPOINT</code>, <code>GEO_LINESTRING</code>, <code>GEO_MULTILINESTRING</code>,
<code>GEO_POLYGON</code> and <code>GEO_MULTIPOLYGON</code>. These functions will produce GeoJSON objects.</p><p>Additionally there are new geo AQL functions <code>GEO_CONTAINS</code>, <code>GEO_INTERSECTS</code> and <code>GEO_EQUALS</code>
for querying and comparing GeoJSON objects.</p><h3 id=aql-editor-geojson-support>AQL Editor GeoJSON Support <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#aql-editor-geojson-support class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>As a feature on top, the web ui embedded AQL editor now supports also displaying all
GeoJSON supported data.</p><h2 id=rocksdb-storage-engine>RocksDB storage engine <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#rocksdb-storage-engine class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=rocksdb-as-default-storage-engine>RocksDB as default storage engine <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#rocksdb-as-default-storage-engine class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The default storage engine in ArangoDB 3.4 is now the RocksDB engine.</p><p>Previous versions of ArangoDB used MMFiles as the default storage engine. This
change will have an effect for new ArangoDB installations only, and only if no
storage engine is selected explicitly or the storage engine selected is &ldquo;auto&rdquo;.
In this case, a new installation will default to the RocksDB storage engine.</p><p>Existing ArangoDB installations upgraded to 3.4 from previous versions will
continue to use their previously selected storage engine.</p><h3 id=optimized-binary-storage-format>Optimized binary storage format <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#optimized-binary-storage-format class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The RocksDB storage engine in ArangoDB 3.4 now also uses an optimized binary
format for storing documents. This format allows inserting new documents in
an order that RocksDB prefers. Using the new format will reduce the number
of compactions that RocksDB needs to do for the ArangoDB documents stored,
allowing for better long-term insertion performance.</p><p>The new binary format will <strong>only be used for new installations</strong> that start with
ArangoDB 3.4. Existing installations upgraded from previous versions will
continue to use the previous binary format.</p><p>Note that there is no need to use the new binary format for installations upgraded
from 3.3, as the old binary format will continue to work as before.
In order to use the new binary format with existing data, it is required to
create a logical dump of the database data, shut down the server, erase the
database directory and restore the data from the logical dump. To minimize
downtime you can alternatively run a second arangod instance in your system,
that replicates the original data; once the replication has reached completion,
you can switch the instances.</p><h3 id=better-control-of-rocksdb-wal-sync-interval>Better control of RocksDB WAL sync interval <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#better-control-of-rocksdb-wal-sync-interval class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>ArangoDB 3.4 also provides a new configuration option <code>--rocksdb.sync-interval</code>
to control how frequently ArangoDB will automatically synchronize data in RocksDB&rsquo;s
write-ahead log (WAL) files to disk. Automatic syncs will only be performed for
not-yet synchronized data, and only for operations that have been executed without
the <em>waitForSync</em> attribute.</p><p>Automatic synchronization of RocksDB WAL file data is performed by a background
thread in ArangoDB. The default sync interval is 100 milliseconds. This can be
adjusted so syncs happen more or less frequently.</p><h3 id=reduced-replication-catch-up-time>Reduced replication catch-up time <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#reduced-replication-catch-up-time class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The catch-up time for comparing the contents of two collections (or shards) on two
different hosts via the incremental replication protocol has been reduced when using
the RocksDB storage engine.</p><h3 id=improved-rocksdb-geo-index-performance>Improved RocksDB geo index performance <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#improved-rocksdb-geo-index-performance class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The rewritten geo index implementation 3.4 speeds up the RocksDB-based geo index
functionality by a factor of 3 to 6 for many common cases when compared to the
RocksDB-based geo index in 3.3.</p><p>A notable implementation detail of previous versions of ArangoDB was that accessing
a RocksDB collection with a geo index acquired a collection-level lock. This severely
limited concurrent access to RocksDB collections with geo indexes in previous
versions. This requirement is now gone and no extra locks need to be acquired when
accessing a RocksDB collection with a geo index.</p><h3 id=optional-caching-for-documents-and-primary-index-values>Optional caching for documents and primary index values <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#optional-caching-for-documents-and-primary-index-values class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The RocksDB engine now provides a new per-collection property <code>cacheEnabled</code> which
enables in-memory caching of documents and primary index entries. This can potentially
speed up point-lookups significantly, especially if collection have a subset of frequently
accessed documents.</p><p>The option can be enabled for a collection as follows:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=o>&lt;</span><span class=nx>collection</span><span class=o>&gt;</span><span class=p>.</span><span class=nx>properties</span><span class=p>({</span> <span class=nx>cacheEnabled</span><span class=o>:</span> <span class=kc>true</span> <span class=p>});</span></span></span></code></pre></div><p>If the cache is enabled, it will be consulted when reading documents and primary index
entries for the collection. If there is a cache miss and the document or primary index
entry has to be looked up from the RocksDB storage engine, the cache will be populated.</p><p>The per-collection cache utilization for primary index entries can be checked via the
command <code>db.&lt;collection>.indexes(true)</code>, which will provide the attributes <code>cacheInUse</code>,
<code>cacheSize</code> and <code>cacheLifeTimeHitRate</code>.</p><p>Memory for the documents and primary index entries cache will be provided by ArangoDB&rsquo;s
central cache facility, whose maximal size can be configured by adjusting the value of
the startup option <code>--cache.size</code>.</p><p>Please note that caching may adversely affect the performance for collections that are
frequently updated. This is because cache entries need to be invalidated whenever documents
in the collection are updated, replaced or removed. Additionally, enabling caching will
subtract memory from the overall cache, so that less RAM may be available for other
items that use in-memory caching (e.g. edge index entries). It is therefore recommended
to turn on caching only for dedicated collections for which the caching effects have been
confirmed to be positive.</p><h3 id=exclusive-collection-access-option>Exclusive collection access option <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#exclusive-collection-access-option class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>In contrast to the MMFiles engine, the RocksDB engine does not require collection-level
locks. This is good in general because it allows concurrent access to a RocksDB
collection.</p><p>Reading documents does not require any locks with the RocksDB engine, and writing documents
will acquire per-document locks. This means that different documents can be modified
concurrently by different transactions.</p><p>When concurrent transactions modify the same documents in a RocksDB collection, there
will be a write-write conflict, and one of the transactions will be aborted. This is
incompatible with the MMFiles engine, in which write-write conflicts are impossible due
to its collection-level locks. In the MMFiles engine, a write transaction always has
exclusive access to a collection, and locks out all other writers.</p><p>While making access to a collection exclusive is almost always undesired from the
throughput perspective, it can greatly simplify client application development. Therefore
the RocksDB engine now provides optional exclusive access to collections on a
per-query/per-transaction basis.</p><p>For AQL queries, all data-modification operations now support the <code>exclusive</code> option, e.g.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>  <span class=kr>UPDATE</span> <span class=n>doc</span> <span class=kr>WITH</span> <span class=p>{</span> <span class=n>updated</span><span class=o>:</span> <span class=kc>true</span> <span class=p>}</span> <span class=kr>IN</span> <span class=n>collection</span> <span class=kp>OPTIONS</span> <span class=p>{</span> <span class=n>exclusive</span><span class=o>:</span> <span class=kc>true</span> <span class=p>}</span></span></span></code></pre></div><p>JavaScript-based transactions can specify which collections to lock exclusively in the
<code>exclusive</code> sub-attribute of their <code>collections</code> attribute:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=nx>_executeTransaction</span><span class=p>({</span>
</span></span><span class=line><span class=cl>  <span class=nx>collections</span><span class=o>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>exclusive</span><span class=o>:</span> <span class=p>[</span> <span class=s2>&#34;collection&#34;</span> <span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=p>...</span>
</span></span><span class=line><span class=cl><span class=p>});</span></span></span></code></pre></div><p>Note that using exclusive access for RocksDB collections will serialize write operations
to RocksDB collections, so it should be used with extreme care.</p><h3 id=rocksdb-library-upgrade>RocksDB library upgrade <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#rocksdb-library-upgrade class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The version of the bundled RocksDB library was upgraded from 5.6 to 5.16.</p><p>The version of the bundled Snappy compression library used by RocksDB was upgraded from
1.1.3 to 1.1.7.</p><h2 id=collection-and-document-operations>Collection and document operations <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#collection-and-document-operations class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=repsert-operation>Repsert operation <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#repsert-operation class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The existing functionality for inserting documents got an extra option to turn
an insert into a replace, in case that a document with the specified <code>_key</code> value
already exists. This type of operation is called a &ldquo;Repsert&rdquo; (Replace-insert).</p><p>Using the new option client applications do not need to check first whether a
given document exists, but can use a single atomic operation to conditionally insert
or replace it.</p><p>Here is an example of control flow that was previously necessary to conditionally
insert or replace a document:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>doc</span> <span class=o>=</span> <span class=p>{</span> <span class=nx>_key</span><span class=o>:</span> <span class=s2>&#34;someKey&#34;</span><span class=p>,</span> <span class=nx>value1</span><span class=o>:</span> <span class=mi>123</span><span class=p>,</span> <span class=nx>value2</span><span class=o>:</span> <span class=s2>&#34;abc&#34;</span> <span class=p>};</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// check if the document already exists...
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>if</span> <span class=p>(</span><span class=o>!</span><span class=nx>db</span><span class=p>.</span><span class=nx>collection</span><span class=p>.</span><span class=nx>exists</span><span class=p>(</span><span class=nx>doc</span><span class=p>.</span><span class=nx>_key</span><span class=p>))</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=c1>// ... document did not exist, so insert it
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=nx>db</span><span class=p>.</span><span class=nx>collection</span><span class=p>.</span><span class=nx>insert</span><span class=p>(</span><span class=nx>doc</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=c1>// ... document did exist, so replace it
</span></span></span><span class=line><span class=cl><span class=c1></span>  <span class=nx>db</span><span class=p>.</span><span class=nx>collection</span><span class=p>.</span><span class=nx>replace</span><span class=p>(</span><span class=nx>doc</span><span class=p>.</span><span class=nx>_key</span><span class=p>,</span> <span class=nx>doc</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></div><p>With ArangoDB 3.4 this can now be simplified to:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>doc</span> <span class=o>=</span> <span class=p>{</span> <span class=nx>_key</span><span class=o>:</span> <span class=s2>&#34;someKey&#34;</span><span class=p>,</span> <span class=nx>value1</span><span class=o>:</span> <span class=mi>123</span><span class=p>,</span> <span class=nx>value2</span><span class=o>:</span> <span class=s2>&#34;abc&#34;</span> <span class=p>};</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// insert the document if it does not exist yet, other replace
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nx>db</span><span class=p>.</span><span class=nx>collection</span><span class=p>.</span><span class=nx>insert</span><span class=p>(</span><span class=nx>doc</span><span class=p>,</span> <span class=p>{</span> <span class=nx>overwrite</span><span class=o>:</span> <span class=kc>true</span> <span class=p>});</span></span></span></code></pre></div><p>Client applications can also optionally retrieve the old revision of the document
in case the insert turned into a replace operation:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>doc</span> <span class=o>=</span> <span class=p>{</span> <span class=nx>_key</span><span class=o>:</span> <span class=s2>&#34;someKey&#34;</span><span class=p>,</span> <span class=nx>value1</span><span class=o>:</span> <span class=mi>123</span><span class=p>,</span> <span class=nx>value2</span><span class=o>:</span> <span class=s2>&#34;abc&#34;</span> <span class=p>};</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// insert the document if it does not exist yet, other replace
</span></span></span><span class=line><span class=cl><span class=c1>// in case of a replace, previous will be populated, in case of an
</span></span></span><span class=line><span class=cl><span class=c1>// insert, previous will be undefined
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nx>previous</span> <span class=o>=</span> <span class=nx>db</span><span class=p>.</span><span class=nx>collection</span><span class=p>.</span><span class=nx>insert</span><span class=p>(</span><span class=nx>doc</span><span class=p>,</span> <span class=p>{</span> <span class=nx>overwrite</span><span class=o>:</span> <span class=kc>true</span><span class=p>,</span> <span class=nx>returnOld</span><span class=o>:</span> <span class=kc>true</span> <span class=p>}).</span><span class=nx>old</span><span class=p>;</span></span></span></code></pre></div><p>The same functionality is available for the document insert method in the
HTTP REST API. The HTTP endpoint for <code>POST /_api/document</code> will now accept the
optional URL parameters <code>overwrite</code> and <code>returnOld</code>.</p><p>AQL also supports making an INSERT a conditional REPSERT. In contrast to regular
INSERT it supports returning the OLD and the NEW document on disk to i.e. inspect
the revision or the previous content of the document.
AQL INSERT is switched to REPSERT by setting the option <code>overwrite</code> for it:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>INSERT</span> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=n>_key</span><span class=o>:</span> <span class=s2>&#34;someKey&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl> <span class=n>value1</span><span class=o>:</span> <span class=mi>123</span><span class=p>,</span>
</span></span><span class=line><span class=cl> <span class=n>value2</span><span class=o>:</span> <span class=s2>&#34;abc&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span> <span class=kr>INTO</span> <span class=n>collection</span> <span class=kp>OPTIONS</span> <span class=p>{</span> <span class=n>overwrite</span><span class=o>:</span> <span class=kc>true</span> <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kr>RETURN</span> <span class=bp>OLD</span></span></span></code></pre></div><p>Please note that in a cluster setup the Repsert operation requires the collection
to be sharded by <code>_key</code>.</p><h3 id=graph-api-extensions>Graph API extensions <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#graph-api-extensions class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The REST APIs for modifying graphs at endpoint <code>/_api/gharial</code> now support returning
the old revision of vertices / edges after modifying them. The APIs also supports
returning the just-inserted vertex / edge. This is in line with the already existing
single-document functionality provided at endpoint <code>/_api/document</code>.</p><p>The old/new revisions can be accessed by passing the URL parameters <code>returnOld</code> and
<code>returnNew</code> to the following endpoints:</p><ul><li><code>/_api/gharial/&lt;graph>/vertex/&lt;collection></code></li><li><code>/_api/gharial/&lt;graph>/edge/&lt;collection></code></li></ul><p>The exception from this is that the HTTP DELETE verb for these APIs does not
support <code>returnOld</code> because that would make the existing API incompatible.</p><h3 id=additional-key-generators>Additional key generators <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#additional-key-generators class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>In addition to the existing key generators <code>traditional</code> (which is still the
default key generator) and <code>autoincrement</code>, ArangoDB 3.4 adds the following key
generators:</p><ul><li><p><code>padded</code>:
The <code>padded</code> key generator generates keys of a fixed length (16 bytes) in
ascending lexicographical sort order. This is ideal for usage with the RocksDB
engine, which will slightly benefit keys that are inserted in lexicographically
ascending order. The key generator can be used in a single-server or cluster.</p></li><li><p><code>uuid</code>: the <code>uuid</code> key generator generates universally unique 128 bit keys, which
are stored in hexadecimal human-readable format. This key generator can be used
in a single-server or cluster to generate &ldquo;seemingly random&rdquo; keys. The keys
produced by this key generator are not lexicographically sorted.</p></li></ul><p>Generators may be chosen with the creation of collections; here an example for
the <em>padded</em> key generator:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=nx>_create</span><span class=p>(</span><span class=s2>&#34;padded&#34;</span><span class=p>,</span> <span class=p>{</span> <span class=nx>keyOptions</span><span class=o>:</span> <span class=p>{</span> <span class=nx>type</span><span class=o>:</span> <span class=s2>&#34;padded&#34;</span> <span class=p>}</span> <span class=p>});</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=nx>padded</span><span class=p>.</span><span class=nx>insert</span><span class=p>({});</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_id&#34;</span> <span class=o>:</span> <span class=s2>&#34;padded/0000000009d0d1c0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_key&#34;</span> <span class=o>:</span> <span class=s2>&#34;0000000009d0d1c0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_rev&#34;</span> <span class=o>:</span> <span class=s2>&#34;_XI6VqNK--_&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=nx>padded</span><span class=p>.</span><span class=nx>insert</span><span class=p>({});</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_id&#34;</span> <span class=o>:</span> <span class=s2>&#34;padded/0000000009d0d1c4&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_key&#34;</span> <span class=o>:</span> <span class=s2>&#34;0000000009d0d1c4&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_rev&#34;</span> <span class=o>:</span> <span class=s2>&#34;_XI6VquC--_&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></div><p>Example for the <em>uuid</em> key generator:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=nx>_create</span><span class=p>(</span><span class=s2>&#34;uuid&#34;</span><span class=p>,</span> <span class=p>{</span> <span class=nx>keyOptions</span><span class=o>:</span> <span class=p>{</span> <span class=nx>type</span><span class=o>:</span> <span class=s2>&#34;uuid&#34;</span> <span class=p>}</span> <span class=p>});</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=nx>uuid</span><span class=p>.</span><span class=nx>insert</span><span class=p>({});</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_id&#34;</span> <span class=o>:</span> <span class=s2>&#34;uuid/16d5dc96-79d6-4803-b547-5a34ce795099&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_key&#34;</span> <span class=o>:</span> <span class=s2>&#34;16d5dc96-79d6-4803-b547-5a34ce795099&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_rev&#34;</span> <span class=o>:</span> <span class=s2>&#34;_XI6VPc2--_&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nx>db</span><span class=p>.</span><span class=nx>uuid</span><span class=p>.</span><span class=nx>insert</span><span class=p>({});</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_id&#34;</span> <span class=o>:</span> <span class=s2>&#34;uuid/0af83d4a-56d4-4553-a97d-c7ed2644dc09&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_key&#34;</span> <span class=o>:</span> <span class=s2>&#34;0af83d4a-56d4-4553-a97d-c7ed2644dc09&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;_rev&#34;</span> <span class=o>:</span> <span class=s2>&#34;_XI6VQgO--_&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></div><h3 id=miscellaneous-improvements>Miscellaneous improvements <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#miscellaneous-improvements class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The command <code>db.&lt;collection>.indexes()</code> was added as an alias for the already existing
<code>db.&lt;collection>.getIndexes()</code> method for retrieving all indexes of a collection. The
alias name is more consistent with the already existing method names for retrieving
all databases and collections.</p><h2 id=cluster-improvements>Cluster improvements <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#cluster-improvements class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=load-balancer-support>Load-balancer support <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#load-balancer-support class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>ArangoDB now supports running multiple Coordinators behind a load balancer that
randomly routes client requests to the different Coordinators. It is not required
anymore that load balancers implement session or connection stickiness on behalf
of ArangoDB.</p><p>In particular, the following ArangoDB APIs were extended to work well with load
balancing:</p><ul><li>the cursor API at endpoint <code>/_api/cursor</code></li><li>the jobs API at endpoint <code>/_api/job</code></li><li>the tasks API at endpoint <code>/_api/tasks</code></li><li>Pregel APIs at endpoint <code>/_api/pregel</code></li></ul><p>Some of these APIs build up Coordinator-local state in memory when being first
accessed, and allow accessing further data using follow-up requests. This caused
problems in previous versions of ArangoDB, when load balancers routed the follow
up requests to these APIs to different Coordinators that did not have access to
the other Coordinator&rsquo;s in-memory state.</p><p>With ArangoDB 3.4, if such an API is accessed by a follow-up request that refers
to state being created on a different Coordinator, the actually accessed Coordinator
will forward the client request to the correct Coordinator. Client applications
and load balancers do not need to be aware of which Coordinator they had used
for the previous requests, though from a performance point of view accessing the
same Coordinator for a sequence of requests will still be beneficial.</p><p>If a Coordinator forwards a request to a different Coordinator, it will send the
client an extra HTTP header <code>x-arango-request-forwarded-to</code> with the id of the
Coordinator it forwarded the request to. Client applications or load balancers
can optionally use that information to make follow-up requests to the &ldquo;correct&rdquo;
Coordinator to save the forwarding.</p><h3 id=refusal-to-start-mixed-engine-clusters>Refusal to start mixed-engine clusters <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#refusal-to-start-mixed-engine-clusters class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Starting a cluster with Coordinators and DB-Servers using different storage
engines is not supported. Doing it anyway will now log an error and abort a
Coordinator&rsquo;s startup.</p><p>Previous versions of ArangoDB did not detect the usage of different storage
engines in a cluster, but the runtime behavior of the cluster was undefined.</p><h3 id=advertised-endpoints>Advertised endpoints <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#advertised-endpoints class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>It is now possible to configure the endpoints advertised by the
Coordinators to clients to be different from the endpoints which are
used for cluster internal communication. This is important for client
drivers which refresh the list of endpoints during the lifetime of the
cluster (which they should do!). In this way one can make the cluster
advertise a load balancer or a separate set of IP addresses for external
access. The new option is called <code>--cluster.my-advertised-endpoint</code>.</p><h3 id=startup-safety-checks>Startup safety checks <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#startup-safety-checks class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The new option <code>--cluster.require-persisted-id</code> can be used to prevent the startup
of a cluster node using the wrong data directory.</p><p>If the option is set to true, then the ArangoDB instance will only start if a
UUID file (containing the instance&rsquo;s cluster-wide ID) is found in the database
directory on startup. Setting this option will make sure the instance is started
using an already existing database directory and not a new one.</p><p>For the first start, the UUID file must either be created manually or the option
must be set to <code>false</code> for the initial startup and later be changed to <code>true</code>.</p><h3 id=coordinator-storage-engine>Coordinator storage engine <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#coordinator-storage-engine class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>In previous versions of ArangoDB, cluster Coordinator nodes used the storage
engine selected by the database administrator (i.e. MMFiles or RocksDB).
Although all database and document data was forwarded from Coordinators to be
stored on the DB-Servers and not on the Coordinator nodes, the storage
engine used on the Coordinator was checking and initializing its on-disk state
on startup.
Especially because no &ldquo;real&rdquo; data was stored by the Coordinator&rsquo;s storage engine,
using a storage engine here did not provide any value but only introduced
unnecessary potential points of failure.</p><p>As of ArangoDB 3.4, cluster Coordinator nodes will now use an internal &ldquo;cluster&rdquo;
storage engine, which actually does not store any data. That prevents 3.4
Coordinators from creating any files or directories inside the database directory
except the meta data files such as <code>ENGINE</code>, <code>LOCK</code>, <code>SERVER</code>, <code>UUID</code> and <code>VERSION</code>.
And as no files need to be read on Coordinator startup except these mentioned
files, it also reduces the possibility of data corruption on Coordinator nodes.</p><h3 id=dbserver-role-as-alias-of-primary><code>DBSERVER</code> role as alias of <code>PRIMARY</code> <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#dbserver-role-as-alias-of-primary class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>When starting a <em>DB-Server</em>, the value <code>DBSERVER</code> can now be specified (as alias of
<code>PRIMARY</code>) in the option <code>--cluster.my-role</code>. The value <code>PRIMARY</code> is still accepted.</p><p>All REST APIs that currently return &ldquo;PRIMARY&rdquo; as <em>role</em>, will continue to return
&ldquo;PRIMARY&rdquo;.</p><h2 id=aql>AQL <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#aql class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=aql-query-profiling>AQL query profiling <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#aql-query-profiling class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>AQL queries can now be executed with optional profiling, using ArangoDB 3.4&rsquo;s new
<code>db._queryProfile()</code> function.</p><p>This new function is a hybrid of the already existing <code>db._query()</code> and <code>db._explain()</code>
functions:</p><ul><li><code>db._query()</code> will execute an AQL query, but not show the execution plan nor
runtime profile information</li><li><code>db._explain()</code> will show the query&rsquo;s execution plan, but not execute the query</li><li><code>db._queryProfile()</code> will run the query, collect the runtime costs of each component
of the query, and finally show the query&rsquo;s execution plan with actual runtime information.
This is very useful for debugging AQL query performance and optimizing queries.</li></ul><p>For more information please refer to the <a href=/3.10/aql/execution-and-performance/query-profiling/ class=link>Query Profiling</a>
page.</p><h3 id=revised-cluster-internal-aql-protocol>Revised cluster-internal AQL protocol <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#revised-cluster-internal-aql-protocol class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>When running an AQL query in a cluster, the Coordinator has to distribute the
individual parts of the AQL query to the relevant shards that will participate
in the execution of the query.</p><p>Up to including ArangoDB 3.3, the Coordinator has deployed the query parts to the
individual shards one by one. The more shards were involved in a query, the more
cluster-internal requests this required, and the longer the setup took.</p><p>In ArangoDB 3.4 the Coordinator will now only send a single request to each of
the involved DB-Servers (in contrast to one request per shard involved).
This will speed up the setup phase of most AQL queries, which will be noticable for
queries that affect a lot of shards.</p><p>The AQL setup has been changed from a two-step protocol to a single-step protocol,
which additionally reduces the total number of cluster-internal requests necessary
for running an AQL query.</p><p>The internal protocol and APIs have been adjusted so that AQL queries can now get
away with less cluster-internal requests than in 3.3 also after the setup phase.</p><p>Finally, there is now an extra optimization for trivial AQL queries that will only
access a single document by its primary key (see below).</p><h3 id=aql-functions-added>AQL functions added <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#aql-functions-added class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The following AQL functions have been added in ArangoDB 3.4:</p><ul><li><code>TO_BASE64</code>: creates the base64-encoded representation of a value</li><li><code>TO_HEX</code>: creates a hex-encoded string representation of a value</li><li><code>ENCODE_URI_COMPONENT</code>: URI-encodes a string value, for later usage in URLs</li><li><code>SOUNDEX</code>: calculates the soundex fingerprint of a string value</li><li><code>ASSERT</code>: aborts a query if a condition is not met</li><li><code>WARN</code>: makes a query produce a warning if a condition is not met</li><li><code>IS_KEY</code>: this function checks if the value passed to it can be used as a document
key, i.e. as the value of the <code>_key</code> attribute for a document</li><li><code>SORTED</code>: will return a sorted version of the input array using AQL&rsquo;s internal
comparison order</li><li><code>SORTED_UNIQUE</code>: same as <code>SORTED</code>, but additionally removes duplicates</li><li><code>COUNT_DISTINCT</code>: counts the number of distinct / unique items in an array</li><li><code>LEVENSHTEIN_DISTANCE</code>: calculates the Levenshtein distance between two string values</li><li><code>REGEX_MATCHES</code>: finds matches in a string using a regular expression</li><li><code>REGEX_SPLIT</code>: splits a string using a regular expression</li><li><code>UUID</code>: generates a universally unique identifier value</li><li><code>TOKENS</code>: splits a string into tokens using a language-specific text Analyzer</li><li><code>VERSION</code>: returns the server version as a string</li></ul><p>The following AQL functions have been added to make working with geographical
data easier:</p><ul><li><code>GEO_POINT</code></li><li><code>GEO_MULTIPOINT</code></li><li><code>GEO_POLYGON</code></li><li><code>GEO_LINESTRING</code></li><li><code>GEO_MULTILINESTRING</code></li><li><code>GEO_CONTAINS</code></li><li><code>GEO_INTERSECTS</code></li><li><code>GEO_EQUALS</code>.</li></ul><p>The first five functions will produce GeoJSON objects from coordinate data. The
latter three functions can be used for querying and comparing GeoJSON objects.</p><p>The following AQL functions can now be used as aggregation functions in a
COLLECT statement:</p><ul><li><code>UNIQUE</code></li><li><code>SORTED_UNIQUE</code></li><li><code>COUNT_DISTINCT</code></li></ul><p>The following function aliases have been created for existing AQL functions:</p><ul><li><code>CONTAINS_ARRAY</code> is an alias for <code>POSITION</code></li><li><code>KEYS</code> is an alias for <code>ATTRIBUTES</code></li></ul><h3 id=distributed-collect>Distributed COLLECT <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#distributed-collect class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>In the general case, AQL COLLECT operations are expensive to execute in a cluster,
because the DB-Servers need to send all shard-local data to the Coordinator
for a centralized aggregation.</p><p>The AQL query optimizer can push some parts of certain COLLECT operations to the
DB-Servers so they can do a per-shard aggregation. The DB-Servers can
then send only the already aggregated results to the Coordinator for a final aggregation.
For several queries this will reduce the amount of data that has to be transferred
between the DB-Servers servers and the Coordinator by a great extent, and thus
will speed up these queries. Work on this has started with ArangoDB 3.3.5, but
ArangoDB 3.4 allows more cases in which COLLECT operations can partially be pushed to
the DB-Servers.</p><p>In ArangoDB 3.3, the following aggregation functions could make use of a distributed
COLLECT in addition to <code>COLLECT WITH COUNT INTO</code> and <code>RETURN DISTINCT</code>:</p><ul><li><code>COUNT</code></li><li><code>SUM</code></li><li><code>MIN</code></li><li><code>MAX</code></li></ul><p>ArangoDB 3.4 additionally enables distributed COLLECT queries that use the following
aggregation functions:</p><ul><li><code>AVERAGE</code></li><li><code>VARIANCE</code></li><li><code>VARIANCE_SAMPLE</code></li><li><code>STDDEV</code></li><li><code>STDDEV_SAMPLE</code></li></ul><h3 id=native-aql-function-implementations>Native AQL function implementations <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#native-aql-function-implementations class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>All built-in AQL functions now have a native implementation in C++.
Previous versions of ArangoDB had AQL function implementations in both C++ and
in JavaScript.</p><p>The JavaScript implementations of AQL functions were powered by the V8 JavaScript
engine, which first required the conversion of all function input into V8&rsquo;s own
data structures, and a later conversion of the function result data into ArangoDB&rsquo;s
native format.</p><p>As all AQL functions are now exclusively implemented in native C++, no more
conversions have to be performed to invoke any of the built-in AQL functions.
This will considerably speed up the following AQL functions and any AQL expression
that uses any of these functions:</p><ul><li><code>APPLY</code></li><li><code>CALL</code></li><li><code>CURRENT_USER</code></li><li><code>DATE_ADD</code></li><li><code>DATE_COMPARE</code></li><li><code>DATE_DAYOFWEEK</code></li><li><code>DATE_DAYOFYEAR</code></li><li><code>DATE_DAYS_IN_MONTH</code></li><li><code>DATE_DAY</code></li><li><code>DATE_DIFF</code></li><li><code>DATE_FORMAT</code></li><li><code>DATE_HOUR</code></li><li><code>DATE_ISO8601</code></li><li><code>DATE_ISOWEEK</code></li><li><code>DATE_LEAPYEAR</code></li><li><code>DATE_MILLISECOND</code></li><li><code>DATE_MINUTE</code></li><li><code>DATE_MONTH</code></li><li><code>DATE_NOW</code></li><li><code>DATE_QUARTER</code></li><li><code>DATE_SECOND</code></li><li><code>DATE_SUBTRACT</code></li><li><code>DATE_TIMESTAMP</code></li><li><code>DATE_YEAR</code></li><li><code>IS_DATESTRING</code></li><li><code>IS_IN_POLYGON</code></li><li><code>LTRIM</code></li><li><code>RTRIM</code></li><li><code>FIND_FIRST</code></li><li><code>FIND_LAST</code></li><li><code>REVERSE</code></li><li><code>SPLIT</code></li><li><code>SUBSTITUTE</code></li><li><code>SHA512</code></li><li><code>TRANSLATE</code></li><li><code>WITHIN_RECTANGLE</code></li></ul><p>Additionally, the AQL functions <code>FULLTEXT</code>, <code>NEAR</code> and <code>WITHIN</code> now use the native
implementations even when executed in a cluster. In previous versions of ArangoDB,
these functions had native implementations for single-server setups only, but fell
back to using the JavaScript variants in a cluster environment.</p><p>Apart from saving conversion overhead, another side effect of adding native
implementations for all built-in AQL functions is, that AQL does not require the usage
of V8 anymore, except for user-defined functions.</p><p>If no user-defined functions are used in AQL, end users do not need to put aside
dedicated V8 contexts for executing AQL queries with ArangoDB 3.4, making server
configuration less complex and easier to understand.</p><h3 id=aql-optimizer-query-planning-improvements>AQL optimizer query planning improvements <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#aql-optimizer-query-planning-improvements class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The AQL query optimizer will by default now create at most 128 different execution
plans per AQL query. In previous versions the maximum number of plans was 192.</p><p>Normally the AQL query optimizer will generate a single execution plan per AQL query,
but there are some cases in which it creates multiple competing plans. More plans
can lead to better optimized queries, however, plan creation has its costs. The
more plans are created and shipped through the optimization pipeline, the more
time will be spent in the optimizer.
To make the optimizer better cope with some edge cases, the maximum number of plans
created is now strictly enforced and was lowered compared to previous versions of
ArangoDB. This helps a specific class of complex queries.</p><p>Note that the default maximum value can be adjusted globally by setting the startup
option <code>--query.optimizer-max-plans</code> or on a per-query basis by setting a query&rsquo;s
<code>maxNumberOfPlans</code> option.</p><h3 id=condition-simplification>Condition simplification <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#condition-simplification class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The query optimizer rule <code>simplify-conditions</code> has been added to simplify certain
expressions inside CalculationNodes, which can speed up runtime evaluation of these
expressions.</p><p>The optimizer rule <code>fuse-filters</code> has been added to merge adjacent FILTER conditions
into a single FILTER condition where possible, allowing to save some runtime registers.</p><h3 id=single-document-optimizations>Single document optimizations <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#single-document-optimizations class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>In a cluster, the cost of setting up a distributed query can be considerable for
trivial AQL queries that will only access a single document, e.g.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span> <span class=kr>FILTER</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=o>==</span> <span class=o>..</span><span class=p>.</span> <span class=kr>RETURN</span> <span class=n>doc</span>
</span></span><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span> <span class=kr>FILTER</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=o>==</span> <span class=o>..</span><span class=p>.</span> <span class=kr>RETURN</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span> <span class=kr>FILTER</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=o>==</span> <span class=o>..</span><span class=p>.</span> <span class=kr>REMOVE</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span> <span class=kr>FILTER</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=o>==</span> <span class=o>..</span><span class=p>.</span> <span class=kr>REMOVE</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl><span class=kr>REMOVE</span><span class=o>..</span><span class=p>.</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span> <span class=kr>FILTER</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=o>==</span> <span class=o>..</span><span class=p>.</span> <span class=kr>UPDATE</span> <span class=n>doc</span> <span class=kr>WITH</span> <span class=p>{</span> <span class=o>..</span><span class=p>.</span> <span class=p>}</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span> <span class=kr>FILTER</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=o>==</span> <span class=o>..</span><span class=p>.</span> <span class=kr>UPDATE</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=kr>WITH</span> <span class=p>{</span> <span class=o>..</span><span class=p>.</span> <span class=p>}</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl><span class=kr>UPDATE</span> <span class=o>..</span><span class=p>.</span> <span class=kr>WITH</span> <span class=p>{</span> <span class=o>..</span><span class=p>.</span> <span class=p>}</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span> <span class=kr>FILTER</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=o>==</span> <span class=o>..</span><span class=p>.</span> <span class=kr>REPLACE</span> <span class=n>doc</span> <span class=kr>WITH</span> <span class=p>{</span> <span class=o>..</span><span class=p>.</span> <span class=p>}</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span> <span class=kr>FILTER</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=o>==</span> <span class=o>..</span><span class=p>.</span> <span class=kr>REPLACE</span> <span class=n>doc</span><span class=p>.</span><span class=n>_key</span> <span class=kr>WITH</span> <span class=p>{</span> <span class=o>..</span><span class=p>.</span> <span class=p>}</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl><span class=kr>REPLACE</span> <span class=o>..</span><span class=p>.</span> <span class=kr>WITH</span> <span class=p>{</span> <span class=o>..</span><span class=p>.</span> <span class=p>}</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kr>INSERT</span> <span class=p>{</span> <span class=o>..</span><span class=p>.</span> <span class=p>}</span> <span class=kr>INTO</span> <span class=n>collection</span></span></span></code></pre></div><p>All of the above queries will affect at most a single document, identified by its
primary key. The AQL query optimizer can now detect this, and use a specialized
code path for directly carrying out the operation on the participating DB-Server(s). This special code path bypasses the general AQL query cluster setup and
shutdown, which would have prohibitive costs for these kinds of queries.</p><p>In case the optimizer makes use of the special code path, the explain output will
contain a node of the type <code>SingleRemoteOperationNode</code>, and the optimizer rules
will contain <code>optimize-cluster-single-document-operations</code>.</p><p>The optimization will fire automatically only for queries with the above patterns.
It will only fire when using <code>_key</code> to identify a single document,
and will be most effective if <code>_key</code> is also used as the collection&rsquo;s shard key.</p><h3 id=subquery-optimizations>Subquery optimizations <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#subquery-optimizations class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The AQL query optimizer can now optimize certain subqueries automatically so that
they perform less work.</p><p>The new optimizer rule <code>optimize-subqueries</code> will fire in the following situations:</p><ul><li><p>in case only a few results are used from a non-modifying subquery, the rule will
automatically add a LIMIT statement into the subquery.</p><p>For example, the unbounded subquery</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kd>LET</span> <span class=n>docs</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>    <span class=kr>FILTER</span> <span class=o>..</span><span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=kr>RETURN</span> <span class=n>doc</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=kr>RETURN</span> <span class=n>docs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span></span></span></code></pre></div><p>will be turned into a subquery that only produces a single result value:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kd>LET</span> <span class=n>docs</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>    <span class=kr>FILTER</span> <span class=o>..</span><span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=kr>LIMIT</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=kr>RETURN</span> <span class=n>doc</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=kr>RETURN</span> <span class=n>docs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span></span></span></code></pre></div></li><li><p>in case the result returned by a subquery is not used later but only the number
of subquery results, the optimizer will modify the result value of the subquery
so that it will return constant values instead of potentially more expensive
data structures.</p><p>For example, the following subquery returning entire documents</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>RETURN</span> <span class=nf>LENGTH</span><span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>    <span class=kr>FILTER</span> <span class=o>..</span><span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=kr>RETURN</span> <span class=n>doc</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><p>will be turned into a subquery that returns only simple boolean values:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>RETURN</span> <span class=nf>LENGTH</span><span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>    <span class=kr>FILTER</span> <span class=o>..</span><span class=p>.</span>
</span></span><span class=line><span class=cl>    <span class=kr>RETURN</span> <span class=kc>true</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><p>This saves fetching the document data from disk in first place, and copying it
from the subquery to the outer scope.
There may be more follow-up optimizations.</p></li></ul><h3 id=collect-into--keep-optimization>COLLECT INTO &mldr; KEEP optimization <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#collect-into--keep-optimization class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>When using an AQL COLLECT &mldr; INTO without a <code>KEEP</code> clause, then the AQL query
optimizer will now automatically detect which sub-attributes of the <code>INTO</code> variables
are used later in the query. The optimizer will add automatic <code>KEEP</code> clauses to
the COLLECT statement then if possible.</p><p>For example, the query</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc1</span> <span class=kr>IN</span> <span class=n>collection1</span>
</span></span><span class=line><span class=cl>  <span class=kr>FOR</span> <span class=n>doc2</span> <span class=kr>IN</span> <span class=n>collection2</span>
</span></span><span class=line><span class=cl>    <span class=kr>COLLECT</span> <span class=n>x</span> <span class=o>=</span> <span class=n>doc1</span><span class=p>.</span><span class=n>x</span> <span class=kr>INTO</span> <span class=n>g</span>
</span></span><span class=line><span class=cl>    <span class=kr>RETURN</span> <span class=p>{</span> <span class=n>x</span><span class=p>,</span> <span class=kr>all</span><span class=o>:</span> <span class=n>g</span><span class=p>[</span><span class=o>*</span><span class=p>].</span><span class=n>doc1</span><span class=p>.</span><span class=n>y</span> <span class=p>}</span></span></span></code></pre></div><p>will automatically be turned into</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc1</span> <span class=kr>IN</span> <span class=n>collection1</span>
</span></span><span class=line><span class=cl>  <span class=kr>FOR</span> <span class=n>doc2</span> <span class=kr>IN</span> <span class=n>collection2</span>
</span></span><span class=line><span class=cl>    <span class=kr>COLLECT</span> <span class=n>x</span> <span class=o>=</span> <span class=n>doc1</span><span class=p>.</span><span class=n>x</span> <span class=kr>INTO</span> <span class=n>g</span> <span class=kp>KEEP</span> <span class=n>doc1</span>
</span></span><span class=line><span class=cl>    <span class=kr>RETURN</span> <span class=p>{</span> <span class=n>x</span><span class=p>,</span> <span class=kr>all</span><span class=o>:</span> <span class=n>g</span><span class=p>[</span><span class=o>*</span><span class=p>].</span><span class=n>doc1</span><span class=p>.</span><span class=n>y</span> <span class=p>}</span></span></span></code></pre></div><p>This prevents variable <code>doc2</code> from being temporarily stored in the variable <code>g</code>,
which saves processing time and memory, especially for big result sets.</p><h3 id=fullcount-changes>Fullcount changes <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#fullcount-changes class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The behavior of the <code>fullCount</code> option for AQL query cursors was adjusted to conform
to users&rsquo; demands. The value returned in the <code>fullCount</code> result attribute will now
be produced only by the last <code>LIMIT</code> statement on the upper most level of the query -
hence <code>LIMIT</code> statements in subqueries will not have any effect on the
<code>fullCount</code> results any more.</p><p>This is a change to previous versions of ArangoDB, in which the <code>fullCount</code>
value was produced by the sequential last <code>LIMIT</code> statement in a query,
regardless if the <code>LIMIT</code> was on the top level of the query or in a subquery.</p><p>The <code>fullCount</code> result value will now also be returned for queries that are served
from the query results cache.</p><h3 id=relaxed-restrictions-for-limit-values>Relaxed restrictions for LIMIT values <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#relaxed-restrictions-for-limit-values class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The <code>offset</code> and <code>count</code> values used in an AQL LIMIT clause can now be expressions, as
long as the expressions can be resolved at query compile time.
For example, the following query will now work:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc</span> <span class=kr>IN</span> <span class=n>collection</span>
</span></span><span class=line><span class=cl>  <span class=kr>LIMIT</span> <span class=mi>0</span><span class=p>,</span> <span class=nf>CEIL</span><span class=p>(</span><span class=nv>@percent</span> <span class=o>*</span> <span class=nv>@count</span> <span class=o>/</span> <span class=mi>100</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>  <span class=kr>RETURN</span> <span class=n>doc</span></span></span></code></pre></div><p>Previous versions of ArangoDB required the <code>offset</code> and <code>count</code> values to be
either number literals or numeric bind parameter values.</p><h3 id=improved-sparse-index-support>Improved sparse index support <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#improved-sparse-index-support class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The AQL query optimizer can now use sparse indexes in more cases than it was able to
in ArangoDB 3.3. If a sparse index is not used in a query because the query optimizer
cannot prove itself that the index attribute value cannot be <code>null</code>, it is now often
useful to add an extra filter condition to the query that requires the sparse index'
attribute to be non-null.</p><p>For example, if for the following query there is a sparse index on <code>value</code> in any
of the collections, the optimizer cannot prove that <code>value</code> can never be <code>null</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc1</span> <span class=kr>IN</span> <span class=n>collection1</span>
</span></span><span class=line><span class=cl>  <span class=kr>FOR</span> <span class=n>doc2</span> <span class=kr>IN</span> <span class=n>collection2</span>
</span></span><span class=line><span class=cl>    <span class=kr>FILTER</span> <span class=n>doc1</span><span class=p>.</span><span class=n>value</span> <span class=o>==</span> <span class=n>doc2</span><span class=p>.</span><span class=n>value</span>
</span></span><span class=line><span class=cl>    <span class=kr>RETURN</span> <span class=p>[</span><span class=n>doc1</span><span class=p>,</span> <span class=n>doc2</span><span class=p>]</span></span></span></code></pre></div><p>By adding an extra filter condition to the query that excludes <code>null</code> values explicitly,
the optimizer in 3.4 will now be able to use a sparse index on <code>value</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-aql data-lang=aql><span class=line><span class=cl><span class=kr>FOR</span> <span class=n>doc1</span> <span class=kr>IN</span> <span class=n>collection1</span>
</span></span><span class=line><span class=cl>  <span class=kr>FOR</span> <span class=n>doc2</span> <span class=kr>IN</span> <span class=n>collection2</span>
</span></span><span class=line><span class=cl>    <span class=kr>FILTER</span> <span class=n>doc1</span><span class=p>.</span><span class=n>value</span> <span class=o>==</span> <span class=n>doc2</span><span class=p>.</span><span class=n>value</span>
</span></span><span class=line><span class=cl>    <span class=kr>FILTER</span> <span class=n>doc2</span><span class=p>.</span><span class=n>value</span> <span class=o>!=</span> <span class=kc>null</span>
</span></span><span class=line><span class=cl>    <span class=kr>RETURN</span> <span class=p>[</span><span class=n>doc1</span><span class=p>,</span> <span class=n>doc2</span><span class=p>]</span></span></span></code></pre></div><p>The optimizer in 3.3 was not able to detect this, and refused to use sparse indexes
for such queries.</p><h3 id=query-results-cache>Query results cache <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#query-results-cache class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The AQL query results cache in ArangoDB 3.4 has got additional parameters to
control which queries should be stored in the cache.</p><p>In addition to the already existing configuration option <code>--query.cache-entries</code>
that controls the maximum number of query results cached in each database&rsquo;s
query results cache, there now exist the following extra options:</p><ul><li><code>--query.cache-entries-max-size</code>: maximum cumulated size of the results stored
in each database&rsquo;s query results cache</li><li><code>--query.cache-entry-max-size</code>: maximum size for an individual cache result</li><li><code>--query.cache-include-system-collections</code>: whether or not results of queries
that involve system collections should be stored in the query results cache</li></ul><p>These options allow more effective control of the amount of memory used by the
query results cache, and can be used to better utilize the cache memory.</p><p>The cache configuration can be changed at runtime using the <code>properties</code> function
of the cache. For example, to limit the per-database number of cache entries to
256 MB and to limit the per-database cumulated size of query results to 64 MB,
and the maximum size of each individual cache entry to 1MB, the following call
could be used:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>require</span><span class=p>(</span><span class=s2>&#34;@arangodb/aql/cache&#34;</span><span class=p>).</span><span class=nx>properties</span><span class=p>({</span>
</span></span><span class=line><span class=cl>  <span class=nx>maxResults</span><span class=o>:</span> <span class=mi>256</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nx>maxResultsSize</span><span class=o>:</span> <span class=mi>64</span> <span class=o>*</span> <span class=mi>1024</span> <span class=o>*</span> <span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nx>maxEntrySize</span><span class=o>:</span> <span class=mi>1024</span> <span class=o>*</span> <span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nx>includeSystem</span><span class=o>:</span> <span class=kc>false</span>
</span></span><span class=line><span class=cl><span class=p>});</span></span></span></code></pre></div><p>The contents of the query results cache can now also be inspected at runtime using
the cache&rsquo;s new <code>toArray</code> function:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-js data-lang=js><span class=line><span class=cl><span class=nx>require</span><span class=p>(</span><span class=s2>&#34;@arangodb/aql/cache&#34;</span><span class=p>).</span><span class=nx>toArray</span><span class=p>();</span></span></span></code></pre></div><p>This will show all query results currently stored in the query results cache of
the current database, along with their query strings, sizes, number of results
and original query run times.</p><p>The functionality is also available via HTTP REST APIs.</p><h3 id=miscellaneous-changes>Miscellaneous changes <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#miscellaneous-changes class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>When creating query execution plans for a query, the query optimizer was fetching
the number of documents of the underlying collections in case multiple query
execution plans were generated. The optimizer used these counts as part of its
internal decisions and execution plan costs calculations.</p><p>Fetching the number of documents of a collection can have measurable overhead in a
cluster, so ArangoDB 3.4 now caches the &ldquo;number of documents&rdquo; that are referred to
when creating query execution plans. This may save a few roundtrips in case the
same collections are frequently accessed using AQL queries.</p><p>The &ldquo;number of documents&rdquo; value was not and is not supposed to be 100% accurate
in this stage, as it is used for rough cost estimates only. It is possible however
that when explaining an execution plan, the &ldquo;number of documents&rdquo; estimated for
a collection is using a cached stale value, and that the estimates change slightly
over time even if the underlying collection is not modified.</p><h2 id=streaming-aql-cursors>Streaming AQL Cursors <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#streaming-aql-cursors class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>AQL query cursors created by client applications traditionally executed an AQL query,
and built up the entire query result in memory. Once the query completed, the results
were sent back to the client application in chunks of configurable size.</p><p>This approach was a good fit for the MMFiles engine with its collection-level locks,
and usually smaller-than-RAM query results. For the RocksDB engine with its document-level
locks and lock-free reads and potentially huge query results, this approach does not always
fit.</p><p>ArangoDB 3.4 allows to optionally execute AQL queries initiated via the cursor API in a
streaming fashion. The query result will then be calculated on the fly, and results are
sent back to the client application as soon as they become available on the server, even
if the query has not yet completed.</p><p>This is especially useful for queries that produce big result sets (e.g.
<code>FOR doc IN collection RETURN doc</code> for big collections). Such queries will take very long
to complete without streaming, because the entire query result will be computed first and
stored in memory. Executing such queries in non-streaming fashion may lead to client
applications timing out before receiving the first chunk of data from the server. Additionally,
creating a huge query result set on the server may make it run out of memory, which is also
undesired. Creating a streaming cursor for such queries will solve both problems.</p><p>Please note that streaming cursors will use resources all the time till you
fetch the last chunk of results.</p><p>Depending on the storage engine used this has different consequences:</p><ul><li><p><strong>MMFiles</strong>: While before collection locks would only be held during the creation of the cursor
(the first request) and thus until the result set was well prepared,
they will now be held until the last chunk requested
by the client through the cursor is processed.</p><p>While Multiple reads are possible, one write operation will effectively stop
all other actions from happening on the collections in question.</p></li><li><p><strong>RocksDB</strong>: Reading occurs on the state of the data when the query
was started. Writing however will happen during working with the cursor.
Thus be prepared for possible conflicts if you have other writes on the collections,
and probably overrule them by <code>ignoreErrors: True</code>, else the query
will abort by the time the conflict happens.</p></li></ul><p>Taking into account the above consequences, you shouldn&rsquo;t use streaming
cursors light-minded for data modification queries.</p><p>Please note that the query options <code>cache</code>, <code>count</code> and <code>fullCount</code> will not work with streaming
cursors. Additionally, the query statistics, warnings and profiling data will only be available
when the last result batch for the query is sent. Using a streaming cursor will also prevent
the query results being stored in the AQL query results cache.</p><p>By default, query cursors created via the cursor API are non-streaming in ArangoDB 3.4,
but streaming can be enabled on a per-query basis by setting the <code>stream</code> attribute
in the request to the cursor API at endpoint <code>/_api/cursor</code>.</p><p>However, streaming cursors are enabled automatically for the following parts of ArangoDB in 3.4:</p><ul><li>when exporting data from collections using the arangoexport binary</li><li>when using <code>db.&lt;collection>.toArray()</code> from the Arango shell</li></ul><p>Please note that AQL queries consumed in a streaming fashion have their own, adjustable
&ldquo;slow query&rdquo; threshold. That means the &ldquo;slow query&rdquo; threshold can be configured separately for
regular queries and streaming queries.</p><h2 id=native-implementations>Native implementations <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#native-implementations class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>The following internal and user-facing functionality has been ported from
JavaScript-based implementations to C++-based implementations in ArangoDB 3.4:</p><ul><li>the statistics gathering background thread</li><li>the REST APIs for<ul><li>managing user defined AQL functions</li><li>graph management at <code>/_api/gharial</code> that also does:<ul><li>vertex management</li><li>edge management</li></ul></li></ul></li><li>the implementations of all built-in AQL functions</li><li>all other parts of AQL except user-defined functions</li><li>database creation and setup</li><li>all the DB-Server internal maintenance tasks for shard creation, index
creation and the like in the cluster</li></ul><p>By making the listed functionality not use and not depend on the V8 JavaScript
engine, the respective functionality can now be invoked more efficiently in the
server, without requiring the conversion of data between ArangoDB&rsquo;s native format
and V8&rsquo;s internal formats. For the maintenance operations this will lead to
improved stability in the cluster.</p><p>As a consequence, ArangoDB Agency and DB-Server nodes in an ArangoDB 3.4
cluster will now turn off the V8 JavaScript engine at startup entirely and automatically.
The V8 engine will still be enabled on cluster Coordinators, single servers and
active failover instances. But even the latter instance types will not require as
many V8 contexts as previous versions of ArangoDB.
This should reduce problems with servers running out of available V8 contexts or
using a lot of memory just for keeping V8 contexts around.</p><h2 id=foxx>Foxx <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#foxx class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>The functions <code>uuidv4</code> and <code>genRandomBytes</code> have been added to the <code>crypto</code> module.</p><p>The functions <code>hexSlice</code>, <code>hexWrite</code> have been added to the <code>Buffer</code> object.</p><p>The functions <code>Buffer.from</code>, <code>Buffer.of</code>, <code>Buffer.alloc</code> and <code>Buffer.allocUnsafe</code>
have been added to the <code>Buffer</code> object for improved compatibility with node.js.</p><h2 id=security>Security <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#security class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=ownership-for-cursors-jobs-and-tasks>Ownership for cursors, jobs and tasks <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#ownership-for-cursors-jobs-and-tasks class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Cursors for AQL query results created by the API at endpoint <code>/_api/cursor</code>
are now tied to the user that first created the cursor.</p><p>Follow-up requests to consume or remove data of an already created cursor will
now be denied if attempted by a different user.</p><p>The same mechanism is also in place for the following APIs:</p><ul><li>jobs created via the endpoint <code>/_api/job</code></li><li>tasks created via the endpoint <code>/_api/tasks</code></li></ul><h3 id=dropped-support-for-sslv2>Dropped support for SSLv2 <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#dropped-support-for-sslv2 class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>ArangoDB 3.4 will not start when attempting to bind the server to a Secure Sockets
Layer (SSL) v2 endpoint. Additionally, the client tools (arangosh, arangoimport,
arangodump, arangorestore etc.) will refuse to connect to an SSLv2-enabled server.</p><p>SSLv2 can be considered unsafe nowadays and as such has been disabled in the OpenSSL
library by default in recent versions. ArangoDB is following this step.</p><p>Clients that use SSLv2 with ArangoDB should change the protocol from SSLv2 to TLSv12
if possible, by adjusting the value of the <code>--ssl.protocol</code> startup option for the
<code>arangod</code> server and all client tools.</p><h2 id=distribution-packages>Distribution Packages <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#distribution-packages class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><p>In addition to the OS-specific packages (eg. <em>rpm</em> for Red Hat / CentOS, <em>deb</em> for
Debian, NSIS installer for Windows etc.) starting from 3.4.0 new <code>tar.gz</code> archive packages
are available for Linux and Mac. They correspond to the <code>.zip</code> packages for Windows,
which can be used for portable installations, and to easily run different ArangoDB
versions on the same machine (e.g. for testing).</p><h2 id=client-tools>Client tools <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#client-tools class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=arangosh>arangosh <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#arangosh class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>Starting with ArangoDB version 3.4.5, the ArangoShell (<em>arangosh</em>) provides the option
<code>--console.history</code> for controlling whether the shell&rsquo;s command-line history
should be loaded from and persisted in a file.</p><p>The default value for this option is <code>true</code>. Setting it to <code>false</code>
will make arangosh not load any command-line history from the history
file, and not store the current session&rsquo;s history when the shell is
exited. The command-line history will then only be available in the
current shell session.</p><h3 id=arangodump>arangodump <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#arangodump class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><em>arangodump</em> can now dump multiple collections in parallel. This can significantly
reduce the time required to take a backup.</p><p>By default, <em>arangodump</em> will use 2 threads for dumping collections. The number of
threads used by <em>arangodump</em> can be adjusted by using the <code>--threads</code> option when
invoking it.</p><h3 id=arangorestore>arangorestore <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#arangorestore class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><em>arangorestore</em> can now restore multiple collections in parallel. This can significantly
reduce the time required to recover data from a backup.</p><p>By default, <em>arangorestore</em> will use 2 threads for restoring collections. The number of
threads used by <em>arangorestore</em> can be adjusted by using the <code>--threads</code> option when
invoking it.</p><h3 id=arangoimport>arangoimport <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#arangoimport class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p><em>arangoimp</em> was renamed to <em>arangoimport</em> for consistency.
The 3.4 release packages will still install <code>arangoimp</code> as a symlink so user scripts
invoking <code>arangoimp</code> do not need to be changed.</p><p><a href=/3.10/components/tools/arangoimport/details/#automatic-pacing-with-busy-or-low-throughput-disk-subsystems class=link>arangoimport now can pace the data load rate automatically</a>
based on the actual rate of
data the server can handle. This is useful in contexts when the server has a limited
I/O bandwidth, which is often the case in cloud environments. Loading data too quickly
may lead to the server exceeding its provisioned I/O operations quickly, which will
make the cloud environment throttle the disk performance and slowing it down drastically.
Using a controlled and adaptive import rate allows preventing this throttling.</p><p>The pacing algorithm is turned on by default, but can be disabled by manually specifying
any value for the <code>--batch-size</code> parameter.</p><p><em>arangoimport</em> also got an extra option <code>--create-database</code> so that it can automatically
create the target database should this be desired. Previous versions of <em>arangoimp</em>
provided options for creating the target collection only
(<code>--create-collection</code>, <code>--create-collection-type</code>).</p><p>Finally, <em>arangoimport</em> got an option <code>--latency</code> which can be used to print microsecond
latency statistics on 10 second intervals for import runs. This can be used to get
additional information about the import run performance and performance development.</p><h2 id=miscellaneous-features>Miscellaneous features <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#miscellaneous-features class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h2><h3 id=logging-without-escaping-non-printable-characters>Logging without escaping non-printable characters <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#logging-without-escaping-non-printable-characters class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The new option <code>--log.escape</code> can be used to enable a slightly different log output
format.</p><p>If set to <code>true</code> (which is the default value), then the logging will work as in
previous versions of ArangoDB, and the following characters in the log output are
escaped:</p><ul><li>the carriage return character (hex 0d)</li><li>the newline character (hex 0a)</li><li>the tabstop character (hex 09)</li><li>any other characters with an ordinal value less than hex 20</li></ul><p>If the <code>--log.escape</code> option is set to <code>false</code> however, no characters are escaped
when logging them. Characters with an ordinal value less than hex 20 (including
carriage return, newline and tabstop) will not be printed in this mode, but will
be replaced with a space character (hex 20). This is because these characters are
often undesired in logs anyway.
Another positive side effect of turning off the escaping is that it will slightly
reduce the CPU overhead for logging. However, this will only be noticable when the
logging is set to a very verbose level (e.g. log levels debug or trace).</p><h3 id=active-failover>Active Failover <a href=/3.10/release-notes/version-3.4/whats-new-in-3-4/#active-failover class=header-link onclick=copyURI(event)><span></span><i class="fa fa-link"></i></a></h3><p>The <em>Active Failover</em> mode is now officially supported for multiple slaves.</p><p>Additionally you can now send read-only requests to followers, so you can
use them for read scaling. To make sure only requests that are intended for
this use-case are served by the follower you need to add a
<code>X-Arango-Allow-Dirty-Read: true</code> header to HTTP requests.</p><p>For more information see
<a href=/3.10/deploy/active-failover/ class=link>Active Failover Architecture</a>.</p><nav class=pagination><span class=prev><a class="nav nav-prev link" href=/3.10/release-notes/version-3.4/><i class="fas fa-chevron-left fa-fw"></i><p>Version 3.4</p></a></span><span class=next><a class="nav nav-next link" href=/3.10/release-notes/version-3.4/known-issues-in-3-4/><p>Known Issues in 3.4</p><i class="fas fa-chevron-right fa-fw"></i></a></span></nav></article><div class=toc-container><a class=edit-page aria-label href=https://github.com/arangodb/docs-hugo/edit/main/site/content/3.10/release-notes/version-3.4/whats-new-in-3-4.md target=_blank><i class="fab fa-fw fa-github edit-page-icon"></i></a><div class=toc><div class=toc-content><div class=toc-header><p>On this page</p></div><nav id=TableOfContents><div class=level-2><a href=#arangosearch>ArangoSearch</a></div><div class=level-2><a href=#new-geo-index-implementation>New geo index implementation</a></div><div class=level-3><a href=#s2-based-geo-index>S2 based geo index</a></div><div class=level-3><a href=#aql-editor-geojson-support>AQL Editor GeoJSON Support</a></div><div class=level-2><a href=#rocksdb-storage-engine>RocksDB storage engine</a></div><div class=level-3><a href=#rocksdb-as-default-storage-engine>RocksDB as default storage engine</a></div><div class=level-3><a href=#optimized-binary-storage-format>Optimized binary storage format</a></div><div class=level-3><a href=#better-control-of-rocksdb-wal-sync-interval>Better control of RocksDB WAL sync interval</a></div><div class=level-3><a href=#reduced-replication-catch-up-time>Reduced replication catch-up time</a></div><div class=level-3><a href=#improved-rocksdb-geo-index-performance>Improved RocksDB geo index performance</a></div><div class=level-3><a href=#optional-caching-for-documents-and-primary-index-values>Optional caching for documents and primary index values</a></div><div class=level-3><a href=#exclusive-collection-access-option>Exclusive collection access option</a></div><div class=level-3><a href=#rocksdb-library-upgrade>RocksDB library upgrade</a></div><div class=level-2><a href=#collection-and-document-operations>Collection and document operations</a></div><div class=level-3><a href=#repsert-operation>Repsert operation</a></div><div class=level-3><a href=#graph-api-extensions>Graph API extensions</a></div><div class=level-3><a href=#additional-key-generators>Additional key generators</a></div><div class=level-3><a href=#miscellaneous-improvements>Miscellaneous improvements</a></div><div class=level-2><a href=#cluster-improvements>Cluster improvements</a></div><div class=level-3><a href=#load-balancer-support>Load-balancer support</a></div><div class=level-3><a href=#refusal-to-start-mixed-engine-clusters>Refusal to start mixed-engine clusters</a></div><div class=level-3><a href=#advertised-endpoints>Advertised endpoints</a></div><div class=level-3><a href=#startup-safety-checks>Startup safety checks</a></div><div class=level-3><a href=#coordinator-storage-engine>Coordinator storage engine</a></div><div class=level-3><a href=#dbserver-role-as-alias-of-primary><code>DBSERVER</code> role as alias of <code>PRIMARY</code></a></div><div class=level-2><a href=#aql>AQL</a></div><div class=level-3><a href=#aql-query-profiling>AQL query profiling</a></div><div class=level-3><a href=#revised-cluster-internal-aql-protocol>Revised cluster-internal AQL protocol</a></div><div class=level-3><a href=#aql-functions-added>AQL functions added</a></div><div class=level-3><a href=#distributed-collect>Distributed COLLECT</a></div><div class=level-3><a href=#native-aql-function-implementations>Native AQL function implementations</a></div><div class=level-3><a href=#aql-optimizer-query-planning-improvements>AQL optimizer query planning improvements</a></div><div class=level-3><a href=#condition-simplification>Condition simplification</a></div><div class=level-3><a href=#single-document-optimizations>Single document optimizations</a></div><div class=level-3><a href=#subquery-optimizations>Subquery optimizations</a></div><div class=level-3><a href=#collect-into--keep-optimization>COLLECT INTO &mldr; KEEP optimization</a></div><div class=level-3><a href=#fullcount-changes>Fullcount changes</a></div><div class=level-3><a href=#relaxed-restrictions-for-limit-values>Relaxed restrictions for LIMIT values</a></div><div class=level-3><a href=#improved-sparse-index-support>Improved sparse index support</a></div><div class=level-3><a href=#query-results-cache>Query results cache</a></div><div class=level-3><a href=#miscellaneous-changes>Miscellaneous changes</a></div><div class=level-2><a href=#streaming-aql-cursors>Streaming AQL Cursors</a></div><div class=level-2><a href=#native-implementations>Native implementations</a></div><div class=level-2><a href=#foxx>Foxx</a></div><div class=level-2><a href=#security>Security</a></div><div class=level-3><a href=#ownership-for-cursors-jobs-and-tasks>Ownership for cursors, jobs and tasks</a></div><div class=level-3><a href=#dropped-support-for-sslv2>Dropped support for SSLv2</a></div><div class=level-2><a href=#distribution-packages>Distribution Packages</a></div><div class=level-2><a href=#client-tools>Client tools</a></div><div class=level-3><a href=#arangosh>arangosh</a></div><div class=level-3><a href=#arangodump>arangodump</a></div><div class=level-3><a href=#arangorestore>arangorestore</a></div><div class=level-3><a href=#arangoimport>arangoimport</a></div><div class=level-2><a href=#miscellaneous-features>Miscellaneous features</a></div><div class=level-3><a href=#logging-without-escaping-non-printable-characters>Logging without escaping non-printable characters</a></div><div class=level-3><a href=#active-failover>Active Failover</a></div></nav></div></div></div></div></div></section></section></div><button class="back-to-top hidden" onclick=goToTop(event) href=#><i class="fa fa-arrow-up"></i></button><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@docsearch/css@3>
<script src=https://cdn.jsdelivr.net/npm/@docsearch/js@3></script>
<script type=text/javascript>window.setupDocSearch=function(e){if(!window.docsearch)return;docsearch({appId:"OK3ZBQ5982",apiKey:"500c85ccecb335d507fe4449aed12e1d",indexName:"arangodbdocs",insights:!0,container:"#searchbox",debug:!1,maxResultsPerGroup:10,searchParameters:{facetFilters:[`version:${e}`]}})}</script></body></html>